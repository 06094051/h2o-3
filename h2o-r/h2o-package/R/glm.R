#' H2O Generalized Linear Models
#'
#' Fit a generalized linear model, specified by a response variable, a set of predictors, and a description of the error distribution.
#'
#' @param x A vector containing the names or indices of the predictor variables to use in building the GLM model.
#' @param y A character string or index that represent the response variable in the model.
#' @param training_frame An \code{\linkS4class{H2OFrame}} object containing the variables in the model.
#' @param ...
#' @param destination_key (Optional) An unique hex key assigned to the resulting model. If none is given, a key will automatically be generated.
#' @param validation_frame An \code{\linkS4class{H2OFrame}} object containing the variables in the model.
#' @param max_iter A non-negative integer specifying the maximum number of iterations.
#' @param beta_eps A non-negative number specifying the magnitude of the maximum difference between the coefficient estimates from successive iterations.
#'        Defines the convergence criterion for \code{h2o.glm}.
#' @param solver A character string specifying the solver used: ADMM (supports more features), L_BFGS (scales better for datasets with many columns)
#' @param standardize A logical value indicating whether the numeric predictors should be standardized to have a mean of 0 and a variance of 1 prior to
#'        training the models.
#' @param family A character string specifying the distribution of the model:  gaussian, binomial, poisson, gamma, tweedie.
#' @param link A character string specifying the link function. The default is the canonical link for the \code{family}. The supported links for each of 
#'        the \code{family} specifications are:
#'        \code{"gaussian"}: \code{"identity"}, \code{"log"}, \code{"inverse"}\cr
#'        \code{"binomial"}: \code{"logit"}, \code{"log"}\cr
#'        \code{"poisson"}: \code{"log"}, \code{"identity"}\cr
#'        \code{"gamma"}: \code{"inverse"}, \code{"log"}, \code{"identity"}\cr
#'        \code{"tweedie"}: \code{"tweedie"}\cr
#' @param tweedie_variance_power A numeric specifying the power for the variance function when \code{family = "tweedie"}.
#' @param tweedie_link_power A numeric specifying the power for the link function when \code{family = "tweedie"}.
#' @param alpha A numeric in [0, 1] specifying the elastic-net mixing parameter.
#'                The elastic-net penalty is defined to be:
#'                \deqn{P(\alpha,\beta) = (1-\alpha)/2||\beta||_2^2 + \alpha||\beta||_1 = \sum_j [(1-\alpha)/2 \beta_j^2 + \alpha|\beta_j|]},
#'                making \code{alpha = 1} the lasso penalty and \code{alpha = 0} the ridge penalty.
#' @param lambda A non-negative shrinkage parameter for the elastic-net, which multiplies \eqn{P(\alpha,\beta)} in the objective function.
#'               When \code{lambda = 0}, no elastic-net penalty is applied and ordinary generalized linear models are fit.
#' @param prior1 (Optional) A numeric specifying the prior probability of class 1 in the response when \code{family = "binomial"}. 
#'               The default prior is the observational frequency of class 1.
#' @param lambda_search A logical value indicating whether to conduct a search over the space of lambda values starting from the lambda max, given
#'                      \code{lambda} is interpreted as lambda min.
#' @param nlambdas The number of lambda values to use when \code{lambda_search = TRUE}.
#' @param lambda_min_ratio Smallest value for lambda as a fraction of lambda.max. By default if the number of observations is greater than the 
#'                         the number of variables then \code{lambda_min_ratio} = 0.0001; if the number of observations is less than the number
#'                         of variables then \code{lambda_min_ratio} = 0.01.
#' @param use_all_factor_levels A logical value indicating whether dummy variables should be used for all factor levels of the categorical predictors.
#'                              When \code{TRUE}, results in an over parameterized models.
#' @param n_folds (Currently Unimplemented)
#' @export
h2o.startGLMJob <- function(x, y, training_frame, destination_key, validation_frame, ...,
                    #AUTOGENERATED Params
                    max_iterations = 50,
                    beta_epsilon = 0,
                    balance_classes = FALSE,
                    class_sampling_factors,
                    max_after_balance_size = 5.0,
                    solver = c("ADMM", "L_BFGS"),
                    standardize = TRUE,
                    family = c("gaussian", "binomial", "poisson", "gamma", "tweedie"),
                    link = c("family_default", "identity", "logit", "log", "inverse", "tweedie"),
                    tweedie_variance_power = NaN,
                    tweedie_link_power = NaN,
                    alpha = 0.5,
                    prior = 0.0,
                    lambda = 1e-05,
                    lambda_search = FALSE,
                    nlambdas = -1,
                    lambda_min_ratio = -1.0,
                    use_all_factor_levels = FALSE,
                    beta_constraints = NULL
                    )
{
    if (!is.null(beta_constraints)) {
        if (!inherits(beta_constraints, "data.frame") && !inherits(beta_constraints, "H2OFrame"))
          stop(paste("`beta_constraints` must be an H2OParsedData or R data.frame. Got: ", class(beta_constraints)))
        if (inherits(beta_constraints, "data.frame")) {
          beta_constraints <- as.h2o(training_frame@conn, beta_constraints)
        }
    }
    dots <- list(...)

    for(type in names(dots))
        if (is.environment(dots[[type]]))
        {
        dots$envir <- type
        type <- NULL
        } else {
          stop(paste0("\n  unused argument (", type, " = ", deparse(dots[[type]]), ")"))
        }
    if (is.null(dots$envir))
        dots$envir <- parent.frame()

    if( missing(x) ) stop("`x` is missing, with no default")
    if( missing(y) ) stop("`y` is missing, with no default")
    if( missing(training_frame) ) stop("`training_frame` is missing, with no default")

    if (!inherits(training_frame, "H2OFrame"))
        tryCatch(training_frame <- h2o.getFrame(training_frame),
                 error = function(err) {
                   stop("argument \"training_frame\" must be a valid H2OFrame or key")
                })
#required map for params with different names, assuming it will change in the RESTAPI end
    .glm.map <- c("x" = "ignored_columns",
                  "y" = "response_column",
                  "key" = "destination_key")

    parms <- as.list(match.call(expand.dots = FALSE)[-1L])
    parms$... <- NULL

    args <- .verify_dataxy(training_frame, x, y)
    parms$x <- args$x_ignore
    parms$y <- args$y
    parms$training_frame  = training_frame
    parms$beta_constraints = beta_constraints
    names(parms) <- lapply(names(parms), function(i) { if (i %in% names(.glm.map)) i <- .glm.map[[i]]; i })
    .h2o.startModelJob(training_frame@conn, 'glm', parms, dots$envir)
}

#' @export
h2o.getGLMModel <- function(keys) {
  job_key  <- keys[[1]]
  dest_key <- keys[[1]]
  .h2o.__waitOnJob(conn, job_key)
  model <- h2o.getModel(dest_key, conn)
  if (delete_train)
    h2o.rm(temp_train_key)
  if (!is.null(params$validation_frame))
    if (delete_valid)
      h2o.rm(temp_valid_key)
  model
}

#' @export
h2o.glm <- function(x, y, training_frame, destination_key, validation_frame,
                    #AUTOGENERATED Params
                    max_iterations = 50,
                    beta_epsilon = 0,
                    score_each_iteration = FALSE,
                    do_classification = FALSE,
                    balance_classes = FALSE,
                    class_sampling_factors,
                    max_after_balance_size = 5.0,
                    solver = c("ADMM", "L_BFGS"),
                    standardize = TRUE,
                    family = c("gaussian", "binomial", "poisson", "gamma", "tweedie"),
                    link = c("family_default", "identity", "logit", "log", "inverse", "tweedie"),
                    tweedie_variance_power = NaN,
                    tweedie_link_power = NaN,
                    alpha = 0.5,
                    prior = 0.0,
                    lambda = 1e-05,
                    lambda_search = FALSE,
                    nlambdas = -1,
                    lambda_min_ratio = 1.0,
                    higher_accuracy = FALSE,
                    use_all_factor_levels = FALSE,
                    nfolds = 0,
                    beta_constraints = NULL,
                    ...
                    )
{
    if (!is.null(beta_constraints)) {
        if (!inherits(beta_constraints, "data.frame") && !inherits(beta_constraints, "H2OFrame"))
          stop(paste("`beta_constraints` must be an H2OParsedData or R data.frame. Got: ", class(beta_constraints)))
        if (inherits(beta_constraints, "data.frame"))
          beta_constraints <- as.h2o(training_frame@conn, beta_constraints)
    }
    dots <- list(...)

    for(type in names(dots))
        if (is.environment(dots[[type]]))
        {
        dots$envir <- type
        type <- NULL
        } else {
          stop(paste0("\n  unused argument (", type, " = ", dots[[type]], ")"))
        }
    if (is.null(dots$envir))
        dots$envir <- parent.frame()

    if( missing(x) ) stop("`x` is missing, with no default")
    if( missing(y) ) stop("`y` is missing, with no default")
    if( missing(training_frame) ) stop("`training_frame` is missing, with no default")    

    if (!inherits(training_frame, "H2OFrame"))
        tryCatch(training_frame <- h2o.getFrame(training_frame),
                 error = function(err) {
                   stop("argument \"training_frame\" must be a valid H2OFrame or key")
                })
#required map for params with different names, assuming it will change in the RESTAPI end
    .glm.map <- c("x" = "ignored_columns",
                "y" = "response_column",
                "key" = "destination_key")

    parms <- as.list(match.call(expand.dots = FALSE)[-1L])
    parms$... <- NULL

    # For now, accept nfolds in the R interface if it is 0 or 1, since those values really mean do nothing.
    # For any other value, error out.
    # Expunge nfolds from the message sent to H2O, since H2O doesn't understand it.
    if (nfolds > 1) stop("nfolds >1 not supported")
    parms$nfolds <- NULL

    args <- .verify_dataxy(training_frame, x, y)
    parms$x <- args$x_ignore
    parms$y <- args$y
    parms$beta_constraints <- beta_constraints
    names(parms) <- lapply(names(parms), function(i) { if (i %in% names(.glm.map)) i <- .glm.map[[i]]; i })
    m <- .h2o.createModel(training_frame@conn, 'glm', parms, dots$envir)
    m@model$coefficients <- m@model$coefficients_table[,2]
    names(m@model$coefficients) <- m@model$coefficients_table[,1]
    m
}

h2o.makeGLMModel <- function(model,beta) {  
   cat("beta =",beta,",",paste("[",paste(as.vector(beta),collapse=","),"]"))
   res = .h2o.__remoteSend(model@conn, method="POST", .h2o.__GLMMakeModel, model=model@key, names = paste("[",paste(paste("\"",names(beta),"\"",sep=""), collapse=","),"]",sep=""), beta = paste("[",paste(as.vector(beta),collapse=","),"]",sep=""))   
   m <- h2o.getModel(key=res$key$name) 
   m@model$coefficients <- m@model$coefficients_table[,2]
   names(m@model$coefficients) <- m@model$coefficients_table[,1]
   m
}
