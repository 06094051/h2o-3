#' Gradient Boosted Machines
#'
#' Builds gradient boosted classification trees, and gradient boosted regression trees on a parsed data set.
#'
#' This function will not convert response column to valid types. In order to
#' run properly the response column must be an numeric for "gaussian" or an
#' enum for "bernoulli" or "multinomial".
#'
#' @param x A vector containing the names or indices of the predictor variables to use in building the GBM model.
#' @param y The name or index of the response variable. If the data does not contain a header, this is the column index
#'        number starting at 0, and increasing from left to right. (The response must be either an integer or a
#'        categorical variable).
#' @param training_frame An \code{\linkS4class{H2OFrame}} object containing the variables in the model.
#' @param destination_key (Optional) The unique hex key assigned to the resulting model. If
#'        none is given, a key will automatically be generated.
#' @param loss A \code{character} string. The loss function to be implemented.
#'        Must be "bernoulli" or "multinomial" (enum response), or "gaussian"
#'        (numeric response).
#' @param ntrees A nonnegative integer that determines the number of trees to grow.
#' @param max_depth Maximum depth to grow the tree.
#' @param min_rows Minimum number of rows to assign to teminal nodes.
#' @param learn_rate An \code{interger} from \code{0.0} to \code{1.0}
#' @param nbins Number of bins to use in building histogram.
#' @param validation_frame An \code{\link{H2OFrame}} object indicating the validation dataset used to contruct the
#'        confusion matrix. If left blank, this defaults to the training data when \code{nfolds = 0}
#' @param balance_classes logical, indicates whether or not to balance training data class
#'        counts via over/under-sampling (for imbalanced data)
#' @param max_after_balance_size Maximum relative size of the training data after balancing class counts (can be less
#'        than 1.0)
#' @param seed Seed for random numbers (affects sampling) - Note: only reproducible when running single threaded
#' @param nfolds (Optional) Number of folds for cross-validation. If \code{nfolds >= 2}, then \code{validation} must remain empty. **Currently not supported**
#' @param score_each_iteration Attempts to score each tree.
#' @seealso \code{\link{predict.H2OGBMModel}} for prediction.
#' @examples
#' library(h2o)
#' localH2O = h2o.init()
#'
#' # Run regression GBM on australia.hex data
#' ausPath <- system.file("extdata", "australia.csv", package="h2o")
#' australia.hex <- h2o.uploadFile(localH2O, path = ausPath)
#' independent <- c("premax", "salmax","minairtemp", "maxairtemp", "maxsst",
#'                  "maxsoilmoist", "Max_czcs")
#' dependent <- "runoffnew"
#' h2o.gbm(y = dependent, x = independent, training_frame = australia.hex,
#'         ntrees = 3, max_depth = 3, min_rows = 2)
#' @export
h2o.gbm <- function(x, y, training_frame, ...,
                    #AUTOGENERATED params
                    destination_key,
                    loss = c("gaussian", "bernoulli", "multinomial"),
                    ntrees = 50,
                    max_depth = 5,
                    min_rows = 10,
                    learn_rate = 0.1,
                    nbins = 20,
                    validation_frame = NULL,
                    balance_classes = FALSE,
                    max_after_balance_size = 1,
                    seed,
                    score_each_iteration)
{
  dots <- list(...)

  for(type in names(dots))
    if (is.environment(dots[[type]]))
    {
    dots$envir <- type
    type <- NULL
    } else {
      stop(paste0("\n  unused argument (", type, " = ", deparse(dots[[type]]), ")"))
    }
  if (is.null(dots$envir))
    dots$envir <- parent.frame()

  # Required args: x, y, training_frame
  if( missing(x) ) stop("`x` is missing, with no default")
  if( missing(y) ) stop("`y` is missing, with no default")
  if( missing(training_frame) ) stop("`training_frame` is missing, with no default")

  # Training_frame may be a key or an H2OFrame object
  if (!inherits(training_frame, "H2OFrame"))
    tryCatch(training_frame <- h2o.getFrame(training_frame),
             error = function(err) {
               stop("argument \"training_frame\" must be a valid H2OFrame or key")
             })

  if (!is.null(validation_frame)) {
    if (!inherits(validation_frame, "H2OFrame"))
        tryCatch(validation_frame <- h2o.getFrame(validation_frame),
                 error = function(err) {
                   stop("argument \"validation_frame\" must be a valid H2OFrame or key")
                 })
  }

  #required map for params with different names, assuming it will change in the RESTAPI end
  .gbm.map <- c("x" = "ignored_columns",
                "y" = "response_column",
                "key" = "destination_key")

  parms <- as.list(match.call(expand.dots = FALSE)[-1L])
  parms$... <- NULL

  args <- .verify_dataxy(training_frame, x, y)
  parms$x <- args$x_ignore
  parms$y <- args$y

  names(parms) <- lapply(names(parms), function(i) { if( i %in% names(.gbm.map) ) i <- .gbm.map[[i]]; i })

  .h2o.createModel(training_frame@conn, 'gbm', parms, dots$envir )
}

# Function call for R sided cross validation of h2o objects
#' @export
h2o.gbm.cv <- function(x, y, training_frame, nfolds = 2,
           #AUTOGENERATED params
           key,
           loss = c("bernoulli"),
           ntrees = 50,
           max_depth = 5,
           min_rows = 10,
           learn_rate = 0.1,
           nbins = 20,
           variable_importance = FALSE,
           balance_classes = FALSE,
           max_after_balance_size = 1,
           seed
           )
{
  env <- parent.frame()
  parms <- lapply(as.list(match.call()[-1L]), eval, env)
  parms$nfolds <- NULL

  do.call("h2o.crossValidate", list(model.type = 'gbm', nfolds = nfolds, params = parms, envir = env))
}
