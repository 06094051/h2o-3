//
// H2O Scala Module
//
description = "H2O Scala API (Scala version ${scalaVersion})"

dependencies {
  compile project(":h2o-core")
  compile project(":h2o-algos")
  compile "org.scala-lang:scala-library:$scalaVersion"
  
  testCompile project(path: ":h2o-core", configuration: "testArchives")
  testCompile "junit:junit:${junitVersion}"
  testCompile "org.scalatest:scalatest_${scalaBaseVersion}:2.2.1"
  testRuntime 'org.pegdown:pegdown:1.4.2'
}

task scalaTest(dependsOn: ['testClasses'], type: JavaExec) {
  main = 'org.scalatest.tools.Runner'
  args = ['-R', 'build/classes/test', '-o']
  classpath = sourceSets.test.runtimeClasspath
}

compileScala {
    scalaCompileOptions.additionalParameters = [
            "-feature",
            "-language:reflectiveCalls", // used for config structural typing
            "-language:postfixOps",
            "-language:implicitConversions"
    ]
}
// The default 'test' behavior is broken in that it does not grok clusters.
// For H2O, all tests need to be run on a cluster, where each JVM is
// "free-running" - it's stdout/stderr are NOT hooked by another process.  If
// they are hooked (e.g., by the gradle driver process) then the stdout/err get
// buffered and when all CPUs are maxed out (happens over a large fraction of
// the test run) no output is visible.  If the JVMs then crash (again, common
// enough), we get NO output for the test run.  So instead we need to arrange a
// complete cluster of free-running JVMs and redirect all output (at the OS
// level) to files - then scrape the files later for test results.
test {
  dependsOn cpLibs, testMultiNode, testJar

  // Defeat task 'test' by running no tests.
  exclude '**'
}

artifacts {
    toPublish scaladocJar
}
