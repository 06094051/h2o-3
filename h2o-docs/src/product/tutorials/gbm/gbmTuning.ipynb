{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# H2O GBM Tuning Tutorial for Python\n",
    "### Navdeep Gill, M.S., Hacker/Data Scientist, H2O.ai\n",
    "\n",
    "In this tutorial, we show how to build a well-tuned H2O GBM model for a supervised classification task. We specifically don't focus on feature engineering and use a small dataset to allow you to reproduce these results in a few minutes on a laptop. This script can be directly transferred to datasets that are hundreds of GBs large and H2O clusters with dozens of compute nodes.\n",
    "\n",
    "You can download the source [from H2O's github repository](https://github.com/h2oai/h2o-3/blob/master/h2o-docs/src/product/tutorials/gbm/gbmTuning.ipynb).\n",
    "\n",
    "## Installation of the H2O Python Package\n",
    "Either download H2O from [H2O.ai's website](http://h2o.ai/download) or install the latest version of H2O into Python with the following set of commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Install dependencies from command line (prepending with `sudo` if needed):\n",
    "[sudo] pip install -U requests\n",
    "[sudo] pip install -U tabulate\n",
    "[sudo] pip install -U future\n",
    "[sudo] pip install -U six\n",
    "\n",
    "# The following command removes the H2O module for Python.\n",
    "[sudo] pip uninstall h2o\n",
    "# Next, use pip to install this version of the H2O Python module.\n",
    "[sudo] pip install http://h2o-release.s3.amazonaws.com/h2o/rel-turchin/6/Python/h2o-3.8.2.6-py2.py3-none-any.whl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Launch an H2O cluster on localhost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "No instance found at ip and port: localhost:54321. Trying to start local jar...\n",
      "\n",
      "\n",
      "JVM stdout: /var/folders/55/rj4cny_s29q4vn1wjt_x08sm0000gn/T/tmpDuptFg/h2o_navdeepgill_started_from_python.out\n",
      "JVM stderr: /var/folders/55/rj4cny_s29q4vn1wjt_x08sm0000gn/T/tmpW95XBX/h2o_navdeepgill_started_from_python.err\n",
      "Using ice_root: /var/folders/55/rj4cny_s29q4vn1wjt_x08sm0000gn/T/tmpos3v9A\n",
      "\n",
      "\n",
      "Java Version: java version \"1.7.0_79\"\n",
      "Java(TM) SE Runtime Environment (build 1.7.0_79-b15)\n",
      "Java HotSpot(TM) 64-Bit Server VM (build 24.79-b02, mixed mode)\n",
      "\n",
      "\n",
      "Starting H2O JVM and connecting: ................ Connection successful!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime: </td>\n",
       "<td>1 seconds 832 milliseconds </td></tr>\n",
       "<tr><td>H2O cluster version: </td>\n",
       "<td>3.8.2.6</td></tr>\n",
       "<tr><td>H2O cluster name: </td>\n",
       "<td>H2O_started_from_python_navdeepgill_btt708</td></tr>\n",
       "<tr><td>H2O cluster total nodes: </td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster total free memory: </td>\n",
       "<td>3.56 GB</td></tr>\n",
       "<tr><td>H2O cluster total cores: </td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O cluster allowed cores: </td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O cluster healthy: </td>\n",
       "<td>True</td></tr>\n",
       "<tr><td>H2O Connection ip: </td>\n",
       "<td>127.0.0.1</td></tr>\n",
       "<tr><td>H2O Connection port: </td>\n",
       "<td>54321</td></tr>\n",
       "<tr><td>H2O Connection proxy: </td>\n",
       "<td>None</td></tr>\n",
       "<tr><td>Python Version: </td>\n",
       "<td>2.7.11</td></tr></table></div>"
      ],
      "text/plain": [
       "------------------------------  ------------------------------------------\n",
       "H2O cluster uptime:             1 seconds 832 milliseconds\n",
       "H2O cluster version:            3.8.2.6\n",
       "H2O cluster name:               H2O_started_from_python_navdeepgill_btt708\n",
       "H2O cluster total nodes:        1\n",
       "H2O cluster total free memory:  3.56 GB\n",
       "H2O cluster total cores:        8\n",
       "H2O cluster allowed cores:      8\n",
       "H2O cluster healthy:            True\n",
       "H2O Connection ip:              127.0.0.1\n",
       "H2O Connection port:            54321\n",
       "H2O Connection proxy:\n",
       "Python Version:                 2.7.11\n",
       "------------------------------  ------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import h2o\n",
    "import numpy as np\n",
    "import math\n",
    "h2o.init(nthreads=-1,strict_version_check=False)\n",
    "## optional: connect to a running H2O cluster\n",
    "#h2o.init(ip=\"mycluster\", port=55555) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Import the data into H2O \n",
    "Everything is scalable and distributed from now on. All processing is done on the fully multi-threaded and distributed H2O Java-based backend and can be scaled to large datasets on large compute clusters.\n",
    "Here, we use a small public dataset ([Titanic](https://stat.ethz.ch/R-manual/R-devel/library/datasets/html/Titanic.html)), but you can use datasets that are hundreds of GBs large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Parse Progress: [##################################################] 100%\n",
      "[1309, 14]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th style=\"text-align: right;\">  pclass</th><th style=\"text-align: right;\">  survived</th><th>name                                           </th><th>sex   </th><th style=\"text-align: right;\">    age</th><th style=\"text-align: right;\">  sibsp</th><th style=\"text-align: right;\">  parch</th><th style=\"text-align: right;\">  ticket</th><th style=\"text-align: right;\">    fare</th><th>cabin  </th><th>embarked  </th><th style=\"text-align: right;\">  boat</th><th style=\"text-align: right;\">  body</th><th>home.dest                      </th></tr>\n",
       "<tr><td style=\"text-align: right;\">       1</td><td style=\"text-align: right;\">         1</td><td>Allen  Miss. Elisabeth Walton                  </td><td>female</td><td style=\"text-align: right;\">29     </td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">   24160</td><td style=\"text-align: right;\">211.338 </td><td>B5     </td><td>S         </td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">   nan</td><td>St Louis  MO                   </td></tr>\n",
       "<tr><td style=\"text-align: right;\">       1</td><td style=\"text-align: right;\">         1</td><td>Allison  Master. Hudson Trevor                 </td><td>male  </td><td style=\"text-align: right;\"> 0.9167</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">  113781</td><td style=\"text-align: right;\">151.55  </td><td>C22 C26</td><td>S         </td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">   nan</td><td>Montreal  PQ / Chesterville  ON</td></tr>\n",
       "<tr><td style=\"text-align: right;\">       1</td><td style=\"text-align: right;\">         0</td><td>Allison  Miss. Helen Loraine                   </td><td>female</td><td style=\"text-align: right;\"> 2     </td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">  113781</td><td style=\"text-align: right;\">151.55  </td><td>C22 C26</td><td>S         </td><td style=\"text-align: right;\">   nan</td><td style=\"text-align: right;\">   nan</td><td>Montreal  PQ / Chesterville  ON</td></tr>\n",
       "<tr><td style=\"text-align: right;\">       1</td><td style=\"text-align: right;\">         0</td><td>Allison  Mr. Hudson Joshua Creighton           </td><td>male  </td><td style=\"text-align: right;\">30     </td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">  113781</td><td style=\"text-align: right;\">151.55  </td><td>C22 C26</td><td>S         </td><td style=\"text-align: right;\">   nan</td><td style=\"text-align: right;\">   135</td><td>Montreal  PQ / Chesterville  ON</td></tr>\n",
       "<tr><td style=\"text-align: right;\">       1</td><td style=\"text-align: right;\">         0</td><td>Allison  Mrs. Hudson J C (Bessie Waldo Daniels)</td><td>female</td><td style=\"text-align: right;\">25     </td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">  113781</td><td style=\"text-align: right;\">151.55  </td><td>C22 C26</td><td>S         </td><td style=\"text-align: right;\">   nan</td><td style=\"text-align: right;\">   nan</td><td>Montreal  PQ / Chesterville  ON</td></tr>\n",
       "<tr><td style=\"text-align: right;\">       1</td><td style=\"text-align: right;\">         1</td><td>Anderson  Mr. Harry                            </td><td>male  </td><td style=\"text-align: right;\">48     </td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">   19952</td><td style=\"text-align: right;\"> 26.55  </td><td>E12    </td><td>S         </td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">   nan</td><td>New York  NY                   </td></tr>\n",
       "<tr><td style=\"text-align: right;\">       1</td><td style=\"text-align: right;\">         1</td><td>Andrews  Miss. Kornelia Theodosia              </td><td>female</td><td style=\"text-align: right;\">63     </td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">   13502</td><td style=\"text-align: right;\"> 77.9583</td><td>D7     </td><td>S         </td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">   nan</td><td>Hudson  NY                     </td></tr>\n",
       "<tr><td style=\"text-align: right;\">       1</td><td style=\"text-align: right;\">         0</td><td>Andrews  Mr. Thomas Jr                         </td><td>male  </td><td style=\"text-align: right;\">39     </td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">  112050</td><td style=\"text-align: right;\">  0     </td><td>A36    </td><td>S         </td><td style=\"text-align: right;\">   nan</td><td style=\"text-align: right;\">   nan</td><td>Belfast  NI                    </td></tr>\n",
       "<tr><td style=\"text-align: right;\">       1</td><td style=\"text-align: right;\">         1</td><td>Appleton  Mrs. Edward Dale (Charlotte Lamson)  </td><td>female</td><td style=\"text-align: right;\">53     </td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">   11769</td><td style=\"text-align: right;\"> 51.4792</td><td>C101   </td><td>S         </td><td style=\"text-align: right;\">   nan</td><td style=\"text-align: right;\">   nan</td><td>Bayside  Queens  NY            </td></tr>\n",
       "<tr><td style=\"text-align: right;\">       1</td><td style=\"text-align: right;\">         0</td><td>Artagaveytia  Mr. Ramon                        </td><td>male  </td><td style=\"text-align: right;\">71     </td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">     nan</td><td style=\"text-align: right;\"> 49.5042</td><td>       </td><td>C         </td><td style=\"text-align: right;\">   nan</td><td style=\"text-align: right;\">    22</td><td>Montevideo  Uruguay            </td></tr>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method H2OFrame.head of >\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th style=\"text-align: right;\">  pclass</th><th style=\"text-align: right;\">  survived</th><th>name                                           </th><th>sex   </th><th style=\"text-align: right;\">    age</th><th style=\"text-align: right;\">  sibsp</th><th style=\"text-align: right;\">  parch</th><th style=\"text-align: right;\">  ticket</th><th style=\"text-align: right;\">    fare</th><th>cabin  </th><th>embarked  </th><th style=\"text-align: right;\">  boat</th><th style=\"text-align: right;\">  body</th><th>home.dest                      </th></tr>\n",
       "<tr><td style=\"text-align: right;\">       1</td><td style=\"text-align: right;\">         1</td><td>Allen  Miss. Elisabeth Walton                  </td><td>female</td><td style=\"text-align: right;\">29     </td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">   24160</td><td style=\"text-align: right;\">211.338 </td><td>B5     </td><td>S         </td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">   nan</td><td>St Louis  MO                   </td></tr>\n",
       "<tr><td style=\"text-align: right;\">       1</td><td style=\"text-align: right;\">         1</td><td>Allison  Master. Hudson Trevor                 </td><td>male  </td><td style=\"text-align: right;\"> 0.9167</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">  113781</td><td style=\"text-align: right;\">151.55  </td><td>C22 C26</td><td>S         </td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">   nan</td><td>Montreal  PQ / Chesterville  ON</td></tr>\n",
       "<tr><td style=\"text-align: right;\">       1</td><td style=\"text-align: right;\">         0</td><td>Allison  Miss. Helen Loraine                   </td><td>female</td><td style=\"text-align: right;\"> 2     </td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">  113781</td><td style=\"text-align: right;\">151.55  </td><td>C22 C26</td><td>S         </td><td style=\"text-align: right;\">   nan</td><td style=\"text-align: right;\">   nan</td><td>Montreal  PQ / Chesterville  ON</td></tr>\n",
       "<tr><td style=\"text-align: right;\">       1</td><td style=\"text-align: right;\">         0</td><td>Allison  Mr. Hudson Joshua Creighton           </td><td>male  </td><td style=\"text-align: right;\">30     </td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">  113781</td><td style=\"text-align: right;\">151.55  </td><td>C22 C26</td><td>S         </td><td style=\"text-align: right;\">   nan</td><td style=\"text-align: right;\">   135</td><td>Montreal  PQ / Chesterville  ON</td></tr>\n",
       "<tr><td style=\"text-align: right;\">       1</td><td style=\"text-align: right;\">         0</td><td>Allison  Mrs. Hudson J C (Bessie Waldo Daniels)</td><td>female</td><td style=\"text-align: right;\">25     </td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">  113781</td><td style=\"text-align: right;\">151.55  </td><td>C22 C26</td><td>S         </td><td style=\"text-align: right;\">   nan</td><td style=\"text-align: right;\">   nan</td><td>Montreal  PQ / Chesterville  ON</td></tr>\n",
       "<tr><td style=\"text-align: right;\">       1</td><td style=\"text-align: right;\">         1</td><td>Anderson  Mr. Harry                            </td><td>male  </td><td style=\"text-align: right;\">48     </td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">   19952</td><td style=\"text-align: right;\"> 26.55  </td><td>E12    </td><td>S         </td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">   nan</td><td>New York  NY                   </td></tr>\n",
       "<tr><td style=\"text-align: right;\">       1</td><td style=\"text-align: right;\">         1</td><td>Andrews  Miss. Kornelia Theodosia              </td><td>female</td><td style=\"text-align: right;\">63     </td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">   13502</td><td style=\"text-align: right;\"> 77.9583</td><td>D7     </td><td>S         </td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">   nan</td><td>Hudson  NY                     </td></tr>\n",
       "<tr><td style=\"text-align: right;\">       1</td><td style=\"text-align: right;\">         0</td><td>Andrews  Mr. Thomas Jr                         </td><td>male  </td><td style=\"text-align: right;\">39     </td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">  112050</td><td style=\"text-align: right;\">  0     </td><td>A36    </td><td>S         </td><td style=\"text-align: right;\">   nan</td><td style=\"text-align: right;\">   nan</td><td>Belfast  NI                    </td></tr>\n",
       "<tr><td style=\"text-align: right;\">       1</td><td style=\"text-align: right;\">         1</td><td>Appleton  Mrs. Edward Dale (Charlotte Lamson)  </td><td>female</td><td style=\"text-align: right;\">53     </td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">   11769</td><td style=\"text-align: right;\"> 51.4792</td><td>C101   </td><td>S         </td><td style=\"text-align: right;\">   nan</td><td style=\"text-align: right;\">   nan</td><td>Bayside  Queens  NY            </td></tr>\n",
       "<tr><td style=\"text-align: right;\">       1</td><td style=\"text-align: right;\">         0</td><td>Artagaveytia  Mr. Ramon                        </td><td>male  </td><td style=\"text-align: right;\">71     </td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">     nan</td><td style=\"text-align: right;\"> 49.5042</td><td>       </td><td>C         </td><td style=\"text-align: right;\">   nan</td><td style=\"text-align: right;\">    22</td><td>Montevideo  Uruguay            </td></tr>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method H2OFrame.tail of >\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th style=\"text-align: right;\">  pclass</th><th style=\"text-align: right;\">  survived</th><th>name                                           </th><th>sex   </th><th style=\"text-align: right;\">    age</th><th style=\"text-align: right;\">  sibsp</th><th style=\"text-align: right;\">  parch</th><th style=\"text-align: right;\">  ticket</th><th style=\"text-align: right;\">    fare</th><th>cabin  </th><th>embarked  </th><th style=\"text-align: right;\">  boat</th><th style=\"text-align: right;\">  body</th><th>home.dest                      </th></tr>\n",
       "<tr><td style=\"text-align: right;\">       1</td><td style=\"text-align: right;\">         1</td><td>Allen  Miss. Elisabeth Walton                  </td><td>female</td><td style=\"text-align: right;\">29     </td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">   24160</td><td style=\"text-align: right;\">211.338 </td><td>B5     </td><td>S         </td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">   nan</td><td>St Louis  MO                   </td></tr>\n",
       "<tr><td style=\"text-align: right;\">       1</td><td style=\"text-align: right;\">         1</td><td>Allison  Master. Hudson Trevor                 </td><td>male  </td><td style=\"text-align: right;\"> 0.9167</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">  113781</td><td style=\"text-align: right;\">151.55  </td><td>C22 C26</td><td>S         </td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">   nan</td><td>Montreal  PQ / Chesterville  ON</td></tr>\n",
       "<tr><td style=\"text-align: right;\">       1</td><td style=\"text-align: right;\">         0</td><td>Allison  Miss. Helen Loraine                   </td><td>female</td><td style=\"text-align: right;\"> 2     </td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">  113781</td><td style=\"text-align: right;\">151.55  </td><td>C22 C26</td><td>S         </td><td style=\"text-align: right;\">   nan</td><td style=\"text-align: right;\">   nan</td><td>Montreal  PQ / Chesterville  ON</td></tr>\n",
       "<tr><td style=\"text-align: right;\">       1</td><td style=\"text-align: right;\">         0</td><td>Allison  Mr. Hudson Joshua Creighton           </td><td>male  </td><td style=\"text-align: right;\">30     </td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">  113781</td><td style=\"text-align: right;\">151.55  </td><td>C22 C26</td><td>S         </td><td style=\"text-align: right;\">   nan</td><td style=\"text-align: right;\">   135</td><td>Montreal  PQ / Chesterville  ON</td></tr>\n",
       "<tr><td style=\"text-align: right;\">       1</td><td style=\"text-align: right;\">         0</td><td>Allison  Mrs. Hudson J C (Bessie Waldo Daniels)</td><td>female</td><td style=\"text-align: right;\">25     </td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">  113781</td><td style=\"text-align: right;\">151.55  </td><td>C22 C26</td><td>S         </td><td style=\"text-align: right;\">   nan</td><td style=\"text-align: right;\">   nan</td><td>Montreal  PQ / Chesterville  ON</td></tr>\n",
       "<tr><td style=\"text-align: right;\">       1</td><td style=\"text-align: right;\">         1</td><td>Anderson  Mr. Harry                            </td><td>male  </td><td style=\"text-align: right;\">48     </td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">   19952</td><td style=\"text-align: right;\"> 26.55  </td><td>E12    </td><td>S         </td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">   nan</td><td>New York  NY                   </td></tr>\n",
       "<tr><td style=\"text-align: right;\">       1</td><td style=\"text-align: right;\">         1</td><td>Andrews  Miss. Kornelia Theodosia              </td><td>female</td><td style=\"text-align: right;\">63     </td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">   13502</td><td style=\"text-align: right;\"> 77.9583</td><td>D7     </td><td>S         </td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">   nan</td><td>Hudson  NY                     </td></tr>\n",
       "<tr><td style=\"text-align: right;\">       1</td><td style=\"text-align: right;\">         0</td><td>Andrews  Mr. Thomas Jr                         </td><td>male  </td><td style=\"text-align: right;\">39     </td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">  112050</td><td style=\"text-align: right;\">  0     </td><td>A36    </td><td>S         </td><td style=\"text-align: right;\">   nan</td><td style=\"text-align: right;\">   nan</td><td>Belfast  NI                    </td></tr>\n",
       "<tr><td style=\"text-align: right;\">       1</td><td style=\"text-align: right;\">         1</td><td>Appleton  Mrs. Edward Dale (Charlotte Lamson)  </td><td>female</td><td style=\"text-align: right;\">53     </td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">   11769</td><td style=\"text-align: right;\"> 51.4792</td><td>C101   </td><td>S         </td><td style=\"text-align: right;\">   nan</td><td style=\"text-align: right;\">   nan</td><td>Bayside  Queens  NY            </td></tr>\n",
       "<tr><td style=\"text-align: right;\">       1</td><td style=\"text-align: right;\">         0</td><td>Artagaveytia  Mr. Ramon                        </td><td>male  </td><td style=\"text-align: right;\">71     </td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">     nan</td><td style=\"text-align: right;\"> 49.5042</td><td>       </td><td>C         </td><td style=\"text-align: right;\">   nan</td><td style=\"text-align: right;\">    22</td><td>Montevideo  Uruguay            </td></tr>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method H2OFrame.describe of >\n",
      "[u'pclass', u'sex', u'age', u'sibsp', u'parch', u'ticket', u'fare', u'cabin', u'embarked', u'boat', u'body', u'home.dest']\n"
     ]
    }
   ],
   "source": [
    "## 'path' can point to a local file, hdfs, s3, nfs, Hive, directories, etc.\n",
    "df = h2o.import_file(path = \"http://s3.amazonaws.com/h2o-public-test-data/smalldata/gbm_test/titanic.csv\")\n",
    "print df.dim\n",
    "print df.head\n",
    "print df.tail\n",
    "print df.describe\n",
    "\n",
    "## pick a response for the supervised problem\n",
    "response = \"survived\"\n",
    "\n",
    "## the response variable is an integer, we will turn it into a categorical/factor for binary classification\n",
    "df[response] = df[response].asfactor()           \n",
    "\n",
    "## use all other columns (except for the name & the response column (\"survived\")) as predictors\n",
    "predictors = df.columns\n",
    "del predictors[1:3]\n",
    "print predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From now on, everything is generic and directly applies to most datasets. We assume that all feature engineering is done at this stage and focus on model tuning. For multi-class problems, you can use `h2o.logloss()` or `h2o.confusion_matrix()` instead of `h2o.auc()` and for regression problems, you can use `h2o.mean_residual_deviance()` or `h2o.mse()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data for Machine Learning\n",
    "We split the data into three pieces: 60% for training, 20% for validation, 20% for final testing. \n",
    "Here, we use random splitting, but this assumes i.i.d. data. If this is not the case (e.g., when events span across multiple rows or data has a time structure), you'll have to sample your data non-randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train, valid, test = df.split_frame(ratios=[0.6,0.2], seed=1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Establish baseline performance\n",
    "As the first step, we'll build some default models to see what accuracy we can expect. Let's use the [AUC metric](http://mlwiki.org/index.php/ROC_Analysis) for this demo, but you can use `h2o.logloss()` and `stopping_metric=\"logloss\"` as well. It ranges from 0.5 for random models to 1 for perfect models.\n",
    "\n",
    "\n",
    "The first model is a default GBM, trained on the 60% training split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "gbm Model Build Progress: [##################################################] 100%\n",
      "Model Details\n",
      "=============\n",
      "H2OGradientBoostingEstimator :  Gradient Boosting Method\n",
      "Model Key:  GBM_model_python_1464825551794_1\n",
      "\n",
      "Model Summary: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>number_of_trees</b></td>\n",
       "<td><b>model_size_in_bytes</b></td>\n",
       "<td><b>min_depth</b></td>\n",
       "<td><b>max_depth</b></td>\n",
       "<td><b>mean_depth</b></td>\n",
       "<td><b>min_leaves</b></td>\n",
       "<td><b>max_leaves</b></td>\n",
       "<td><b>mean_leaves</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>50.0</td>\n",
       "<td>27316.0</td>\n",
       "<td>5.0</td>\n",
       "<td>5.0</td>\n",
       "<td>5.0</td>\n",
       "<td>10.0</td>\n",
       "<td>21.0</td>\n",
       "<td>15.58</td></tr></table></div>"
      ],
      "text/plain": [
       "    number_of_trees    model_size_in_bytes    min_depth    max_depth    mean_depth    min_leaves    max_leaves    mean_leaves\n",
       "--  -----------------  ---------------------  -----------  -----------  ------------  ------------  ------------  -------------\n",
       "    50                 27316                  5            5            5             10            21            15.58"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomial: gbm\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.0347141508428\n",
      "R^2: 0.853514801928\n",
      "LogLoss: 0.135724386711\n",
      "AUC: 0.990369609999\n",
      "Gini: 0.980739219997\n",
      "\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.394257736927: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>0</b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>0</td>\n",
       "<td>461.0</td>\n",
       "<td>18.0</td>\n",
       "<td>0.0376</td>\n",
       "<td> (18.0/479.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>13.0</td>\n",
       "<td>288.0</td>\n",
       "<td>0.0432</td>\n",
       "<td> (13.0/301.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>474.0</td>\n",
       "<td>306.0</td>\n",
       "<td>0.0397</td>\n",
       "<td> (31.0/780.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       0    1    Error    Rate\n",
       "-----  ---  ---  -------  ------------\n",
       "0      461  18   0.0376   (18.0/479.0)\n",
       "1      13   288  0.0432   (13.0/301.0)\n",
       "Total  474  306  0.0397   (31.0/780.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.3942577</td>\n",
       "<td>0.9489292</td>\n",
       "<td>220.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.3942577</td>\n",
       "<td>0.9536424</td>\n",
       "<td>220.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.6059331</td>\n",
       "<td>0.9682188</td>\n",
       "<td>197.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.4073598</td>\n",
       "<td>0.9602564</td>\n",
       "<td>218.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9945845</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0608964</td>\n",
       "<td>1.0</td>\n",
       "<td>280.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9945845</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_MCC</td>\n",
       "<td>0.3942577</td>\n",
       "<td>0.9164872</td>\n",
       "<td>220.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.3942577</td>\n",
       "<td>0.9568106</td>\n",
       "<td>220.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                      threshold    value     idx\n",
       "--------------------------  -----------  --------  -----\n",
       "max f1                      0.394258     0.948929  220\n",
       "max f2                      0.394258     0.953642  220\n",
       "max f0point5                0.605933     0.968219  197\n",
       "max accuracy                0.40736      0.960256  218\n",
       "max precision               0.994584     1         0\n",
       "max recall                  0.0608964    1         280\n",
       "max specificity             0.994584     1         0\n",
       "max absolute_MCC            0.394258     0.916487  220\n",
       "max min_per_class_accuracy  0.394258     0.956811  220"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gains/Lift Table: Avg response rate: 38.59 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0102564</td>\n",
       "<td>0.9792763</td>\n",
       "<td>2.5913621</td>\n",
       "<td>2.5913621</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0265781</td>\n",
       "<td>0.0265781</td>\n",
       "<td>159.1362126</td>\n",
       "<td>159.1362126</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0205128</td>\n",
       "<td>0.9772307</td>\n",
       "<td>2.5913621</td>\n",
       "<td>2.5913621</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0265781</td>\n",
       "<td>0.0531561</td>\n",
       "<td>159.1362126</td>\n",
       "<td>159.1362126</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0307692</td>\n",
       "<td>0.9749052</td>\n",
       "<td>2.5913621</td>\n",
       "<td>2.5913621</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0265781</td>\n",
       "<td>0.0797342</td>\n",
       "<td>159.1362126</td>\n",
       "<td>159.1362126</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0410256</td>\n",
       "<td>0.9735284</td>\n",
       "<td>2.5913621</td>\n",
       "<td>2.5913621</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0265781</td>\n",
       "<td>0.1063123</td>\n",
       "<td>159.1362126</td>\n",
       "<td>159.1362126</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.0525641</td>\n",
       "<td>0.9727573</td>\n",
       "<td>2.5913621</td>\n",
       "<td>2.5913621</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0299003</td>\n",
       "<td>0.1362126</td>\n",
       "<td>159.1362126</td>\n",
       "<td>159.1362126</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1</td>\n",
       "<td>0.9705040</td>\n",
       "<td>2.5913621</td>\n",
       "<td>2.5913621</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.1229236</td>\n",
       "<td>0.2591362</td>\n",
       "<td>159.1362126</td>\n",
       "<td>159.1362126</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.15</td>\n",
       "<td>0.9690187</td>\n",
       "<td>2.5913621</td>\n",
       "<td>2.5913621</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.1295681</td>\n",
       "<td>0.3887043</td>\n",
       "<td>159.1362126</td>\n",
       "<td>159.1362126</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2</td>\n",
       "<td>0.9666881</td>\n",
       "<td>2.5913621</td>\n",
       "<td>2.5913621</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.1295681</td>\n",
       "<td>0.5182724</td>\n",
       "<td>159.1362126</td>\n",
       "<td>159.1362126</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.3</td>\n",
       "<td>0.9286900</td>\n",
       "<td>2.5913621</td>\n",
       "<td>2.5913621</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.2591362</td>\n",
       "<td>0.7774086</td>\n",
       "<td>159.1362126</td>\n",
       "<td>159.1362126</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.4</td>\n",
       "<td>0.3392288</td>\n",
       "<td>1.8272425</td>\n",
       "<td>2.4003322</td>\n",
       "<td>0.7051282</td>\n",
       "<td>0.9262821</td>\n",
       "<td>0.1827243</td>\n",
       "<td>0.9601329</td>\n",
       "<td>82.7242525</td>\n",
       "<td>140.0332226</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5115385</td>\n",
       "<td>0.1092959</td>\n",
       "<td>0.2680719</td>\n",
       "<td>1.9354033</td>\n",
       "<td>0.1034483</td>\n",
       "<td>0.7468672</td>\n",
       "<td>0.0299003</td>\n",
       "<td>0.9900332</td>\n",
       "<td>-73.1928056</td>\n",
       "<td>93.5403292</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.6333333</td>\n",
       "<td>0.0608964</td>\n",
       "<td>0.0818325</td>\n",
       "<td>1.5789474</td>\n",
       "<td>0.0315789</td>\n",
       "<td>0.6093117</td>\n",
       "<td>0.0099668</td>\n",
       "<td>1.0</td>\n",
       "<td>-91.8167512</td>\n",
       "<td>57.8947368</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.7128205</td>\n",
       "<td>0.0376842</td>\n",
       "<td>0.0</td>\n",
       "<td>1.4028777</td>\n",
       "<td>0.0</td>\n",
       "<td>0.5413669</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>40.2877698</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.8</td>\n",
       "<td>0.0257127</td>\n",
       "<td>0.0</td>\n",
       "<td>1.25</td>\n",
       "<td>0.0</td>\n",
       "<td>0.4823718</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>25.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.9320513</td>\n",
       "<td>0.0192902</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0729023</td>\n",
       "<td>0.0</td>\n",
       "<td>0.4140303</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>7.2902338</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0160264</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.3858974</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    cumulative_response_rate    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  --------------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.0102564                   0.979276           2.59136    2.59136            1                1                           0.0265781       0.0265781                  159.136   159.136\n",
       "    2        0.0205128                   0.977231           2.59136    2.59136            1                1                           0.0265781       0.0531561                  159.136   159.136\n",
       "    3        0.0307692                   0.974905           2.59136    2.59136            1                1                           0.0265781       0.0797342                  159.136   159.136\n",
       "    4        0.0410256                   0.973528           2.59136    2.59136            1                1                           0.0265781       0.106312                   159.136   159.136\n",
       "    5        0.0525641                   0.972757           2.59136    2.59136            1                1                           0.0299003       0.136213                   159.136   159.136\n",
       "    6        0.1                         0.970504           2.59136    2.59136            1                1                           0.122924        0.259136                   159.136   159.136\n",
       "    7        0.15                        0.969019           2.59136    2.59136            1                1                           0.129568        0.388704                   159.136   159.136\n",
       "    8        0.2                         0.966688           2.59136    2.59136            1                1                           0.129568        0.518272                   159.136   159.136\n",
       "    9        0.3                         0.92869            2.59136    2.59136            1                1                           0.259136        0.777409                   159.136   159.136\n",
       "    10       0.4                         0.339229           1.82724    2.40033            0.705128         0.926282                    0.182724        0.960133                   82.7243   140.033\n",
       "    11       0.511538                    0.109296           0.268072   1.9354             0.103448         0.746867                    0.0299003       0.990033                   -73.1928  93.5403\n",
       "    12       0.633333                    0.0608964          0.0818325  1.57895            0.0315789        0.609312                    0.00996678      1                          -91.8168  57.8947\n",
       "    13       0.712821                    0.0376842          0          1.40288            0                0.541367                    0               1                          -100      40.2878\n",
       "    14       0.8                         0.0257127          0          1.25               0                0.482372                    0               1                          -100      25\n",
       "    15       0.932051                    0.0192902          0          1.0729             0                0.41403                     0               1                          -100      7.29023\n",
       "    16       1                           0.0160264          0          1                  0                0.385897                    0               1                          -100      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Scoring History: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>timestamp</b></td>\n",
       "<td><b>duration</b></td>\n",
       "<td><b>number_of_trees</b></td>\n",
       "<td><b>training_MSE</b></td>\n",
       "<td><b>training_logloss</b></td>\n",
       "<td><b>training_AUC</b></td>\n",
       "<td><b>training_lift</b></td>\n",
       "<td><b>training_classification_error</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-06-01 16:59:31</td>\n",
       "<td> 0.020 sec</td>\n",
       "<td>0.0</td>\n",
       "<td>0.2369806</td>\n",
       "<td>0.6668775</td>\n",
       "<td>0.5</td>\n",
       "<td>1.0</td>\n",
       "<td>0.6141026</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-06-01 16:59:31</td>\n",
       "<td> 0.226 sec</td>\n",
       "<td>1.0</td>\n",
       "<td>0.2022753</td>\n",
       "<td>0.5942842</td>\n",
       "<td>0.9685634</td>\n",
       "<td>2.5913621</td>\n",
       "<td>0.0782051</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-06-01 16:59:31</td>\n",
       "<td> 0.333 sec</td>\n",
       "<td>2.0</td>\n",
       "<td>0.1744836</td>\n",
       "<td>0.5361788</td>\n",
       "<td>0.9760888</td>\n",
       "<td>2.5913621</td>\n",
       "<td>0.0692308</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-06-01 16:59:31</td>\n",
       "<td> 0.436 sec</td>\n",
       "<td>3.0</td>\n",
       "<td>0.1520389</td>\n",
       "<td>0.4883150</td>\n",
       "<td>0.9760888</td>\n",
       "<td>2.5913621</td>\n",
       "<td>0.0692308</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-06-01 16:59:31</td>\n",
       "<td> 0.526 sec</td>\n",
       "<td>4.0</td>\n",
       "<td>0.1335759</td>\n",
       "<td>0.4476644</td>\n",
       "<td>0.9767338</td>\n",
       "<td>2.5913621</td>\n",
       "<td>0.0692308</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-06-01 16:59:32</td>\n",
       "<td> 1.518 sec</td>\n",
       "<td>46.0</td>\n",
       "<td>0.0351867</td>\n",
       "<td>0.1373187</td>\n",
       "<td>0.9900159</td>\n",
       "<td>2.5913621</td>\n",
       "<td>0.0410256</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-06-01 16:59:32</td>\n",
       "<td> 1.535 sec</td>\n",
       "<td>47.0</td>\n",
       "<td>0.0350182</td>\n",
       "<td>0.1368714</td>\n",
       "<td>0.9901338</td>\n",
       "<td>2.5913621</td>\n",
       "<td>0.0410256</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-06-01 16:59:32</td>\n",
       "<td> 1.553 sec</td>\n",
       "<td>48.0</td>\n",
       "<td>0.0349213</td>\n",
       "<td>0.1365776</td>\n",
       "<td>0.9902794</td>\n",
       "<td>2.5913621</td>\n",
       "<td>0.0410256</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-06-01 16:59:32</td>\n",
       "<td> 1.572 sec</td>\n",
       "<td>49.0</td>\n",
       "<td>0.0347513</td>\n",
       "<td>0.1361386</td>\n",
       "<td>0.9903765</td>\n",
       "<td>2.5913621</td>\n",
       "<td>0.0397436</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-06-01 16:59:32</td>\n",
       "<td> 1.592 sec</td>\n",
       "<td>50.0</td>\n",
       "<td>0.0347142</td>\n",
       "<td>0.1357244</td>\n",
       "<td>0.9903696</td>\n",
       "<td>2.5913621</td>\n",
       "<td>0.0397436</td></tr></table></div>"
      ],
      "text/plain": [
       "     timestamp            duration    number_of_trees    training_MSE     training_logloss    training_AUC    training_lift    training_classification_error\n",
       "---  -------------------  ----------  -----------------  ---------------  ------------------  --------------  ---------------  -------------------------------\n",
       "     2016-06-01 16:59:31  0.020 sec   0.0                0.236980604865   0.66687754039       0.5             1.0              0.614102564103\n",
       "     2016-06-01 16:59:31  0.226 sec   1.0                0.20227525227    0.594284206025      0.968563383017  2.59136212625    0.0782051282051\n",
       "     2016-06-01 16:59:31  0.333 sec   2.0                0.17448358399    0.536178835173      0.976088750789  2.59136212625    0.0692307692308\n",
       "     2016-06-01 16:59:31  0.436 sec   3.0                0.152038884955   0.488314986422      0.976088750789  2.59136212625    0.0692307692308\n",
       "     2016-06-01 16:59:31  0.526 sec   4.0                0.133575857211   0.447664398007      0.976733782312  2.59136212625    0.0692307692308\n",
       "---  ---                  ---         ---                ---              ---                 ---             ---              ---\n",
       "     2016-06-01 16:59:32  1.518 sec   46.0               0.0351866688934  0.137318716441      0.990015883034  2.59136212625    0.0410256410256\n",
       "     2016-06-01 16:59:32  1.535 sec   47.0               0.0350181660315  0.136871423281      0.990133792022  2.59136212625    0.0410256410256\n",
       "     2016-06-01 16:59:32  1.553 sec   48.0               0.0349212906762  0.136577564791      0.990279444302  2.59136212625    0.0410256410256\n",
       "     2016-06-01 16:59:32  1.572 sec   49.0               0.0347513221364  0.136138626945      0.990376545822  2.59136212625    0.0397435897436\n",
       "     2016-06-01 16:59:32  1.592 sec   50.0               0.0347141508428  0.135724386711      0.990369609999  2.59136212625    0.0397435897436"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "See the whole table with table.as_data_frame()\n",
      "\n",
      "Variable Importances: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>variable</b></td>\n",
       "<td><b>relative_importance</b></td>\n",
       "<td><b>scaled_importance</b></td>\n",
       "<td><b>percentage</b></td></tr>\n",
       "<tr><td>boat</td>\n",
       "<td>608.0037231</td>\n",
       "<td>1.0</td>\n",
       "<td>0.5470799</td></tr>\n",
       "<tr><td>home.dest</td>\n",
       "<td>379.0013123</td>\n",
       "<td>0.6233536</td>\n",
       "<td>0.3410242</td></tr>\n",
       "<tr><td>cabin</td>\n",
       "<td>35.3481979</td>\n",
       "<td>0.0581381</td>\n",
       "<td>0.0318062</td></tr>\n",
       "<tr><td>sex</td>\n",
       "<td>28.0973225</td>\n",
       "<td>0.0462124</td>\n",
       "<td>0.0252819</td></tr>\n",
       "<tr><td>ticket</td>\n",
       "<td>21.2186050</td>\n",
       "<td>0.0348988</td>\n",
       "<td>0.0190924</td></tr>\n",
       "<tr><td>embarked</td>\n",
       "<td>14.9458570</td>\n",
       "<td>0.0245819</td>\n",
       "<td>0.0134482</td></tr>\n",
       "<tr><td>fare</td>\n",
       "<td>11.1052256</td>\n",
       "<td>0.0182651</td>\n",
       "<td>0.0099924</td></tr>\n",
       "<tr><td>age</td>\n",
       "<td>5.4856591</td>\n",
       "<td>0.0090224</td>\n",
       "<td>0.0049360</td></tr>\n",
       "<tr><td>parch</td>\n",
       "<td>3.7122171</td>\n",
       "<td>0.0061056</td>\n",
       "<td>0.0033402</td></tr>\n",
       "<tr><td>sibsp</td>\n",
       "<td>1.8749361</td>\n",
       "<td>0.0030838</td>\n",
       "<td>0.0016871</td></tr>\n",
       "<tr><td>body</td>\n",
       "<td>1.2949954</td>\n",
       "<td>0.0021299</td>\n",
       "<td>0.0011652</td></tr>\n",
       "<tr><td>pclass</td>\n",
       "<td>1.2737147</td>\n",
       "<td>0.0020949</td>\n",
       "<td>0.0011461</td></tr></table></div>"
      ],
      "text/plain": [
       "variable    relative_importance    scaled_importance    percentage\n",
       "----------  ---------------------  -------------------  ------------\n",
       "boat        608.004                1                    0.54708\n",
       "home.dest   379.001                0.623354             0.341024\n",
       "cabin       35.3482                0.0581381            0.0318062\n",
       "sex         28.0973                0.0462124            0.0252819\n",
       "ticket      21.2186                0.0348988            0.0190924\n",
       "embarked    14.9459                0.0245819            0.0134482\n",
       "fare        11.1052                0.0182651            0.00999245\n",
       "age         5.48566                0.00902241           0.00493598\n",
       "parch       3.71222                0.00610558           0.00334024\n",
       "sibsp       1.87494                0.00308376           0.00168706\n",
       "body        1.295                  0.00212991           0.00116523\n",
       "pclass      1.27371                0.00209491           0.00114608"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#We only provide the required parameters, everything else is default\n",
    "gbm = h2o.H2OGradientBoostingEstimator(distribution='bernoulli')\n",
    "gbm.train(x=predictors, y=response, training_frame=train)\n",
    "\n",
    "## Show a detailed model summary\n",
    "print gbm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The AUC is over 94%, so this model is highly predictive!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.943195266272\n"
     ]
    }
   ],
   "source": [
    "## Get the AUC on the validation set\n",
    "perf = gbm.model_performance(valid)\n",
    "print perf.auc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second model is another default GBM, but trained on 80% of the data (here, we combine the training and validation splits to get more training data), and cross-validated using 4 folds.\n",
    "Note that cross-validation takes longer and is not usually done for really large datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "gbm Model Build Progress: [##################################################] 100%\n",
      "Model Details\n",
      "=============\n",
      "H2OGradientBoostingEstimator :  Gradient Boosting Method\n",
      "Model Key:  GBM_model_python_1464825551794_105\n",
      "\n",
      "Model Summary: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>number_of_trees</b></td>\n",
       "<td><b>model_size_in_bytes</b></td>\n",
       "<td><b>min_depth</b></td>\n",
       "<td><b>max_depth</b></td>\n",
       "<td><b>mean_depth</b></td>\n",
       "<td><b>min_leaves</b></td>\n",
       "<td><b>max_leaves</b></td>\n",
       "<td><b>mean_leaves</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>50.0</td>\n",
       "<td>33300.0</td>\n",
       "<td>5.0</td>\n",
       "<td>5.0</td>\n",
       "<td>5.0</td>\n",
       "<td>11.0</td>\n",
       "<td>22.0</td>\n",
       "<td>18.92</td></tr></table></div>"
      ],
      "text/plain": [
       "    number_of_trees    model_size_in_bytes    min_depth    max_depth    mean_depth    min_leaves    max_leaves    mean_leaves\n",
       "--  -----------------  ---------------------  -----------  -----------  ------------  ------------  ------------  -------------\n",
       "    50                 33300                  5            5            5             11            22            18.92"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomial: gbm\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.0345774118897\n",
      "R^2: 0.853993340225\n",
      "LogLoss: 0.128413772379\n",
      "AUC: 0.989262148027\n",
      "Gini: 0.978524296053\n",
      "\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.339643844673: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>0</b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>0</td>\n",
       "<td>624.0</td>\n",
       "<td>24.0</td>\n",
       "<td>0.037</td>\n",
       "<td> (24.0/648.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>20.0</td>\n",
       "<td>386.0</td>\n",
       "<td>0.0493</td>\n",
       "<td> (20.0/406.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>644.0</td>\n",
       "<td>410.0</td>\n",
       "<td>0.0417</td>\n",
       "<td> (44.0/1054.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       0    1    Error    Rate\n",
       "-----  ---  ---  -------  -------------\n",
       "0      624  24   0.037    (24.0/648.0)\n",
       "1      20   386  0.0493   (20.0/406.0)\n",
       "Total  644  410  0.0417   (44.0/1054.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.3396438</td>\n",
       "<td>0.9460784</td>\n",
       "<td>193.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.2788154</td>\n",
       "<td>0.9512195</td>\n",
       "<td>200.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.5307025</td>\n",
       "<td>0.9714747</td>\n",
       "<td>179.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.3396438</td>\n",
       "<td>0.9582543</td>\n",
       "<td>193.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9957889</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0635094</td>\n",
       "<td>1.0</td>\n",
       "<td>252.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9957889</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_MCC</td>\n",
       "<td>0.3396438</td>\n",
       "<td>0.9120532</td>\n",
       "<td>193.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.3190823</td>\n",
       "<td>0.9532020</td>\n",
       "<td>195.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                      threshold    value     idx\n",
       "--------------------------  -----------  --------  -----\n",
       "max f1                      0.339644     0.946078  193\n",
       "max f2                      0.278815     0.95122   200\n",
       "max f0point5                0.530703     0.971475  179\n",
       "max accuracy                0.339644     0.958254  193\n",
       "max precision               0.995789     1         0\n",
       "max recall                  0.0635094    1         252\n",
       "max specificity             0.995789     1         0\n",
       "max absolute_MCC            0.339644     0.912053  193\n",
       "max min_per_class_accuracy  0.319082     0.953202  195"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gains/Lift Table: Avg response rate: 38.52 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0113852</td>\n",
       "<td>0.9955574</td>\n",
       "<td>2.5960591</td>\n",
       "<td>2.5960591</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0295567</td>\n",
       "<td>0.0295567</td>\n",
       "<td>159.6059113</td>\n",
       "<td>159.6059113</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0237192</td>\n",
       "<td>0.9954868</td>\n",
       "<td>2.5960591</td>\n",
       "<td>2.5960591</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0320197</td>\n",
       "<td>0.0615764</td>\n",
       "<td>159.6059113</td>\n",
       "<td>159.6059113</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0303605</td>\n",
       "<td>0.9952492</td>\n",
       "<td>2.5960591</td>\n",
       "<td>2.5960591</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0172414</td>\n",
       "<td>0.0788177</td>\n",
       "<td>159.6059113</td>\n",
       "<td>159.6059113</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0407970</td>\n",
       "<td>0.9949399</td>\n",
       "<td>2.5960591</td>\n",
       "<td>2.5960591</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0270936</td>\n",
       "<td>0.1059113</td>\n",
       "<td>159.6059113</td>\n",
       "<td>159.6059113</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.0502846</td>\n",
       "<td>0.9947559</td>\n",
       "<td>2.5960591</td>\n",
       "<td>2.5960591</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0246305</td>\n",
       "<td>0.1305419</td>\n",
       "<td>159.6059113</td>\n",
       "<td>159.6059113</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1005693</td>\n",
       "<td>0.9938667</td>\n",
       "<td>2.5960591</td>\n",
       "<td>2.5960591</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.1305419</td>\n",
       "<td>0.2610837</td>\n",
       "<td>159.6059113</td>\n",
       "<td>159.6059113</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.1499051</td>\n",
       "<td>0.9847828</td>\n",
       "<td>2.5960591</td>\n",
       "<td>2.5960591</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.1280788</td>\n",
       "<td>0.3891626</td>\n",
       "<td>159.6059113</td>\n",
       "<td>159.6059113</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2001898</td>\n",
       "<td>0.9803967</td>\n",
       "<td>2.5960591</td>\n",
       "<td>2.5960591</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.1305419</td>\n",
       "<td>0.5197044</td>\n",
       "<td>159.6059113</td>\n",
       "<td>159.6059113</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.2998102</td>\n",
       "<td>0.9459382</td>\n",
       "<td>2.5960591</td>\n",
       "<td>2.5960591</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.2586207</td>\n",
       "<td>0.7783251</td>\n",
       "<td>159.6059113</td>\n",
       "<td>159.6059113</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.4032258</td>\n",
       "<td>0.2904861</td>\n",
       "<td>1.7386451</td>\n",
       "<td>2.3761576</td>\n",
       "<td>0.6697248</td>\n",
       "<td>0.9152941</td>\n",
       "<td>0.1798030</td>\n",
       "<td>0.9581281</td>\n",
       "<td>73.8645094</td>\n",
       "<td>137.6157635</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5009488</td>\n",
       "<td>0.1057465</td>\n",
       "<td>0.1764312</td>\n",
       "<td>1.9470443</td>\n",
       "<td>0.0679612</td>\n",
       "<td>0.75</td>\n",
       "<td>0.0172414</td>\n",
       "<td>0.9753695</td>\n",
       "<td>-82.3568798</td>\n",
       "<td>94.7044335</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.6233397</td>\n",
       "<td>0.0687787</td>\n",
       "<td>0.1811204</td>\n",
       "<td>1.6003104</td>\n",
       "<td>0.0697674</td>\n",
       "<td>0.6164384</td>\n",
       "<td>0.0221675</td>\n",
       "<td>0.9975369</td>\n",
       "<td>-81.8879597</td>\n",
       "<td>60.0310412</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.7001898</td>\n",
       "<td>0.0415999</td>\n",
       "<td>0.0320501</td>\n",
       "<td>1.4281843</td>\n",
       "<td>0.0123457</td>\n",
       "<td>0.5501355</td>\n",
       "<td>0.0024631</td>\n",
       "<td>1.0</td>\n",
       "<td>-96.7949887</td>\n",
       "<td>42.8184282</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.8007590</td>\n",
       "<td>0.0126482</td>\n",
       "<td>0.0</td>\n",
       "<td>1.2488152</td>\n",
       "<td>0.0</td>\n",
       "<td>0.4810427</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>24.8815166</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.9051233</td>\n",
       "<td>0.0085597</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1048218</td>\n",
       "<td>0.0</td>\n",
       "<td>0.4255765</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>10.4821803</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0022015</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.3851992</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    cumulative_response_rate    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  --------------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.0113852                   0.995557           2.59606    2.59606            1                1                           0.0295567       0.0295567                  159.606   159.606\n",
       "    2        0.0237192                   0.995487           2.59606    2.59606            1                1                           0.0320197       0.0615764                  159.606   159.606\n",
       "    3        0.0303605                   0.995249           2.59606    2.59606            1                1                           0.0172414       0.0788177                  159.606   159.606\n",
       "    4        0.040797                    0.99494            2.59606    2.59606            1                1                           0.0270936       0.105911                   159.606   159.606\n",
       "    5        0.0502846                   0.994756           2.59606    2.59606            1                1                           0.0246305       0.130542                   159.606   159.606\n",
       "    6        0.100569                    0.993867           2.59606    2.59606            1                1                           0.130542        0.261084                   159.606   159.606\n",
       "    7        0.149905                    0.984783           2.59606    2.59606            1                1                           0.128079        0.389163                   159.606   159.606\n",
       "    8        0.20019                     0.980397           2.59606    2.59606            1                1                           0.130542        0.519704                   159.606   159.606\n",
       "    9        0.29981                     0.945938           2.59606    2.59606            1                1                           0.258621        0.778325                   159.606   159.606\n",
       "    10       0.403226                    0.290486           1.73865    2.37616            0.669725         0.915294                    0.179803        0.958128                   73.8645   137.616\n",
       "    11       0.500949                    0.105746           0.176431   1.94704            0.0679612        0.75                        0.0172414       0.975369                   -82.3569  94.7044\n",
       "    12       0.62334                     0.0687787          0.18112    1.60031            0.0697674        0.616438                    0.0221675       0.997537                   -81.888   60.031\n",
       "    13       0.70019                     0.0415999          0.0320501  1.42818            0.0123457        0.550136                    0.00246305      1                          -96.795   42.8184\n",
       "    14       0.800759                    0.0126482          0          1.24882            0                0.481043                    0               1                          -100      24.8815\n",
       "    15       0.905123                    0.00855973         0          1.10482            0                0.425577                    0               1                          -100      10.4822\n",
       "    16       1                           0.00220153         0          1                  0                0.385199                    0               1                          -100      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomial: gbm\n",
      "** Reported on cross-validation data. **\n",
      "\n",
      "MSE: 0.0719141389606\n",
      "R^2: 0.696335189756\n",
      "LogLoss: 0.259459936663\n",
      "AUC: 0.940343155142\n",
      "Gini: 0.880686310284\n",
      "\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.527612429749: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>0</b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>0</td>\n",
       "<td>625.0</td>\n",
       "<td>23.0</td>\n",
       "<td>0.0355</td>\n",
       "<td> (23.0/648.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>68.0</td>\n",
       "<td>338.0</td>\n",
       "<td>0.1675</td>\n",
       "<td> (68.0/406.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>693.0</td>\n",
       "<td>361.0</td>\n",
       "<td>0.0863</td>\n",
       "<td> (91.0/1054.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       0    1    Error    Rate\n",
       "-----  ---  ---  -------  -------------\n",
       "0      625  23   0.0355   (23.0/648.0)\n",
       "1      68   338  0.1675   (68.0/406.0)\n",
       "Total  693  361  0.0863   (91.0/1054.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.5276124</td>\n",
       "<td>0.8813559</td>\n",
       "<td>159.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.2332222</td>\n",
       "<td>0.8820686</td>\n",
       "<td>220.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.6511963</td>\n",
       "<td>0.9241020</td>\n",
       "<td>136.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.5333012</td>\n",
       "<td>0.9136622</td>\n",
       "<td>157.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9968387</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0055336</td>\n",
       "<td>1.0</td>\n",
       "<td>396.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9968387</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_MCC</td>\n",
       "<td>0.5333012</td>\n",
       "<td>0.8174812</td>\n",
       "<td>157.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.2692503</td>\n",
       "<td>0.8842593</td>\n",
       "<td>211.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                      threshold    value     idx\n",
       "--------------------------  -----------  --------  -----\n",
       "max f1                      0.527612     0.881356  159\n",
       "max f2                      0.233222     0.882069  220\n",
       "max f0point5                0.651196     0.924102  136\n",
       "max accuracy                0.533301     0.913662  157\n",
       "max precision               0.996839     1         0\n",
       "max recall                  0.00553361   1         396\n",
       "max specificity             0.996839     1         0\n",
       "max absolute_MCC            0.533301     0.817481  157\n",
       "max min_per_class_accuracy  0.26925      0.884259  211"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gains/Lift Table: Avg response rate: 38.52 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0104364</td>\n",
       "<td>0.9960152</td>\n",
       "<td>2.5960591</td>\n",
       "<td>2.5960591</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0270936</td>\n",
       "<td>0.0270936</td>\n",
       "<td>159.6059113</td>\n",
       "<td>159.6059113</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0218216</td>\n",
       "<td>0.9956228</td>\n",
       "<td>2.5960591</td>\n",
       "<td>2.5960591</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0295567</td>\n",
       "<td>0.0566502</td>\n",
       "<td>159.6059113</td>\n",
       "<td>159.6059113</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0303605</td>\n",
       "<td>0.9949225</td>\n",
       "<td>2.5960591</td>\n",
       "<td>2.5960591</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0221675</td>\n",
       "<td>0.0788177</td>\n",
       "<td>159.6059113</td>\n",
       "<td>159.6059113</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0407970</td>\n",
       "<td>0.9943393</td>\n",
       "<td>2.5960591</td>\n",
       "<td>2.5960591</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0270936</td>\n",
       "<td>0.1059113</td>\n",
       "<td>159.6059113</td>\n",
       "<td>159.6059113</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.0502846</td>\n",
       "<td>0.9939988</td>\n",
       "<td>2.5960591</td>\n",
       "<td>2.5960591</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0246305</td>\n",
       "<td>0.1305419</td>\n",
       "<td>159.6059113</td>\n",
       "<td>159.6059113</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1005693</td>\n",
       "<td>0.9830256</td>\n",
       "<td>2.5960591</td>\n",
       "<td>2.5960591</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.1305419</td>\n",
       "<td>0.2610837</td>\n",
       "<td>159.6059113</td>\n",
       "<td>159.6059113</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.1499051</td>\n",
       "<td>0.9735360</td>\n",
       "<td>2.5461349</td>\n",
       "<td>2.5796284</td>\n",
       "<td>0.9807692</td>\n",
       "<td>0.9936709</td>\n",
       "<td>0.1256158</td>\n",
       "<td>0.3866995</td>\n",
       "<td>154.6134900</td>\n",
       "<td>157.9628359</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2001898</td>\n",
       "<td>0.9564909</td>\n",
       "<td>2.5470769</td>\n",
       "<td>2.5714519</td>\n",
       "<td>0.9811321</td>\n",
       "<td>0.9905213</td>\n",
       "<td>0.1280788</td>\n",
       "<td>0.5147783</td>\n",
       "<td>154.7076866</td>\n",
       "<td>157.1451918</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.2998102</td>\n",
       "<td>0.7542109</td>\n",
       "<td>2.4477129</td>\n",
       "<td>2.5303361</td>\n",
       "<td>0.9428571</td>\n",
       "<td>0.9746835</td>\n",
       "<td>0.2438424</td>\n",
       "<td>0.7586207</td>\n",
       "<td>144.7712878</td>\n",
       "<td>153.0336098</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.4003795</td>\n",
       "<td>0.2965896</td>\n",
       "<td>1.2245562</td>\n",
       "<td>2.2023440</td>\n",
       "<td>0.4716981</td>\n",
       "<td>0.8483412</td>\n",
       "<td>0.1231527</td>\n",
       "<td>0.8817734</td>\n",
       "<td>22.4556186</td>\n",
       "<td>120.2343987</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5047438</td>\n",
       "<td>0.1458318</td>\n",
       "<td>0.3776086</td>\n",
       "<td>1.8250491</td>\n",
       "<td>0.1454545</td>\n",
       "<td>0.7030075</td>\n",
       "<td>0.0394089</td>\n",
       "<td>0.9211823</td>\n",
       "<td>-62.2391402</td>\n",
       "<td>82.5049076</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.5996205</td>\n",
       "<td>0.0935251</td>\n",
       "<td>0.1557635</td>\n",
       "<td>1.5609216</td>\n",
       "<td>0.06</td>\n",
       "<td>0.6012658</td>\n",
       "<td>0.0147783</td>\n",
       "<td>0.9359606</td>\n",
       "<td>-84.4236453</td>\n",
       "<td>56.0921619</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.7001898</td>\n",
       "<td>0.0597891</td>\n",
       "<td>0.2694024</td>\n",
       "<td>1.3754189</td>\n",
       "<td>0.1037736</td>\n",
       "<td>0.5298103</td>\n",
       "<td>0.0270936</td>\n",
       "<td>0.9630542</td>\n",
       "<td>-73.0597639</td>\n",
       "<td>37.5418853</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.8178368</td>\n",
       "<td>0.0457614</td>\n",
       "<td>0.0628079</td>\n",
       "<td>1.1865978</td>\n",
       "<td>0.0241935</td>\n",
       "<td>0.4570766</td>\n",
       "<td>0.0073892</td>\n",
       "<td>0.9704433</td>\n",
       "<td>-93.7192118</td>\n",
       "<td>18.6597785</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.8994307</td>\n",
       "<td>0.0281169</td>\n",
       "<td>0.2113071</td>\n",
       "<td>1.0981221</td>\n",
       "<td>0.0813953</td>\n",
       "<td>0.4229958</td>\n",
       "<td>0.0172414</td>\n",
       "<td>0.9876847</td>\n",
       "<td>-78.8692863</td>\n",
       "<td>9.8122051</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0031282</td>\n",
       "<td>0.1224556</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0471698</td>\n",
       "<td>0.3851992</td>\n",
       "<td>0.0123153</td>\n",
       "<td>1.0</td>\n",
       "<td>-87.7544381</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    cumulative_response_rate    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  --------------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.0104364                   0.996015           2.59606    2.59606            1                1                           0.0270936       0.0270936                  159.606   159.606\n",
       "    2        0.0218216                   0.995623           2.59606    2.59606            1                1                           0.0295567       0.0566502                  159.606   159.606\n",
       "    3        0.0303605                   0.994923           2.59606    2.59606            1                1                           0.0221675       0.0788177                  159.606   159.606\n",
       "    4        0.040797                    0.994339           2.59606    2.59606            1                1                           0.0270936       0.105911                   159.606   159.606\n",
       "    5        0.0502846                   0.993999           2.59606    2.59606            1                1                           0.0246305       0.130542                   159.606   159.606\n",
       "    6        0.100569                    0.983026           2.59606    2.59606            1                1                           0.130542        0.261084                   159.606   159.606\n",
       "    7        0.149905                    0.973536           2.54613    2.57963            0.980769         0.993671                    0.125616        0.3867                     154.613   157.963\n",
       "    8        0.20019                     0.956491           2.54708    2.57145            0.981132         0.990521                    0.128079        0.514778                   154.708   157.145\n",
       "    9        0.29981                     0.754211           2.44771    2.53034            0.942857         0.974684                    0.243842        0.758621                   144.771   153.034\n",
       "    10       0.40038                     0.29659            1.22456    2.20234            0.471698         0.848341                    0.123153        0.881773                   22.4556   120.234\n",
       "    11       0.504744                    0.145832           0.377609   1.82505            0.145455         0.703008                    0.0394089       0.921182                   -62.2391  82.5049\n",
       "    12       0.59962                     0.0935251          0.155764   1.56092            0.06             0.601266                    0.0147783       0.935961                   -84.4236  56.0922\n",
       "    13       0.70019                     0.0597891          0.269402   1.37542            0.103774         0.52981                     0.0270936       0.963054                   -73.0598  37.5419\n",
       "    14       0.817837                    0.0457614          0.0628079  1.1866             0.0241935        0.457077                    0.00738916      0.970443                   -93.7192  18.6598\n",
       "    15       0.899431                    0.0281169          0.211307   1.09812            0.0813953        0.422996                    0.0172414       0.987685                   -78.8693  9.81221\n",
       "    16       1                           0.00312817         0.122456   1                  0.0471698        0.385199                    0.0123153       1                          -87.7544  0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Cross-Validation Metrics Summary: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>mean</b></td>\n",
       "<td><b>sd</b></td>\n",
       "<td><b>cv_1_valid</b></td>\n",
       "<td><b>cv_2_valid</b></td>\n",
       "<td><b>cv_3_valid</b></td>\n",
       "<td><b>cv_4_valid</b></td></tr>\n",
       "<tr><td>F0point5</td>\n",
       "<td>0.9127705</td>\n",
       "<td>0.0107794</td>\n",
       "<td>0.9204546</td>\n",
       "<td>0.9183673</td>\n",
       "<td>0.8867521</td>\n",
       "<td>0.9255079</td></tr>\n",
       "<tr><td>F1</td>\n",
       "<td>0.8876407</td>\n",
       "<td>0.0054374</td>\n",
       "<td>0.8756757</td>\n",
       "<td>0.8959276</td>\n",
       "<td>0.8924731</td>\n",
       "<td>0.8864865</td></tr>\n",
       "<tr><td>F2</td>\n",
       "<td>0.8646252</td>\n",
       "<td>0.0169603</td>\n",
       "<td>0.8350515</td>\n",
       "<td>0.8745583</td>\n",
       "<td>0.8982684</td>\n",
       "<td>0.8506224</td></tr>\n",
       "<tr><td>accuracy</td>\n",
       "<td>0.9174827</td>\n",
       "<td>0.0030382</td>\n",
       "<td>0.9151291</td>\n",
       "<td>0.9118774</td>\n",
       "<td>0.9230769</td>\n",
       "<td>0.9198473</td></tr>\n",
       "<tr><td>auc</td>\n",
       "<td>0.9432912</td>\n",
       "<td>0.0077477</td>\n",
       "<td>0.9298538</td>\n",
       "<td>0.9361525</td>\n",
       "<td>0.9578804</td>\n",
       "<td>0.9492781</td></tr>\n",
       "<tr><td>err</td>\n",
       "<td>0.0825173</td>\n",
       "<td>0.0030382</td>\n",
       "<td>0.0848708</td>\n",
       "<td>0.0881226</td>\n",
       "<td>0.0769231</td>\n",
       "<td>0.0801527</td></tr>\n",
       "<tr><td>err_count</td>\n",
       "<td>21.75</td>\n",
       "<td>0.9185587</td>\n",
       "<td>23.0</td>\n",
       "<td>23.0</td>\n",
       "<td>20.0</td>\n",
       "<td>21.0</td></tr>\n",
       "<tr><td>lift_top_group</td>\n",
       "<td>2.6130292</td>\n",
       "<td>0.1474290</td>\n",
       "<td>2.71</td>\n",
       "<td>2.269565</td>\n",
       "<td>2.826087</td>\n",
       "<td>2.6464646</td></tr>\n",
       "<tr><td>logloss</td>\n",
       "<td>0.2594696</td>\n",
       "<td>0.0162408</td>\n",
       "<td>0.2549429</td>\n",
       "<td>0.2922707</td>\n",
       "<td>0.2278113</td>\n",
       "<td>0.2628536</td></tr>\n",
       "<tr><td>max_per_class_error</td>\n",
       "<td>0.1496684</td>\n",
       "<td>0.0247777</td>\n",
       "<td>0.19</td>\n",
       "<td>0.1391304</td>\n",
       "<td>0.0978261</td>\n",
       "<td>0.1717172</td></tr>\n",
       "<tr><td>mcc</td>\n",
       "<td>0.8256168</td>\n",
       "<td>0.0041895</td>\n",
       "<td>0.8180702</td>\n",
       "<td>0.8217822</td>\n",
       "<td>0.8327203</td>\n",
       "<td>0.8298947</td></tr>\n",
       "<tr><td>mse</td>\n",
       "<td>0.0719055</td>\n",
       "<td>0.0039584</td>\n",
       "<td>0.0718557</td>\n",
       "<td>0.0792111</td>\n",
       "<td>0.0634998</td>\n",
       "<td>0.0730556</td></tr>\n",
       "<tr><td>precision</td>\n",
       "<td>0.9308426</td>\n",
       "<td>0.0203158</td>\n",
       "<td>0.9529412</td>\n",
       "<td>0.9339623</td>\n",
       "<td>0.8829787</td>\n",
       "<td>0.9534883</td></tr>\n",
       "<tr><td>r2</td>\n",
       "<td>0.6953803</td>\n",
       "<td>0.0114978</td>\n",
       "<td>0.6913945</td>\n",
       "<td>0.6786216</td>\n",
       "<td>0.7222706</td>\n",
       "<td>0.6892343</td></tr>\n",
       "<tr><td>recall</td>\n",
       "<td>0.8503316</td>\n",
       "<td>0.0247777</td>\n",
       "<td>0.81</td>\n",
       "<td>0.8608696</td>\n",
       "<td>0.9021739</td>\n",
       "<td>0.8282828</td></tr>\n",
       "<tr><td>specificity</td>\n",
       "<td>0.9596617</td>\n",
       "<td>0.0123822</td>\n",
       "<td>0.9766082</td>\n",
       "<td>0.9520548</td>\n",
       "<td>0.9345238</td>\n",
       "<td>0.9754601</td></tr></table></div>"
      ],
      "text/plain": [
       "                     mean       sd          cv_1_valid    cv_2_valid    cv_3_valid    cv_4_valid\n",
       "-------------------  ---------  ----------  ------------  ------------  ------------  ------------\n",
       "F0point5             0.912771   0.0107794   0.920455      0.918367      0.886752      0.925508\n",
       "F1                   0.887641   0.00543736  0.875676      0.895928      0.892473      0.886486\n",
       "F2                   0.864625   0.0169603   0.835052      0.874558      0.898268      0.850622\n",
       "accuracy             0.917483   0.0030382   0.915129      0.911877      0.923077      0.919847\n",
       "auc                  0.943291   0.00774769  0.929854      0.936152      0.95788       0.949278\n",
       "err                  0.0825173  0.0030382   0.0848708     0.0881226     0.0769231     0.0801527\n",
       "err_count            21.75      0.918559    23            23            20            21\n",
       "lift_top_group       2.61303    0.147429    2.71          2.26957       2.82609       2.64646\n",
       "logloss              0.25947    0.0162408   0.254943      0.292271      0.227811      0.262854\n",
       "max_per_class_error  0.149668   0.0247777   0.19          0.13913       0.0978261     0.171717\n",
       "mcc                  0.825617   0.00418952  0.81807       0.821782      0.83272       0.829895\n",
       "mse                  0.0719055  0.00395844  0.0718557     0.0792111     0.0634998     0.0730556\n",
       "precision            0.930843   0.0203158   0.952941      0.933962      0.882979      0.953488\n",
       "r2                   0.69538    0.0114978   0.691395      0.678622      0.722271      0.689234\n",
       "recall               0.850332   0.0247777   0.81          0.86087       0.902174      0.828283\n",
       "specificity          0.959662   0.0123822   0.976608      0.952055      0.934524      0.97546"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scoring History: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>timestamp</b></td>\n",
       "<td><b>duration</b></td>\n",
       "<td><b>number_of_trees</b></td>\n",
       "<td><b>training_MSE</b></td>\n",
       "<td><b>training_logloss</b></td>\n",
       "<td><b>training_AUC</b></td>\n",
       "<td><b>training_lift</b></td>\n",
       "<td><b>training_classification_error</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-06-01 16:59:45</td>\n",
       "<td> 2.076 sec</td>\n",
       "<td>0.0</td>\n",
       "<td>0.2368208</td>\n",
       "<td>0.6665521</td>\n",
       "<td>0.5</td>\n",
       "<td>1.0</td>\n",
       "<td>0.6148008</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-06-01 16:59:45</td>\n",
       "<td> 2.085 sec</td>\n",
       "<td>1.0</td>\n",
       "<td>0.2017114</td>\n",
       "<td>0.5930715</td>\n",
       "<td>0.9709850</td>\n",
       "<td>2.5960591</td>\n",
       "<td>0.0721063</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-06-01 16:59:45</td>\n",
       "<td> 2.093 sec</td>\n",
       "<td>2.0</td>\n",
       "<td>0.1736422</td>\n",
       "<td>0.5343418</td>\n",
       "<td>0.9710363</td>\n",
       "<td>2.5960591</td>\n",
       "<td>0.0721063</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-06-01 16:59:45</td>\n",
       "<td> 2.101 sec</td>\n",
       "<td>3.0</td>\n",
       "<td>0.1510759</td>\n",
       "<td>0.4861838</td>\n",
       "<td>0.9710135</td>\n",
       "<td>2.5960591</td>\n",
       "<td>0.0721063</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-06-01 16:59:45</td>\n",
       "<td> 2.109 sec</td>\n",
       "<td>4.0</td>\n",
       "<td>0.1328107</td>\n",
       "<td>0.4460070</td>\n",
       "<td>0.9765516</td>\n",
       "<td>2.5960591</td>\n",
       "<td>0.0673624</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-06-01 16:59:45</td>\n",
       "<td> 2.648 sec</td>\n",
       "<td>46.0</td>\n",
       "<td>0.0350350</td>\n",
       "<td>0.1309968</td>\n",
       "<td>0.9892279</td>\n",
       "<td>2.5960591</td>\n",
       "<td>0.0426945</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-06-01 16:59:45</td>\n",
       "<td> 2.664 sec</td>\n",
       "<td>47.0</td>\n",
       "<td>0.0349514</td>\n",
       "<td>0.1305076</td>\n",
       "<td>0.9892127</td>\n",
       "<td>2.5960591</td>\n",
       "<td>0.0426945</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-06-01 16:59:45</td>\n",
       "<td> 2.683 sec</td>\n",
       "<td>48.0</td>\n",
       "<td>0.0348895</td>\n",
       "<td>0.1297943</td>\n",
       "<td>0.9892089</td>\n",
       "<td>2.5960591</td>\n",
       "<td>0.0426945</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-06-01 16:59:45</td>\n",
       "<td> 2.699 sec</td>\n",
       "<td>49.0</td>\n",
       "<td>0.0347542</td>\n",
       "<td>0.1289823</td>\n",
       "<td>0.9892545</td>\n",
       "<td>2.5960591</td>\n",
       "<td>0.0417457</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-06-01 16:59:45</td>\n",
       "<td> 2.715 sec</td>\n",
       "<td>50.0</td>\n",
       "<td>0.0345774</td>\n",
       "<td>0.1284138</td>\n",
       "<td>0.9892621</td>\n",
       "<td>2.5960591</td>\n",
       "<td>0.0417457</td></tr></table></div>"
      ],
      "text/plain": [
       "     timestamp            duration    number_of_trees    training_MSE     training_logloss    training_AUC    training_lift    training_classification_error\n",
       "---  -------------------  ----------  -----------------  ---------------  ------------------  --------------  ---------------  -------------------------------\n",
       "     2016-06-01 16:59:45  2.076 sec   0.0                0.23682078573    0.666552137038      0.5             1.0              0.614800759013\n",
       "     2016-06-01 16:59:45  2.085 sec   1.0                0.201711426136   0.593071541349      0.970984993614  2.5960591133     0.0721062618596\n",
       "     2016-06-01 16:59:45  2.093 sec   2.0                0.173642235922   0.534341821003      0.971036307243  2.5960591133     0.0721062618596\n",
       "     2016-06-01 16:59:45  2.101 sec   3.0                0.151075933943   0.486183787711      0.971013501186  2.5960591133     0.0721062618596\n",
       "     2016-06-01 16:59:45  2.109 sec   4.0                0.132810689961   0.446007030976      0.976551572098  2.5960591133     0.0673624288425\n",
       "---  ---                  ---         ---                ---              ---                 ---             ---              ---\n",
       "     2016-06-01 16:59:45  2.648 sec   46.0               0.0350350415991  0.130996835085      0.989227938941  2.5960591133     0.0426944971537\n",
       "     2016-06-01 16:59:45  2.664 sec   47.0               0.0349513697965  0.130507633943      0.989212734902  2.5960591133     0.0426944971537\n",
       "     2016-06-01 16:59:45  2.683 sec   48.0               0.0348895084901  0.129794333095      0.989208933893  2.5960591133     0.0426944971537\n",
       "     2016-06-01 16:59:45  2.699 sec   49.0               0.034754175365   0.128982341188      0.989254546007  2.5960591133     0.0417457305503\n",
       "     2016-06-01 16:59:45  2.715 sec   50.0               0.0345774118897  0.128413772379      0.989262148027  2.5960591133     0.0417457305503"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "See the whole table with table.as_data_frame()\n",
      "\n",
      "Variable Importances: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>variable</b></td>\n",
       "<td><b>relative_importance</b></td>\n",
       "<td><b>scaled_importance</b></td>\n",
       "<td><b>percentage</b></td></tr>\n",
       "<tr><td>boat</td>\n",
       "<td>853.3854370</td>\n",
       "<td>1.0</td>\n",
       "<td>0.5441471</td></tr>\n",
       "<tr><td>home.dest</td>\n",
       "<td>561.1301270</td>\n",
       "<td>0.6575342</td>\n",
       "<td>0.3577953</td></tr>\n",
       "<tr><td>cabin</td>\n",
       "<td>44.6142235</td>\n",
       "<td>0.0522791</td>\n",
       "<td>0.0284475</td></tr>\n",
       "<tr><td>sex</td>\n",
       "<td>43.1090775</td>\n",
       "<td>0.0505154</td>\n",
       "<td>0.0274878</td></tr>\n",
       "<tr><td>ticket</td>\n",
       "<td>16.0098724</td>\n",
       "<td>0.0187604</td>\n",
       "<td>0.0102084</td></tr>\n",
       "<tr><td>embarked</td>\n",
       "<td>14.3029938</td>\n",
       "<td>0.0167603</td>\n",
       "<td>0.0091201</td></tr>\n",
       "<tr><td>parch</td>\n",
       "<td>10.1755810</td>\n",
       "<td>0.0119238</td>\n",
       "<td>0.0064883</td></tr>\n",
       "<tr><td>fare</td>\n",
       "<td>9.9404049</td>\n",
       "<td>0.0116482</td>\n",
       "<td>0.0063383</td></tr>\n",
       "<tr><td>age</td>\n",
       "<td>9.5454817</td>\n",
       "<td>0.0111854</td>\n",
       "<td>0.0060865</td></tr>\n",
       "<tr><td>sibsp</td>\n",
       "<td>3.3454669</td>\n",
       "<td>0.0039202</td>\n",
       "<td>0.0021332</td></tr>\n",
       "<tr><td>body</td>\n",
       "<td>2.3150084</td>\n",
       "<td>0.0027127</td>\n",
       "<td>0.0014761</td></tr>\n",
       "<tr><td>pclass</td>\n",
       "<td>0.4254822</td>\n",
       "<td>0.0004986</td>\n",
       "<td>0.0002713</td></tr></table></div>"
      ],
      "text/plain": [
       "variable    relative_importance    scaled_importance    percentage\n",
       "----------  ---------------------  -------------------  ------------\n",
       "boat        853.385                1                    0.544147\n",
       "home.dest   561.13                 0.657534             0.357795\n",
       "cabin       44.6142                0.0522791            0.0284475\n",
       "sex         43.1091                0.0505154            0.0274878\n",
       "ticket      16.0099                0.0187604            0.0102084\n",
       "embarked    14.303                 0.0167603            0.00912007\n",
       "parch       10.1756                0.0119238            0.00648829\n",
       "fare        9.9404                 0.0116482            0.00633833\n",
       "age         9.54548                0.0111854            0.00608652\n",
       "sibsp       3.34547                0.00392023           0.00213318\n",
       "body        2.31501                0.00271273           0.00147613\n",
       "pclass      0.425482               0.000498581          0.000271302"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method H2OGradientBoostingEstimator.cross_validation_metrics_summary of >\n",
      "0.989262148027\n"
     ]
    }
   ],
   "source": [
    "## rbind() makes a copy here, so it's better to use split_frame with `ratios = c(0.8)` instead above\n",
    "cv_gbm = h2o.H2OGradientBoostingEstimator(distribution='bernoulli',nfolds = 4, seed = 0xDECAF)\n",
    "cv_gbm.train(x = predictors, y = response, training_frame = train.rbind(valid))\n",
    "\n",
    "## Show a detailed summary of the cross validation metrics\n",
    "## This gives you an idea of the variance between the folds\n",
    "print cv_gbm.cross_validation_metrics_summary\n",
    "\n",
    "## Get the cross-validated AUC by scoring the combined holdout predictions.\n",
    "## (Instead of taking the average of the metrics across the folds)\n",
    "perf_cv = cv_gbm.model_performance()\n",
    "print perf_cv.auc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we train a GBM with \"I feel lucky\" parameters.\n",
    "We'll use early stopping to automatically tune the number of trees using the validation AUC. \n",
    "We'll use a lower learning rate (lower is always better, just takes more trees to converge).\n",
    "We'll also use stochastic sampling of rows and columns to (hopefully) improve generalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gbm_lucky = h2o.H2OGradientBoostingEstimator(\n",
    "  ## more trees is better if the learning rate is small enough \n",
    "  ## here, use \"more than enough\" trees - we have early stopping\n",
    "  ntrees = 10000,                                                            \n",
    "\n",
    "  ## smaller learning rate is better (this is a good value for most datasets, but see below for annealing)\n",
    "  learn_rate=0.01,                                                         \n",
    "\n",
    "  ## early stopping once the validation AUC doesn't improve by at least 0.01% for 5 consecutive scoring events\n",
    "  stopping_rounds = 5, stopping_tolerance = 1e-4, stopping_metric = \"AUC\", \n",
    "\n",
    "  ## sample 80% of rows per tree\n",
    "  sample_rate = 0.8,                                                       \n",
    "\n",
    "  ## sample 80% of columns per split\n",
    "  col_sample_rate = 0.8,                                                   \n",
    "\n",
    "  ## fix a random number generator seed for reproducibility\n",
    "  seed = 1234,                                                             \n",
    "\n",
    "  ## score every 10 trees to make early stopping reproducible (it depends on the scoring interval)\n",
    "  score_tree_interval = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "gbm Model Build Progress: [##################################################] 100%\n",
      "0.93933502395\n"
     ]
    }
   ],
   "source": [
    "gbm_lucky.train(x=predictors, y=response, training_frame=train, validation_frame=valid)\n",
    "perf_lucky = gbm_lucky.model_performance(valid)\n",
    "print perf_lucky.auc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model doesn't seem to be much better than the previous models with an AUC of ~.93."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Hyper-Parameter Search\n",
    "\n",
    "Next, we'll do real hyper-parameter optimization to see if we can beat the best AUC so far (around 94%).\n",
    "\n",
    "The key here is to start tuning some key parameters first (i.e., those that we expect to have the biggest impact on the results). From experience with gradient boosted trees across many datasets, we can state the following \"rules\":\n",
    "\n",
    "1. Build as many trees (`ntrees`) as it takes until the validation set error starts increasing.\n",
    "2. A lower learning rate (`learn_rate`) is generally better, but will require more trees. Using `learn_rate=0.02 `and `learn_rate_annealing=0.995` (reduction of learning rate with each additional tree) can help speed up convergence without sacrificing accuracy too much, and is great to hyper-parameter searches. For faster scans, use values of 0.05 and 0.99 instead.\n",
    "3. The optimum maximum allowed depth for the trees (`max_depth`) is data dependent, deeper trees take longer to train, especially at depths greater than 10.\n",
    "4. Row and column sampling (`sample_rate` and `col_sample_rate`) can improve generalization and lead to lower validation and test set errors. Good general values for large datasets are around 0.7 to 0.8 (sampling 70-80 percent of the data) for both parameters. Column sampling per tree (`col_sample_rate_per_tree`) can also be tuned. Note that it is multiplicative with `col_sample_rate`, so setting both parameters to 0.8 results in 64% of columns being considered at any given node to split.\n",
    "5. For highly imbalanced classification datasets (e.g., fewer buyers than non-buyers), stratified row sampling based on response class membership can help improve predictive accuracy.  It is configured with `sample_rate_per_class` (array of ratios, one per response class in lexicographic order).\n",
    "6. Most other options only have a small impact on the model performance, but are worth tuning with a Random hyper-parameter search nonetheless, if highest performance is critical.\n",
    "\n",
    "First we want to know what value of `max_depth` to use because it has a big impact on the model training time and optimal values depend strongly on the dataset.\n",
    "We'll do a quick Cartesian grid search to get a rough idea of good candidate `max_depth` values. Each model in the grid search will use early stopping to tune the number of trees using the validation set AUC, as before.\n",
    "We'll use learning rate annealing to speed up convergence without sacrificing too much accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "gbm Grid Build Progress: [##################################################] 100%\n"
     ]
    }
   ],
   "source": [
    "## Depth 10 is usually plenty of depth for most datasets, but you never know\n",
    "hyper_params = {'max_depth' : range(1,30,2)}\n",
    "#hyper_params = {max_depth = c(4,6,8,12,16,20)} ##faster for larger datasets\n",
    "\n",
    "#Build initial GBM Model\n",
    "gbm_grid = h2o.H2OGradientBoostingEstimator(distribution='bernoulli',\n",
    "                                    ## more trees is better if the learning rate is small enough \n",
    "                                    ## here, use \"more than enough\" trees - we have early stopping\n",
    "                                    ntrees=10000,\n",
    "                                    ## smaller learning rate is better\n",
    "                                    ## since we have learning_rate_annealing, we can afford to start with a \n",
    "                                    #bigger learning rate\n",
    "                                    learn_rate=0.05,\n",
    "                                    ## sample 80% of rows per tree\n",
    "                                    sample_rate = 0.8,\n",
    "                                    ## sample 80% of columns per split\n",
    "                                    col_sample_rate = 0.8,\n",
    "                                    ## fix a random number generator seed for reproducibility\n",
    "                                    seed = 1234,\n",
    "                                    ## score every 10 trees to make early stopping reproducible \n",
    "                                    #(it depends on the scoring interval)\n",
    "                                    score_tree_interval = 10, \n",
    "                                    ## early stopping once the validation AUC doesn't improve by at least 0.01% for \n",
    "                                    #5 consecutive scoring events\n",
    "                                    stopping_rounds = 5,\n",
    "                                    stopping_metric = \"AUC\",\n",
    "                                    stopping_tolerance = 1e-4)\n",
    "\n",
    "#Build grid search with previously made GBM and hyper parameters\n",
    "grid = h2o.H2OGridSearch(gbm_grid,hyper_params,\n",
    "                         grid_id = 'depth_grid',\n",
    "                         search_criteria = {'strategy': \"Cartesian\"})\n",
    "\n",
    "\n",
    "#Train grid search\n",
    "grid.train(x=predictors, \n",
    "           y=response,\n",
    "           ## learning rate annealing: learning_rate shrinks by 1% after every tree \n",
    "           ## (use 1.00 to disable, but then lower the learning_rate)\n",
    "           learn_rate_annealing = 0.99,\n",
    "           training_frame=train,\n",
    "           validation_frame = valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      max_depth            model_ids   logloss\n",
      "0            25  depth_grid_model_12  0.215749\n",
      "1            23  depth_grid_model_11  0.216639\n",
      "2            29  depth_grid_model_14  0.218503\n",
      "3            13   depth_grid_model_6  0.218825\n",
      "4            19   depth_grid_model_9  0.218849\n",
      "5            27  depth_grid_model_13  0.219126\n",
      "6            21  depth_grid_model_10  0.219794\n",
      "7            17   depth_grid_model_8  0.220059\n",
      "8            11   depth_grid_model_5  0.221247\n",
      "9             9   depth_grid_model_4  0.222040\n",
      "10           15   depth_grid_model_7  0.222911\n",
      "11            7   depth_grid_model_3  0.225722\n",
      "12            5   depth_grid_model_2  0.232193\n",
      "13            3   depth_grid_model_1  0.264067\n",
      "14            1   depth_grid_model_0  0.324154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## by default, display the grid search results sorted by increasing logloss (since this is a classification task)\n",
    "print grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Grid Search Results for H2OGradientBoostingEstimator: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>Model Id</b></td>\n",
       "<td><b>Hyperparameters: [max_depth]</b></td>\n",
       "<td><b>auc(valid=True)</b></td></tr>\n",
       "<tr><td>depth_grid_model_13</td>\n",
       "<td>[27]</td>\n",
       "<td>0.9565793</td></tr>\n",
       "<tr><td>depth_grid_model_12</td>\n",
       "<td>[25]</td>\n",
       "<td>0.9563539</td></tr>\n",
       "<tr><td>depth_grid_model_14</td>\n",
       "<td>[29]</td>\n",
       "<td>0.9562412</td></tr>\n",
       "<tr><td>depth_grid_model_10</td>\n",
       "<td>[21]</td>\n",
       "<td>0.9546633</td></tr>\n",
       "<tr><td>depth_grid_model_9</td>\n",
       "<td>[19]</td>\n",
       "<td>0.9544942</td></tr>\n",
       "<tr><td>depth_grid_model_6</td>\n",
       "<td>[13]</td>\n",
       "<td>0.9543815</td></tr>\n",
       "<tr><td>depth_grid_model_11</td>\n",
       "<td>[23]</td>\n",
       "<td>0.9540434</td></tr>\n",
       "<tr><td>depth_grid_model_5</td>\n",
       "<td>[11]</td>\n",
       "<td>0.9521837</td></tr>\n",
       "<tr><td>depth_grid_model_7</td>\n",
       "<td>[15]</td>\n",
       "<td>0.9517892</td></tr>\n",
       "<tr><td>depth_grid_model_8</td>\n",
       "<td>[17]</td>\n",
       "<td>0.9515075</td></tr>\n",
       "<tr><td>depth_grid_model_4</td>\n",
       "<td>[9]</td>\n",
       "<td>0.9504367</td></tr>\n",
       "<tr><td>depth_grid_model_3</td>\n",
       "<td>[7]</td>\n",
       "<td>0.9469428</td></tr>\n",
       "<tr><td>depth_grid_model_2</td>\n",
       "<td>[5]</td>\n",
       "<td>0.9393068</td></tr>\n",
       "<tr><td>depth_grid_model_1</td>\n",
       "<td>[3]</td>\n",
       "<td>0.9327134</td></tr>\n",
       "<tr><td>depth_grid_model_0</td>\n",
       "<td>[1]</td>\n",
       "<td>0.9290223</td></tr></table></div>"
      ],
      "text/plain": [
       "Model Id             Hyperparameters: [max_depth]    auc(valid=True)\n",
       "-------------------  ------------------------------  -----------------\n",
       "depth_grid_model_13  [27]                            0.956579\n",
       "depth_grid_model_12  [25]                            0.956354\n",
       "depth_grid_model_14  [29]                            0.956241\n",
       "depth_grid_model_10  [21]                            0.954663\n",
       "depth_grid_model_9   [19]                            0.954494\n",
       "depth_grid_model_6   [13]                            0.954382\n",
       "depth_grid_model_11  [23]                            0.954043\n",
       "depth_grid_model_5   [11]                            0.952184\n",
       "depth_grid_model_7   [15]                            0.951789\n",
       "depth_grid_model_8   [17]                            0.951507\n",
       "depth_grid_model_4   [9]                             0.950437\n",
       "depth_grid_model_3   [7]                             0.946943\n",
       "depth_grid_model_2   [5]                             0.939307\n",
       "depth_grid_model_1   [3]                             0.932713\n",
       "depth_grid_model_0   [1]                             0.929022"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## sort the grid models by decreasing AUC\n",
    "sorted_grid = grid.sort_by('auc(valid=True)',increasing=False)\n",
    "print(sorted_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([27], [25], [29], [21], [19])\n"
     ]
    }
   ],
   "source": [
    "# find the range of the max_depth for the top ten models\n",
    "top_depths = sorted_grid[0:5]\n",
    "max_depths = top_depths['Hyperparameters: [max_depth]']\n",
    "print max_depths\n",
    "\n",
    "# get the max depths as a list\n",
    "max_min_list = []\n",
    "for element in max_depths:\n",
    "    max_min_list.append(element[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that `max_depth` values of 19 to 29 are best suited for this dataset, which is unusally deep!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MaxDepth 29\n",
      "MinDepth 19\n"
     ]
    }
   ],
   "source": [
    "new_max = max(max_min_list)\n",
    "new_min = min(max_min_list)\n",
    "\n",
    "print \"MaxDepth\", new_max\n",
    "print \"MinDepth\", new_min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know a good range for max_depth, we can tune all other parameters in more detail. Since we don't know what combinations of hyper-parameters will result in the best model, we'll use random hyper-parameter search to \"let the machine get luckier than a best guess of any human\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create hyperameter and search criteria lists\n",
    "# variable used in the dictionary:\n",
    "log_val = math.log(train.nrow,2)-1\n",
    "\n",
    "hyper_params_tune = {'max_depth' : list(np.arange(new_min,new_max+1,1)),\n",
    "                'sample_rate': list(np.arange(0.2,1.01,0.01)),\n",
    "                'col_sample_rate' : list(np.arange(0.2,1,0.01)),\n",
    "                'col_sample_rate_per_tree': list(np.arange(0.2,1.01,0.01)),\n",
    "                'col_sample_rate_change_per_level': list(np.arange(0.9,1.10,0.01)),\n",
    "                'min_rows': list(2**np.arange(0,log_val,1)),\n",
    "                'nbins': list(2**np.arange(4,11,1)),\n",
    "                'nbins_cats': list(2**np.arange(4,13,1)),\n",
    "                'min_split_improvement': [0,1e-8,1e-6,1e-4],\n",
    "                'histogram_type': [\"UniformAdaptive\",\"QuantilesGlobal\",\"RoundRobin\"]}\n",
    "search_criteria_tune = {'strategy': \"RandomDiscrete\",\n",
    "                   'max_runtime_secs': 36000,\n",
    "                   'max_models' :50,\n",
    "                   'seed' : 1234,\n",
    "                   'stopping_rounds' : 5,\n",
    "                   'stopping_metric' : \"AUC\",\n",
    "                   }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "gbm Grid Build Progress: [##################################################] 100%\n",
      "       histogram_type  nbins_cats  sample_rate  nbins  min_rows  \\\n",
      "0     UniformAdaptive          64         0.50   1024         4   \n",
      "1          RoundRobin          64         0.73    256         4   \n",
      "2          RoundRobin          32         0.37   1024         2   \n",
      "3          RoundRobin         128         0.73     64         1   \n",
      "4     UniformAdaptive          16         0.71    256         1   \n",
      "5     UniformAdaptive          32         0.30    512        16   \n",
      "6          RoundRobin          64         0.37    128         4   \n",
      "7          RoundRobin         256         0.85     32         1   \n",
      "8          RoundRobin         128         0.94    256        16   \n",
      "9     UniformAdaptive         512         0.99   1024        32   \n",
      "10         RoundRobin        4096         0.81   1024         4   \n",
      "11    UniformAdaptive        1024         0.66    256         8   \n",
      "12         RoundRobin        2048         0.32     64         1   \n",
      "13    QuantilesGlobal          64         0.41     16         8   \n",
      "14         RoundRobin        4096         0.93   1024         2   \n",
      "15    QuantilesGlobal         512         0.53     64         2   \n",
      "16         RoundRobin         128         0.26    512       128   \n",
      "17    UniformAdaptive          32         0.75    512        32   \n",
      "18         RoundRobin        2048         0.77     32         8   \n",
      "19    UniformAdaptive        1024         0.73     32        64   \n",
      "20    UniformAdaptive        1024         0.30    128        32   \n",
      "21         RoundRobin          32         0.37    512         2   \n",
      "22    UniformAdaptive         512         0.23    512        16   \n",
      "23    QuantilesGlobal          16         0.23    512         4   \n",
      "24    QuantilesGlobal          64         0.88    256        16   \n",
      "25    QuantilesGlobal         256         0.49    512         1   \n",
      "26    UniformAdaptive        2048         0.48     32       128   \n",
      "27    QuantilesGlobal        1024         0.51    512         2   \n",
      "28         RoundRobin         256         0.82    256        32   \n",
      "29    QuantilesGlobal        1024         0.25    512         4   \n",
      "30    UniformAdaptive         256         0.83    512         4   \n",
      "31    QuantilesGlobal         256         0.22   1024         1   \n",
      "32    QuantilesGlobal          64         0.54     16       128   \n",
      "33         RoundRobin          64         0.61    256        16   \n",
      "34    QuantilesGlobal        2048         0.93     16        64   \n",
      "35    QuantilesGlobal         512         0.87    128        64   \n",
      "36    QuantilesGlobal         128         0.71    128        16   \n",
      "37    UniformAdaptive        4096         0.38     64       128   \n",
      "38    QuantilesGlobal        4096         0.98   1024       128   \n",
      "39    QuantilesGlobal          64         0.94     32        64   \n",
      "40    QuantilesGlobal        2048         0.58   1024         4   \n",
      "41    QuantilesGlobal         128         0.74    256       256   \n",
      "42    UniformAdaptive          32         0.25    512       256   \n",
      "43         RoundRobin         128         0.53     64       256   \n",
      "44    UniformAdaptive        2048         0.33     64       256   \n",
      "45    UniformAdaptive        1024         0.34     32       256   \n",
      "46    QuantilesGlobal         256         0.97    128       256   \n",
      "47    QuantilesGlobal         256         0.66    256       256   \n",
      "48    UniformAdaptive         512         0.40     32       256   \n",
      "49    QuantilesGlobal        2048         0.63    128       256   \n",
      "\n",
      "    col_sample_rate_change_per_level  min_split_improvement  max_depth  \\\n",
      "0                               1.04           1.000000e-04         25   \n",
      "1                               1.05           1.000000e-06         23   \n",
      "2                               1.08           1.000000e-06         28   \n",
      "3                               0.93           1.000000e-04         29   \n",
      "4                               0.94           1.000000e-06         20   \n",
      "5                               1.05           1.000000e-04         19   \n",
      "6                               1.09           1.000000e-06         23   \n",
      "7                               1.01           0.000000e+00         21   \n",
      "8                               1.02           1.000000e-04         24   \n",
      "9                               1.03           1.000000e-08         24   \n",
      "10                              1.02           0.000000e+00         22   \n",
      "11                              0.94           1.000000e-04         25   \n",
      "12                              1.00           1.000000e-06         21   \n",
      "13                              1.10           1.000000e-06         20   \n",
      "14                              0.92           1.000000e-04         28   \n",
      "15                              0.94           1.000000e-04         23   \n",
      "16                              1.04           0.000000e+00         26   \n",
      "17                              0.95           1.000000e-04         24   \n",
      "18                              1.10           1.000000e-06         22   \n",
      "19                              0.93           1.000000e-08         22   \n",
      "20                              1.05           1.000000e-06         22   \n",
      "21                              1.06           1.000000e-04         25   \n",
      "22                              1.07           0.000000e+00         29   \n",
      "23                              1.10           1.000000e-08         27   \n",
      "24                              0.92           1.000000e-08         25   \n",
      "25                              1.01           1.000000e-08         23   \n",
      "26                              1.07           1.000000e-06         19   \n",
      "27                              0.92           0.000000e+00         26   \n",
      "28                              0.99           1.000000e-04         24   \n",
      "29                              0.98           1.000000e-04         29   \n",
      "30                              0.96           1.000000e-06         23   \n",
      "31                              0.92           0.000000e+00         22   \n",
      "32                              0.99           1.000000e-08         19   \n",
      "33                              0.91           1.000000e-08         22   \n",
      "34                              0.98           0.000000e+00         19   \n",
      "35                              0.91           1.000000e-04         20   \n",
      "36                              1.09           0.000000e+00         19   \n",
      "37                              0.91           1.000000e-08         20   \n",
      "38                              1.08           1.000000e-06         26   \n",
      "39                              0.97           1.000000e-08         22   \n",
      "40                              0.94           1.000000e-06         20   \n",
      "41                              0.94           1.000000e-08         27   \n",
      "42                              1.01           1.000000e-06         26   \n",
      "43                              0.91           1.000000e-04         22   \n",
      "44                              1.03           1.000000e-06         23   \n",
      "45                              0.99           1.000000e-04         27   \n",
      "46                              0.97           1.000000e-04         27   \n",
      "47                              1.03           1.000000e-08         19   \n",
      "48                              0.94           1.000000e-06         20   \n",
      "49                              0.97           1.000000e-08         29   \n",
      "\n",
      "    col_sample_rate  col_sample_rate_per_tree           model_ids   logloss  \n",
      "0              0.79                      0.93  grid_tune_model_43  0.177272  \n",
      "1              0.43                      0.88  grid_tune_model_41  0.185474  \n",
      "2              0.87                      0.72   grid_tune_model_7  0.187034  \n",
      "3              0.33                      0.88  grid_tune_model_32  0.190424  \n",
      "4              0.28                      0.80  grid_tune_model_13  0.191696  \n",
      "5              0.81                      0.87   grid_tune_model_3  0.198157  \n",
      "6              0.26                      0.67  grid_tune_model_22  0.198215  \n",
      "7              0.32                      0.70  grid_tune_model_19  0.200319  \n",
      "8              0.34                      0.80   grid_tune_model_8  0.202162  \n",
      "9              0.87                      0.72   grid_tune_model_9  0.205638  \n",
      "10             0.78                      0.74  grid_tune_model_37  0.210835  \n",
      "11             0.63                      0.94  grid_tune_model_23  0.213279  \n",
      "12             0.96                      0.65  grid_tune_model_28  0.216331  \n",
      "13             0.46                      0.86  grid_tune_model_21  0.218028  \n",
      "14             0.97                      0.35  grid_tune_model_29  0.238780  \n",
      "15             0.48                      0.94  grid_tune_model_15  0.239847  \n",
      "16             0.87                      0.80  grid_tune_model_39  0.242245  \n",
      "17             0.80                      0.42  grid_tune_model_20  0.247110  \n",
      "18             0.65                      0.29  grid_tune_model_14  0.256422  \n",
      "19             0.95                      0.45  grid_tune_model_17  0.260568  \n",
      "20             0.94                      0.88   grid_tune_model_4  0.261127  \n",
      "21             0.60                      0.29  grid_tune_model_10  0.265846  \n",
      "22             0.86                      0.39  grid_tune_model_31  0.268954  \n",
      "23             0.93                      0.78  grid_tune_model_18  0.277144  \n",
      "24             0.36                      0.91   grid_tune_model_0  0.283991  \n",
      "25             0.28                      0.82   grid_tune_model_1  0.298491  \n",
      "26             0.61                      0.86  grid_tune_model_40  0.299960  \n",
      "27             0.82                      0.42  grid_tune_model_44  0.300968  \n",
      "28             0.29                      0.26  grid_tune_model_25  0.303145  \n",
      "29             0.99                      0.96  grid_tune_model_42  0.308016  \n",
      "30             0.68                      0.22  grid_tune_model_11  0.318067  \n",
      "31             0.21                      0.71  grid_tune_model_48  0.318096  \n",
      "32             0.63                      0.61  grid_tune_model_49  0.329672  \n",
      "33             0.69                      0.20  grid_tune_model_26  0.330745  \n",
      "34             0.32                      0.84   grid_tune_model_5  0.338175  \n",
      "35             0.52                      0.70   grid_tune_model_6  0.340349  \n",
      "36             0.38                      0.32  grid_tune_model_47  0.341157  \n",
      "37             0.75                      0.43  grid_tune_model_35  0.342280  \n",
      "38             0.67                      0.70   grid_tune_model_2  0.351382  \n",
      "39             0.66                      0.33  grid_tune_model_34  0.351896  \n",
      "40             0.71                      0.21  grid_tune_model_27  0.380730  \n",
      "41             0.90                      0.59  grid_tune_model_24  0.511360  \n",
      "42             0.79                      0.57  grid_tune_model_36  0.511511  \n",
      "43             0.38                      0.64  grid_tune_model_12  0.523558  \n",
      "44             0.49                      0.36  grid_tune_model_45  0.530872  \n",
      "45             0.98                      0.33  grid_tune_model_16  0.538870  \n",
      "46             0.40                      0.47  grid_tune_model_38  0.540695  \n",
      "47             0.46                      0.40  grid_tune_model_33  0.551119  \n",
      "48             0.61                      0.86  grid_tune_model_30  0.583820  \n",
      "49             0.59                      0.98  grid_tune_model_46  0.597061  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "gbm_grid_tune = h2o.H2OGradientBoostingEstimator(distribution='bernoulli',\n",
    "                                    ## more trees is better if the learning rate is small enough \n",
    "                                    ## here, use \"more than enough\" trees - we have early stopping\n",
    "                                    ntrees=10000,\n",
    "                                    ## smaller learning rate is better\n",
    "                                    ## since we have learning_rate_annealing, we can afford to start with a \n",
    "                                    #bigger learning rate\n",
    "                                    learn_rate=0.05,\n",
    "                                    ## fix a random number generator seed for reproducibility\n",
    "                                    seed = 1234,\n",
    "                                    ## score every 10 trees to make early stopping reproducible \n",
    "                                    #(it depends on the scoring interval)\n",
    "                                    score_tree_interval = 10, \n",
    "                                    ## early stopping once the validation AUC doesn't improve by at least 0.01% for \n",
    "                                    #5 consecutive scoring events\n",
    "                                    stopping_rounds = 5,\n",
    "                                    stopping_metric = \"AUC\",\n",
    "                                    stopping_tolerance = 1e-4)\n",
    "            \n",
    "#Build grid search with previously made GBM and hyper parameters\n",
    "grid_tune = h2o.H2OGridSearch(gbm_grid_tune,hyper_params = hyper_params_tune,\n",
    "                                    grid_id = 'grid_tune',\n",
    "                                    search_criteria = search_criteria_tune)\n",
    "#Train grid search\n",
    "grid_tune.train(x=predictors, \n",
    "           y=response,\n",
    "           ## learning rate annealing: learning_rate shrinks by 1% after every tree \n",
    "           ## (use 1.00 to disable, but then lower the learning_rate)\n",
    "           learn_rate_annealing = 0.99,\n",
    "           training_frame=train,\n",
    "           validation_frame = valid)\n",
    "\n",
    "print grid_tune"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the best models have even better validation AUCs than our previous best models, so the random grid search was successful!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Grid Search Results for H2OGradientBoostingEstimator: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>Model Id</b></td>\n",
       "<td><b>Hyperparameters: [nbins, col_sample_rate, min_split_improvement, col_sample_rate_per_tree, min_rows, col_sample_rate_change_per_level, nbins_cats, sample_rate, histogram_type, max_depth]</b></td>\n",
       "<td><b>auc(valid=True)</b></td></tr>\n",
       "<tr><td>grid_tune_model_32</td>\n",
       "<td>[64, 0.3300000000000001, 0.0001, 0.8800000000000006, 1.0, 0.93, 128, 0.7300000000000004, u'RoundRobin', 29]</td>\n",
       "<td>0.9703860</td></tr>\n",
       "<tr><td>grid_tune_model_41</td>\n",
       "<td>[256, 0.4300000000000002, 1e-06, 0.8800000000000006, 4.0, 1.0500000000000003, 64, 0.7300000000000004, u'RoundRobin', 23]</td>\n",
       "<td>0.9701606</td></tr>\n",
       "<tr><td>grid_tune_model_43</td>\n",
       "<td>[1024, 0.7900000000000005, 0.0001, 0.9300000000000006, 4.0, 1.04, 64, 0.5000000000000002, u'UniformAdaptive', 25]</td>\n",
       "<td>0.9699352</td></tr>\n",
       "<tr><td>grid_tune_model_8</td>\n",
       "<td>[256, 0.34000000000000014, 0.0001, 0.8000000000000005, 16.0, 1.02, 128, 0.9400000000000006, u'RoundRobin', 24]</td>\n",
       "<td>0.9686391</td></tr>\n",
       "<tr><td>grid_tune_model_19</td>\n",
       "<td>[32, 0.3200000000000001, 0.0, 0.7000000000000004, 1.0, 1.0100000000000002, 256, 0.8500000000000005, u'RoundRobin', 21]</td>\n",
       "<td>0.9683573</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td>grid_tune_model_24</td>\n",
       "<td>[256, 0.9000000000000006, 1e-08, 0.5900000000000003, 256.0, 0.9400000000000001, 128, 0.7400000000000004, u'QuantilesGlobal', 27]</td>\n",
       "<td>0.8131586</td></tr>\n",
       "<tr><td>grid_tune_model_33</td>\n",
       "<td>[256, 0.46000000000000024, 1e-08, 0.4000000000000002, 256.0, 1.0300000000000002, 256, 0.6600000000000004, u'QuantilesGlobal', 19]</td>\n",
       "<td>0.8127360</td></tr>\n",
       "<tr><td>grid_tune_model_16</td>\n",
       "<td>[32, 0.9800000000000006, 0.0001, 0.3300000000000001, 256.0, 0.9900000000000001, 1024, 0.34000000000000014, u'UniformAdaptive', 27]</td>\n",
       "<td>0.7916314</td></tr>\n",
       "<tr><td>grid_tune_model_30</td>\n",
       "<td>[32, 0.6100000000000003, 1e-06, 0.8600000000000005, 256.0, 0.9400000000000001, 512, 0.4000000000000002, u'UniformAdaptive', 20]</td>\n",
       "<td>0.7570583</td></tr>\n",
       "<tr><td>grid_tune_model_46</td>\n",
       "<td>[128, 0.5900000000000003, 1e-08, 0.9800000000000006, 256.0, 0.9700000000000001, 2048, 0.6300000000000003, u'QuantilesGlobal', 29]</td>\n",
       "<td>0.7421245</td></tr></table></div>"
      ],
      "text/plain": [
       "Model Id            Hyperparameters: [nbins, col_sample_rate, min_split_improvement, col_sample_rate_per_tree, min_rows, col_sample_rate_change_per_level, nbins_cats, sample_rate, histogram_type, max_depth]    auc(valid=True)\n",
       "------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------  -----------------\n",
       "grid_tune_model_32  [64, 0.3300000000000001, 0.0001, 0.8800000000000006, 1.0, 0.93, 128, 0.7300000000000004, u'RoundRobin', 29]                                                                                   0.970386024232\n",
       "grid_tune_model_41  [256, 0.4300000000000002, 1e-06, 0.8800000000000006, 4.0, 1.0500000000000003, 64, 0.7300000000000004, u'RoundRobin', 23]                                                                      0.970160608622\n",
       "grid_tune_model_43  [1024, 0.7900000000000005, 0.0001, 0.9300000000000006, 4.0, 1.04, 64, 0.5000000000000002, u'UniformAdaptive', 25]                                                                             0.969935193012\n",
       "grid_tune_model_8   [256, 0.34000000000000014, 0.0001, 0.8000000000000005, 16.0, 1.02, 128, 0.9400000000000006, u'RoundRobin', 24]                                                                                0.968639053254\n",
       "grid_tune_model_19  [32, 0.3200000000000001, 0.0, 0.7000000000000004, 1.0, 1.0100000000000002, 256, 0.8500000000000005, u'RoundRobin', 21]                                                                        0.968357283742\n",
       "---                 ---                                                                                                                                                                                           ---\n",
       "grid_tune_model_24  [256, 0.9000000000000006, 1e-08, 0.5900000000000003, 256.0, 0.9400000000000001, 128, 0.7400000000000004, u'QuantilesGlobal', 27]                                                              0.813158636236\n",
       "grid_tune_model_33  [256, 0.46000000000000024, 1e-08, 0.4000000000000002, 256.0, 1.0300000000000002, 256, 0.6600000000000004, u'QuantilesGlobal', 19]                                                             0.812735981967\n",
       "grid_tune_model_16  [32, 0.9800000000000006, 0.0001, 0.3300000000000001, 256.0, 0.9900000000000001, 1024, 0.34000000000000014, u'UniformAdaptive', 27]                                                            0.791631445478\n",
       "grid_tune_model_30  [32, 0.6100000000000003, 1e-06, 0.8600000000000005, 256.0, 0.9400000000000001, 512, 0.4000000000000002, u'UniformAdaptive', 20]                                                               0.757058326289\n",
       "grid_tune_model_46  [128, 0.5900000000000003, 1e-08, 0.9800000000000006, 256.0, 0.9700000000000001, 2048, 0.6300000000000003, u'QuantilesGlobal', 29]                                                             0.742124542125"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "See the whole table with table.as_data_frame()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Sort the grid models by AUC\n",
    "sorted_grid_tune = grid_tune.sort_by('auc(valid=True)',increasing=False)\n",
    "print sorted_grid_tune"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can inspect the best 5 models from the grid search explicitly, and query their validation AUC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.9703860242321781, 0.970160608622147, 0.9699351930121162, 0.9686390532544378, 0.9683572837418991)\n"
     ]
    }
   ],
   "source": [
    "print sorted_grid_tune[\"auc(valid=True)\"][0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Inspection and Final Test Set Scoring\n",
    "\n",
    "Let's see how well the best model of the grid search (as judged by validation set AUC) does on the held out test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Get the best model from the list (the model name listed at the top of the table)\n",
    "best_model = h2o.get_model('grid_tune_model_32')\n",
    "test_performance_model = best_model.model_performance(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good news. It does as well on the test set as on the validation set, so it looks like our best GBM model generalizes well to the unseen test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.975816043346\n"
     ]
    }
   ],
   "source": [
    "#Get the performance on the test model\n",
    "print test_performance_model.auc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can inspect the winning model's parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learn_rate 0.05\n",
      "fold_column None\n",
      "col_sample_rate_per_tree 0.88\n",
      "learn_rate_annealing 0.99\n",
      "score_tree_interval 10\n",
      "sample_rate_per_class None\n",
      "seed 1234\n",
      "keep_cross_validation_predictions False\n",
      "model_id {u'URL': u'/4/Models/grid_tune_model_32', u'type': u'Key<Model>', u'name': u'grid_tune_model_32', u'__meta': {u'schema_name': u'ModelKeyV3', u'schema_version': 3, u'schema_type': u'Key<Model>'}}\n",
      "nfolds 0\n",
      "max_abs_leafnode_pred 1.79769313486e+308\n",
      "offset_column None\n",
      "quantile_alpha 0.5\n",
      "stopping_tolerance 0.0001\n",
      "fold_assignment AUTO\n",
      "training_frame {u'URL': u'/4/Frames/py_44', u'type': u'Key<Frame>', u'name': u'py_44', u'__meta': {u'schema_name': u'FrameKeyV3', u'schema_version': 3, u'schema_type': u'Key<Frame>'}}\n",
      "max_runtime_secs 35916.603\n",
      "checkpoint None\n",
      "balance_classes False\n",
      "r2_stopping 0.999999\n",
      "validation_frame {u'URL': u'/4/Frames/py_45', u'type': u'Key<Frame>', u'name': u'py_45', u'__meta': {u'schema_name': u'FrameKeyV3', u'schema_version': 3, u'schema_type': u'Key<Frame>'}}\n",
      "max_depth 29\n",
      "response_column {u'is_member_of_frames': None, u'column_name': u'survived', u'__meta': {u'schema_name': u'ColSpecifierV3', u'schema_version': 3, u'schema_type': u'VecSpecifier'}}\n",
      "build_tree_one_node False\n",
      "ntrees 10000\n",
      "min_split_improvement 0.0001\n",
      "ignored_columns [u'name']\n",
      "tweedie_power 1.5\n",
      "min_rows 1.0\n",
      "max_confusion_matrix_size 20\n",
      "score_each_iteration False\n",
      "nbins_top_level 1024\n",
      "max_after_balance_size 5.0\n",
      "nbins 64\n",
      "histogram_type RoundRobin\n",
      "col_sample_rate 0.33\n",
      "stopping_metric AUC\n",
      "weights_column None\n",
      "stopping_rounds 5\n",
      "col_sample_rate_change_per_level 0.93\n",
      "max_hit_ratio_k 0\n",
      "nbins_cats 128\n",
      "sample_rate 0.73\n",
      "distribution bernoulli\n",
      "class_sampling_factors None\n",
      "ignore_const_cols True\n",
      "keep_cross_validation_fold_assignment False\n"
     ]
    }
   ],
   "source": [
    "for key, value in best_model.params.iteritems():\n",
    "    print key,value['actual']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can confirm that these parameters are generally sound, by building a GBM model on the whole dataset (instead of the 60%) and using internal 5-fold cross-validation (re-using all other parameters including the seed):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gbm_best = h2o.H2OGradientBoostingEstimator(distribution='bernoulli',\n",
    "                                    ntrees=10000,\n",
    "                                    learn_rate=0.05,\n",
    "                                    col_sample_rate = 0.33,\n",
    "                                    col_sample_rate_change_per_level = 0.93,\n",
    "                                    col_sample_rate_per_tree = 0.88,\n",
    "                                    seed = 1234,\n",
    "                                    sample_rate = 0.73,\n",
    "                                    score_tree_interval = 10, \n",
    "                                    stopping_rounds = 5,\n",
    "                                    stopping_metric = \"AUC\",\n",
    "                                    stopping_tolerance = 1e-4,\n",
    "                                    nbins_cats = 128,\n",
    "                                    histogram_type = \"RoundRobin\",\n",
    "                                    min_split_improvement = 0.0001,\n",
    "                                    nfolds = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "gbm Model Build Progress: [##################################################] 100%\n"
     ]
    }
   ],
   "source": [
    "gbm_best.train(x=predictors, y=response,learn_rate_annealing = 0.99, training_frame=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details\n",
      "=============\n",
      "H2OGradientBoostingEstimator :  Gradient Boosting Method\n",
      "Model Key:  GBM_model_python_1464825551794_7134\n",
      "\n",
      "Model Summary: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>number_of_trees</b></td>\n",
       "<td><b>model_size_in_bytes</b></td>\n",
       "<td><b>min_depth</b></td>\n",
       "<td><b>max_depth</b></td>\n",
       "<td><b>mean_depth</b></td>\n",
       "<td><b>min_leaves</b></td>\n",
       "<td><b>max_leaves</b></td>\n",
       "<td><b>mean_leaves</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>238.0</td>\n",
       "<td>67561.0</td>\n",
       "<td>5.0</td>\n",
       "<td>5.0</td>\n",
       "<td>5.0</td>\n",
       "<td>9.0</td>\n",
       "<td>27.0</td>\n",
       "<td>18.718487</td></tr></table></div>"
      ],
      "text/plain": [
       "    number_of_trees    model_size_in_bytes    min_depth    max_depth    mean_depth    min_leaves    max_leaves    mean_leaves\n",
       "--  -----------------  ---------------------  -----------  -----------  ------------  ------------  ------------  -------------\n",
       "    238                67561                  5            5            5             9             27            18.7185"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomial: gbm\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.024742035678\n",
      "R^2: 0.895191574696\n",
      "LogLoss: 0.0946858792667\n",
      "AUC: 0.99643881335\n",
      "Gini: 0.9928776267\n",
      "\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.431132213513: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>0</b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>0</td>\n",
       "<td>802.0</td>\n",
       "<td>7.0</td>\n",
       "<td>0.0087</td>\n",
       "<td> (7.0/809.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>30.0</td>\n",
       "<td>470.0</td>\n",
       "<td>0.06</td>\n",
       "<td> (30.0/500.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>832.0</td>\n",
       "<td>477.0</td>\n",
       "<td>0.0283</td>\n",
       "<td> (37.0/1309.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       0    1    Error    Rate\n",
       "-----  ---  ---  -------  -------------\n",
       "0      802  7    0.0087   (7.0/809.0)\n",
       "1      30   470  0.06     (30.0/500.0)\n",
       "Total  832  477  0.0283   (37.0/1309.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.4311322</td>\n",
       "<td>0.9621290</td>\n",
       "<td>132.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.2400137</td>\n",
       "<td>0.9648082</td>\n",
       "<td>175.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.4967490</td>\n",
       "<td>0.9830508</td>\n",
       "<td>124.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.4967490</td>\n",
       "<td>0.9717341</td>\n",
       "<td>124.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9996552</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0988633</td>\n",
       "<td>1.0</td>\n",
       "<td>234.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9996552</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_MCC</td>\n",
       "<td>0.4967490</td>\n",
       "<td>0.9408723</td>\n",
       "<td>124.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.3115916</td>\n",
       "<td>0.9653894</td>\n",
       "<td>161.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                      threshold    value     idx\n",
       "--------------------------  -----------  --------  -----\n",
       "max f1                      0.431132     0.962129  132\n",
       "max f2                      0.240014     0.964808  175\n",
       "max f0point5                0.496749     0.983051  124\n",
       "max accuracy                0.496749     0.971734  124\n",
       "max precision               0.999655     1         0\n",
       "max recall                  0.0988633    1         234\n",
       "max specificity             0.999655     1         0\n",
       "max absolute_MCC            0.496749     0.940872  124\n",
       "max min_per_class_accuracy  0.311592     0.965389  161"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gains/Lift Table: Avg response rate: 38.20 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0106952</td>\n",
       "<td>0.9996445</td>\n",
       "<td>2.618</td>\n",
       "<td>2.618</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.028</td>\n",
       "<td>0.028</td>\n",
       "<td>161.8</td>\n",
       "<td>161.8</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0206264</td>\n",
       "<td>0.9995825</td>\n",
       "<td>2.618</td>\n",
       "<td>2.618</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.026</td>\n",
       "<td>0.054</td>\n",
       "<td>161.8</td>\n",
       "<td>161.8</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0305577</td>\n",
       "<td>0.9995164</td>\n",
       "<td>2.618</td>\n",
       "<td>2.618</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.026</td>\n",
       "<td>0.08</td>\n",
       "<td>161.8</td>\n",
       "<td>161.8</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0404889</td>\n",
       "<td>0.9994217</td>\n",
       "<td>2.618</td>\n",
       "<td>2.618</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.026</td>\n",
       "<td>0.106</td>\n",
       "<td>161.8</td>\n",
       "<td>161.8</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.0504202</td>\n",
       "<td>0.9993512</td>\n",
       "<td>2.618</td>\n",
       "<td>2.618</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.026</td>\n",
       "<td>0.132</td>\n",
       "<td>161.8</td>\n",
       "<td>161.8</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1000764</td>\n",
       "<td>0.9989560</td>\n",
       "<td>2.618</td>\n",
       "<td>2.618</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.13</td>\n",
       "<td>0.262</td>\n",
       "<td>161.8</td>\n",
       "<td>161.8</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.1504966</td>\n",
       "<td>0.9984189</td>\n",
       "<td>2.618</td>\n",
       "<td>2.618</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.132</td>\n",
       "<td>0.394</td>\n",
       "<td>161.8</td>\n",
       "<td>161.8</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2001528</td>\n",
       "<td>0.9974748</td>\n",
       "<td>2.618</td>\n",
       "<td>2.618</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.13</td>\n",
       "<td>0.524</td>\n",
       "<td>161.8</td>\n",
       "<td>161.8</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.3002292</td>\n",
       "<td>0.9283516</td>\n",
       "<td>2.618</td>\n",
       "<td>2.618</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.262</td>\n",
       "<td>0.786</td>\n",
       "<td>161.8</td>\n",
       "<td>161.8</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.4003056</td>\n",
       "<td>0.2598057</td>\n",
       "<td>1.8585802</td>\n",
       "<td>2.4281450</td>\n",
       "<td>0.7099237</td>\n",
       "<td>0.9274809</td>\n",
       "<td>0.186</td>\n",
       "<td>0.972</td>\n",
       "<td>85.8580153</td>\n",
       "<td>142.8145038</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5003820</td>\n",
       "<td>0.0818178</td>\n",
       "<td>0.2797863</td>\n",
       "<td>1.9984733</td>\n",
       "<td>0.1068702</td>\n",
       "<td>0.7633588</td>\n",
       "<td>0.028</td>\n",
       "<td>1.0</td>\n",
       "<td>-72.0213740</td>\n",
       "<td>99.8473282</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.5996944</td>\n",
       "<td>0.0419893</td>\n",
       "<td>0.0</td>\n",
       "<td>1.6675159</td>\n",
       "<td>0.0</td>\n",
       "<td>0.6369427</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>66.7515924</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.7005348</td>\n",
       "<td>0.0265239</td>\n",
       "<td>0.0</td>\n",
       "<td>1.4274809</td>\n",
       "<td>0.0</td>\n",
       "<td>0.5452563</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>42.7480916</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.7998472</td>\n",
       "<td>0.0173404</td>\n",
       "<td>0.0</td>\n",
       "<td>1.2502388</td>\n",
       "<td>0.0</td>\n",
       "<td>0.4775549</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>25.0238777</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.8999236</td>\n",
       "<td>0.0089685</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1112054</td>\n",
       "<td>0.0</td>\n",
       "<td>0.4244482</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>11.1205433</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0007817</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.3819710</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    cumulative_response_rate    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  --------  -----------------  ---------------  --------------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.0106952                   0.999645           2.618     2.618              1                1                           0.028           0.028                      161.8     161.8\n",
       "    2        0.0206264                   0.999583           2.618     2.618              1                1                           0.026           0.054                      161.8     161.8\n",
       "    3        0.0305577                   0.999516           2.618     2.618              1                1                           0.026           0.08                       161.8     161.8\n",
       "    4        0.0404889                   0.999422           2.618     2.618              1                1                           0.026           0.106                      161.8     161.8\n",
       "    5        0.0504202                   0.999351           2.618     2.618              1                1                           0.026           0.132                      161.8     161.8\n",
       "    6        0.100076                    0.998956           2.618     2.618              1                1                           0.13            0.262                      161.8     161.8\n",
       "    7        0.150497                    0.998419           2.618     2.618              1                1                           0.132           0.394                      161.8     161.8\n",
       "    8        0.200153                    0.997475           2.618     2.618              1                1                           0.13            0.524                      161.8     161.8\n",
       "    9        0.300229                    0.928352           2.618     2.618              1                1                           0.262           0.786                      161.8     161.8\n",
       "    10       0.400306                    0.259806           1.85858   2.42815            0.709924         0.927481                    0.186           0.972                      85.858    142.815\n",
       "    11       0.500382                    0.0818178          0.279786  1.99847            0.10687          0.763359                    0.028           1                          -72.0214  99.8473\n",
       "    12       0.599694                    0.0419893          0         1.66752            0                0.636943                    0               1                          -100      66.7516\n",
       "    13       0.700535                    0.0265239          0         1.42748            0                0.545256                    0               1                          -100      42.7481\n",
       "    14       0.799847                    0.0173404          0         1.25024            0                0.477555                    0               1                          -100      25.0239\n",
       "    15       0.899924                    0.00896852         0         1.11121            0                0.424448                    0               1                          -100      11.1205\n",
       "    16       1                           0.000781745        0         1                  0                0.381971                    0               1                          -100      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomial: gbm\n",
      "** Reported on cross-validation data. **\n",
      "\n",
      "MSE: 0.0548944822053\n",
      "R^2: 0.767464394898\n",
      "LogLoss: 0.190785731053\n",
      "AUC: 0.96914091471\n",
      "Gini: 0.938281829419\n",
      "\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.570170412897: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>0</b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>0</td>\n",
       "<td>793.0</td>\n",
       "<td>16.0</td>\n",
       "<td>0.0198</td>\n",
       "<td> (16.0/809.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>71.0</td>\n",
       "<td>429.0</td>\n",
       "<td>0.142</td>\n",
       "<td> (71.0/500.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>864.0</td>\n",
       "<td>445.0</td>\n",
       "<td>0.0665</td>\n",
       "<td> (87.0/1309.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       0    1    Error    Rate\n",
       "-----  ---  ---  -------  -------------\n",
       "0      793  16   0.0198   (16.0/809.0)\n",
       "1      71   429  0.142    (71.0/500.0)\n",
       "Total  864  445  0.0665   (87.0/1309.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.5701704</td>\n",
       "<td>0.9079365</td>\n",
       "<td>119.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.2341802</td>\n",
       "<td>0.9030232</td>\n",
       "<td>199.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.6942130</td>\n",
       "<td>0.9494536</td>\n",
       "<td>100.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.5701704</td>\n",
       "<td>0.9335371</td>\n",
       "<td>119.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9998896</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0157905</td>\n",
       "<td>1.0</td>\n",
       "<td>367.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9998896</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_MCC</td>\n",
       "<td>0.5701704</td>\n",
       "<td>0.8597688</td>\n",
       "<td>119.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.2814202</td>\n",
       "<td>0.9072930</td>\n",
       "<td>185.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                      threshold    value     idx\n",
       "--------------------------  -----------  --------  -----\n",
       "max f1                      0.57017      0.907937  119\n",
       "max f2                      0.23418      0.903023  199\n",
       "max f0point5                0.694213     0.949454  100\n",
       "max accuracy                0.57017      0.933537  119\n",
       "max precision               0.99989      1         0\n",
       "max recall                  0.0157905    1         367\n",
       "max specificity             0.99989      1         0\n",
       "max absolute_MCC            0.57017      0.859769  119\n",
       "max min_per_class_accuracy  0.28142      0.907293  185"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gains/Lift Table: Avg response rate: 38.20 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0106952</td>\n",
       "<td>0.9999194</td>\n",
       "<td>2.618</td>\n",
       "<td>2.618</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.028</td>\n",
       "<td>0.028</td>\n",
       "<td>161.8</td>\n",
       "<td>161.8</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0206264</td>\n",
       "<td>0.9998643</td>\n",
       "<td>2.618</td>\n",
       "<td>2.618</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.026</td>\n",
       "<td>0.054</td>\n",
       "<td>161.8</td>\n",
       "<td>161.8</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0305577</td>\n",
       "<td>0.9997939</td>\n",
       "<td>2.618</td>\n",
       "<td>2.618</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.026</td>\n",
       "<td>0.08</td>\n",
       "<td>161.8</td>\n",
       "<td>161.8</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0404889</td>\n",
       "<td>0.9996700</td>\n",
       "<td>2.618</td>\n",
       "<td>2.618</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.026</td>\n",
       "<td>0.106</td>\n",
       "<td>161.8</td>\n",
       "<td>161.8</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.0504202</td>\n",
       "<td>0.9995073</td>\n",
       "<td>2.618</td>\n",
       "<td>2.618</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.026</td>\n",
       "<td>0.132</td>\n",
       "<td>161.8</td>\n",
       "<td>161.8</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1000764</td>\n",
       "<td>0.9986523</td>\n",
       "<td>2.618</td>\n",
       "<td>2.618</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.13</td>\n",
       "<td>0.262</td>\n",
       "<td>161.8</td>\n",
       "<td>161.8</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.1504966</td>\n",
       "<td>0.9969341</td>\n",
       "<td>2.618</td>\n",
       "<td>2.618</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.132</td>\n",
       "<td>0.394</td>\n",
       "<td>161.8</td>\n",
       "<td>161.8</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2001528</td>\n",
       "<td>0.9933988</td>\n",
       "<td>2.5777231</td>\n",
       "<td>2.6080076</td>\n",
       "<td>0.9846154</td>\n",
       "<td>0.9961832</td>\n",
       "<td>0.128</td>\n",
       "<td>0.522</td>\n",
       "<td>157.7723077</td>\n",
       "<td>160.8007634</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.3002292</td>\n",
       "<td>0.8673018</td>\n",
       "<td>2.5980153</td>\n",
       "<td>2.6046768</td>\n",
       "<td>0.9923664</td>\n",
       "<td>0.9949109</td>\n",
       "<td>0.26</td>\n",
       "<td>0.782</td>\n",
       "<td>159.8015267</td>\n",
       "<td>160.4676845</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.4003056</td>\n",
       "<td>0.2953306</td>\n",
       "<td>1.2190687</td>\n",
       "<td>2.2582748</td>\n",
       "<td>0.4656489</td>\n",
       "<td>0.8625954</td>\n",
       "<td>0.122</td>\n",
       "<td>0.904</td>\n",
       "<td>21.9068702</td>\n",
       "<td>125.8274809</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5003820</td>\n",
       "<td>0.0962700</td>\n",
       "<td>0.4796336</td>\n",
       "<td>1.9025466</td>\n",
       "<td>0.1832061</td>\n",
       "<td>0.7267176</td>\n",
       "<td>0.048</td>\n",
       "<td>0.952</td>\n",
       "<td>-52.0366412</td>\n",
       "<td>90.2546565</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.6004584</td>\n",
       "<td>0.0467288</td>\n",
       "<td>0.2797863</td>\n",
       "<td>1.6320865</td>\n",
       "<td>0.1068702</td>\n",
       "<td>0.6234097</td>\n",
       "<td>0.028</td>\n",
       "<td>0.98</td>\n",
       "<td>-72.0213740</td>\n",
       "<td>63.2086514</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.6997708</td>\n",
       "<td>0.0308050</td>\n",
       "<td>0.0604154</td>\n",
       "<td>1.4090328</td>\n",
       "<td>0.0230769</td>\n",
       "<td>0.5382096</td>\n",
       "<td>0.006</td>\n",
       "<td>0.986</td>\n",
       "<td>-93.9584615</td>\n",
       "<td>40.9032751</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.7998472</td>\n",
       "<td>0.0190292</td>\n",
       "<td>0.0799389</td>\n",
       "<td>1.2427373</td>\n",
       "<td>0.0305344</td>\n",
       "<td>0.4746896</td>\n",
       "<td>0.008</td>\n",
       "<td>0.994</td>\n",
       "<td>-92.0061069</td>\n",
       "<td>24.2737345</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.8999236</td>\n",
       "<td>0.0088202</td>\n",
       "<td>0.0599542</td>\n",
       "<td>1.1112054</td>\n",
       "<td>0.0229008</td>\n",
       "<td>0.4244482</td>\n",
       "<td>0.006</td>\n",
       "<td>1.0</td>\n",
       "<td>-94.0045802</td>\n",
       "<td>11.1205433</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0003133</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.3819710</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    cumulative_response_rate    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  --------------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.0106952                   0.999919           2.618      2.618              1                1                           0.028           0.028                      161.8     161.8\n",
       "    2        0.0206264                   0.999864           2.618      2.618              1                1                           0.026           0.054                      161.8     161.8\n",
       "    3        0.0305577                   0.999794           2.618      2.618              1                1                           0.026           0.08                       161.8     161.8\n",
       "    4        0.0404889                   0.99967            2.618      2.618              1                1                           0.026           0.106                      161.8     161.8\n",
       "    5        0.0504202                   0.999507           2.618      2.618              1                1                           0.026           0.132                      161.8     161.8\n",
       "    6        0.100076                    0.998652           2.618      2.618              1                1                           0.13            0.262                      161.8     161.8\n",
       "    7        0.150497                    0.996934           2.618      2.618              1                1                           0.132           0.394                      161.8     161.8\n",
       "    8        0.200153                    0.993399           2.57772    2.60801            0.984615         0.996183                    0.128           0.522                      157.772   160.801\n",
       "    9        0.300229                    0.867302           2.59802    2.60468            0.992366         0.994911                    0.26            0.782                      159.802   160.468\n",
       "    10       0.400306                    0.295331           1.21907    2.25827            0.465649         0.862595                    0.122           0.904                      21.9069   125.827\n",
       "    11       0.500382                    0.09627            0.479634   1.90255            0.183206         0.726718                    0.048           0.952                      -52.0366  90.2547\n",
       "    12       0.600458                    0.0467288          0.279786   1.63209            0.10687          0.62341                     0.028           0.98                       -72.0214  63.2087\n",
       "    13       0.699771                    0.030805           0.0604154  1.40903            0.0230769        0.53821                     0.006           0.986                      -93.9585  40.9033\n",
       "    14       0.799847                    0.0190292          0.0799389  1.24274            0.0305344        0.47469                     0.008           0.994                      -92.0061  24.2737\n",
       "    15       0.899924                    0.0088202          0.0599542  1.11121            0.0229008        0.424448                    0.006           1                          -94.0046  11.1205\n",
       "    16       1                           0.000313304        0          1                  0                0.381971                    0               1                          -100      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Cross-Validation Metrics Summary: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>mean</b></td>\n",
       "<td><b>sd</b></td>\n",
       "<td><b>cv_1_valid</b></td>\n",
       "<td><b>cv_2_valid</b></td>\n",
       "<td><b>cv_3_valid</b></td>\n",
       "<td><b>cv_4_valid</b></td>\n",
       "<td><b>cv_5_valid</b></td></tr>\n",
       "<tr><td>F0point5</td>\n",
       "<td>0.9464863</td>\n",
       "<td>0.0028340</td>\n",
       "<td>0.9423077</td>\n",
       "<td>0.9466019</td>\n",
       "<td>0.9447005</td>\n",
       "<td>0.954023</td>\n",
       "<td>0.9447983</td></tr>\n",
       "<tr><td>F1</td>\n",
       "<td>0.9115442</td>\n",
       "<td>0.0094239</td>\n",
       "<td>0.9158878</td>\n",
       "<td>0.8914286</td>\n",
       "<td>0.9010989</td>\n",
       "<td>0.9222222</td>\n",
       "<td>0.9270833</td></tr>\n",
       "<tr><td>F2</td>\n",
       "<td>0.879416</td>\n",
       "<td>0.0171493</td>\n",
       "<td>0.8909091</td>\n",
       "<td>0.8423326</td>\n",
       "<td>0.8613445</td>\n",
       "<td>0.8924731</td>\n",
       "<td>0.9100205</td></tr>\n",
       "<tr><td>accuracy</td>\n",
       "<td>0.9367068</td>\n",
       "<td>0.0050753</td>\n",
       "<td>0.9325843</td>\n",
       "<td>0.9298893</td>\n",
       "<td>0.9302326</td>\n",
       "<td>0.9448819</td>\n",
       "<td>0.9459459</td></tr>\n",
       "<tr><td>auc</td>\n",
       "<td>0.969806</td>\n",
       "<td>0.0051657</td>\n",
       "<td>0.9580933</td>\n",
       "<td>0.9658036</td>\n",
       "<td>0.9707908</td>\n",
       "<td>0.9786164</td>\n",
       "<td>0.975726</td></tr>\n",
       "<tr><td>err</td>\n",
       "<td>0.0632932</td>\n",
       "<td>0.0050753</td>\n",
       "<td>0.0674157</td>\n",
       "<td>0.0701107</td>\n",
       "<td>0.0697674</td>\n",
       "<td>0.0551181</td>\n",
       "<td>0.0540541</td></tr>\n",
       "<tr><td>err_count</td>\n",
       "<td>16.6</td>\n",
       "<td>1.5231546</td>\n",
       "<td>18.0</td>\n",
       "<td>19.0</td>\n",
       "<td>18.0</td>\n",
       "<td>14.0</td>\n",
       "<td>14.0</td></tr>\n",
       "<tr><td>lift_top_group</td>\n",
       "<td>2.6258688</td>\n",
       "<td>0.0998947</td>\n",
       "<td>2.3839285</td>\n",
       "<td>2.8229167</td>\n",
       "<td>2.632653</td>\n",
       "<td>2.6736841</td>\n",
       "<td>2.6161616</td></tr>\n",
       "<tr><td>logloss</td>\n",
       "<td>0.1903914</td>\n",
       "<td>0.0178253</td>\n",
       "<td>0.2237620</td>\n",
       "<td>0.1981992</td>\n",
       "<td>0.2069530</td>\n",
       "<td>0.1559702</td>\n",
       "<td>0.1670726</td></tr>\n",
       "<tr><td>max_per_class_error</td>\n",
       "<td>0.1406182</td>\n",
       "<td>0.0217442</td>\n",
       "<td>0.125</td>\n",
       "<td>0.1875</td>\n",
       "<td>0.1632653</td>\n",
       "<td>0.1263158</td>\n",
       "<td>0.1010101</td></tr>\n",
       "<tr><td>mcc</td>\n",
       "<td>0.8667105</td>\n",
       "<td>0.0105305</td>\n",
       "<td>0.8624610</td>\n",
       "<td>0.8490802</td>\n",
       "<td>0.8537086</td>\n",
       "<td>0.8830066</td>\n",
       "<td>0.885296</td></tr>\n",
       "<tr><td>mse</td>\n",
       "<td>0.0548048</td>\n",
       "<td>0.0043917</td>\n",
       "<td>0.0603349</td>\n",
       "<td>0.0577931</td>\n",
       "<td>0.0611235</td>\n",
       "<td>0.0460892</td>\n",
       "<td>0.0486834</td></tr>\n",
       "<tr><td>precision</td>\n",
       "<td>0.9715553</td>\n",
       "<td>0.0078933</td>\n",
       "<td>0.9607843</td>\n",
       "<td>0.9873418</td>\n",
       "<td>0.9761905</td>\n",
       "<td>0.9764706</td>\n",
       "<td>0.9569892</td></tr>\n",
       "<tr><td>r2</td>\n",
       "<td>0.7674178</td>\n",
       "<td>0.0182495</td>\n",
       "<td>0.7522343</td>\n",
       "<td>0.7473580</td>\n",
       "<td>0.7405213</td>\n",
       "<td>0.8031455</td>\n",
       "<td>0.7938300</td></tr>\n",
       "<tr><td>recall</td>\n",
       "<td>0.8593817</td>\n",
       "<td>0.0217442</td>\n",
       "<td>0.875</td>\n",
       "<td>0.8125</td>\n",
       "<td>0.8367347</td>\n",
       "<td>0.8736842</td>\n",
       "<td>0.8989899</td></tr>\n",
       "<tr><td>specificity</td>\n",
       "<td>0.9836801</td>\n",
       "<td>0.0055354</td>\n",
       "<td>0.9741936</td>\n",
       "<td>0.9942857</td>\n",
       "<td>0.9875</td>\n",
       "<td>0.9874214</td>\n",
       "<td>0.975</td></tr></table></div>"
      ],
      "text/plain": [
       "                     mean       sd          cv_1_valid    cv_2_valid    cv_3_valid    cv_4_valid    cv_5_valid\n",
       "-------------------  ---------  ----------  ------------  ------------  ------------  ------------  ------------\n",
       "F0point5             0.946486   0.00283398  0.942308      0.946602      0.944701      0.954023      0.944798\n",
       "F1                   0.911544   0.00942388  0.915888      0.891429      0.901099      0.922222      0.927083\n",
       "F2                   0.879416   0.0171493   0.890909      0.842333      0.861344      0.892473      0.910021\n",
       "accuracy             0.936707   0.00507527  0.932584      0.929889      0.930233      0.944882      0.945946\n",
       "auc                  0.969806   0.0051657   0.958093      0.965804      0.970791      0.978616      0.975726\n",
       "err                  0.0632932  0.00507527  0.0674157     0.0701107     0.0697674     0.0551181     0.0540541\n",
       "err_count            16.6       1.52315     18            19            18            14            14\n",
       "lift_top_group       2.62587    0.0998947   2.38393       2.82292       2.63265       2.67368       2.61616\n",
       "logloss              0.190391   0.0178253   0.223762      0.198199      0.206953      0.15597       0.167073\n",
       "max_per_class_error  0.140618   0.0217442   0.125         0.1875        0.163265      0.126316      0.10101\n",
       "mcc                  0.866711   0.0105305   0.862461      0.84908       0.853709      0.883007      0.885296\n",
       "mse                  0.0548048  0.00439172  0.0603349     0.0577931     0.0611235     0.0460892     0.0486834\n",
       "precision            0.971555   0.0078933   0.960784      0.987342      0.97619       0.976471      0.956989\n",
       "r2                   0.767418   0.0182495   0.752234      0.747358      0.740521      0.803145      0.79383\n",
       "recall               0.859382   0.0217442   0.875         0.8125        0.836735      0.873684      0.89899\n",
       "specificity          0.98368    0.0055354   0.974194      0.994286      0.9875        0.987421      0.975"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scoring History: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>timestamp</b></td>\n",
       "<td><b>duration</b></td>\n",
       "<td><b>number_of_trees</b></td>\n",
       "<td><b>training_MSE</b></td>\n",
       "<td><b>training_logloss</b></td>\n",
       "<td><b>training_AUC</b></td>\n",
       "<td><b>training_lift</b></td>\n",
       "<td><b>training_classification_error</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-06-01 17:03:46</td>\n",
       "<td> 3.233 sec</td>\n",
       "<td>0.0</td>\n",
       "<td>0.2360691</td>\n",
       "<td>0.6650208</td>\n",
       "<td>0.5</td>\n",
       "<td>1.0</td>\n",
       "<td>0.6180290</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-06-01 17:03:46</td>\n",
       "<td> 3.260 sec</td>\n",
       "<td>10.0</td>\n",
       "<td>0.1436176</td>\n",
       "<td>0.4688668</td>\n",
       "<td>0.9713708</td>\n",
       "<td>2.618</td>\n",
       "<td>0.0733384</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-06-01 17:03:46</td>\n",
       "<td> 3.279 sec</td>\n",
       "<td>20.0</td>\n",
       "<td>0.0964926</td>\n",
       "<td>0.3553781</td>\n",
       "<td>0.9736193</td>\n",
       "<td>2.618</td>\n",
       "<td>0.0710466</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-06-01 17:03:46</td>\n",
       "<td> 3.302 sec</td>\n",
       "<td>30.0</td>\n",
       "<td>0.0763702</td>\n",
       "<td>0.2958328</td>\n",
       "<td>0.9764215</td>\n",
       "<td>2.618</td>\n",
       "<td>0.0672269</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-06-01 17:03:46</td>\n",
       "<td> 3.327 sec</td>\n",
       "<td>40.0</td>\n",
       "<td>0.0633225</td>\n",
       "<td>0.2504598</td>\n",
       "<td>0.9789098</td>\n",
       "<td>2.618</td>\n",
       "<td>0.0634072</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-06-01 17:03:47</td>\n",
       "<td> 4.054 sec</td>\n",
       "<td>200.0</td>\n",
       "<td>0.0280089</td>\n",
       "<td>0.1064794</td>\n",
       "<td>0.9948888</td>\n",
       "<td>2.618</td>\n",
       "<td>0.0320856</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-06-01 17:03:47</td>\n",
       "<td> 4.214 sec</td>\n",
       "<td>210.0</td>\n",
       "<td>0.0270032</td>\n",
       "<td>0.1030859</td>\n",
       "<td>0.9953053</td>\n",
       "<td>2.618</td>\n",
       "<td>0.0313216</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-06-01 17:03:47</td>\n",
       "<td> 4.284 sec</td>\n",
       "<td>220.0</td>\n",
       "<td>0.0263122</td>\n",
       "<td>0.1002153</td>\n",
       "<td>0.9956984</td>\n",
       "<td>2.618</td>\n",
       "<td>0.0290298</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-06-01 17:03:47</td>\n",
       "<td> 4.353 sec</td>\n",
       "<td>230.0</td>\n",
       "<td>0.0254105</td>\n",
       "<td>0.0970644</td>\n",
       "<td>0.9961063</td>\n",
       "<td>2.618</td>\n",
       "<td>0.0282659</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-06-01 17:03:47</td>\n",
       "<td> 4.424 sec</td>\n",
       "<td>238.0</td>\n",
       "<td>0.0247420</td>\n",
       "<td>0.0946859</td>\n",
       "<td>0.9964388</td>\n",
       "<td>2.618</td>\n",
       "<td>0.0282659</td></tr></table></div>"
      ],
      "text/plain": [
       "     timestamp            duration    number_of_trees    training_MSE     training_logloss    training_AUC    training_lift    training_classification_error\n",
       "---  -------------------  ----------  -----------------  ---------------  ------------------  --------------  ---------------  -------------------------------\n",
       "     2016-06-01 17:03:46  3.233 sec   0.0                0.236069148126   0.6650207727        0.5             1.0              0.618029029794\n",
       "     2016-06-01 17:03:46  3.260 sec   10.0               0.143617609942   0.468866793275      0.971370828183  2.618            0.0733384262796\n",
       "     2016-06-01 17:03:46  3.279 sec   20.0               0.0964926198233  0.355378056419      0.973619283066  2.618            0.0710466004584\n",
       "     2016-06-01 17:03:46  3.302 sec   30.0               0.0763702074818  0.295832798668      0.976421508035  2.618            0.0672268907563\n",
       "     2016-06-01 17:03:46  3.327 sec   40.0               0.0633224536027  0.250459787271      0.978909765142  2.618            0.0634071810542\n",
       "---  ---                  ---         ---                ---              ---                 ---             ---              ---\n",
       "     2016-06-01 17:03:47  4.054 sec   200.0              0.0280089211756  0.106479397811      0.994888751545  2.618            0.0320855614973\n",
       "     2016-06-01 17:03:47  4.214 sec   210.0              0.0270032432053  0.103085913872      0.995305315204  2.618            0.0313216195569\n",
       "     2016-06-01 17:03:47  4.284 sec   220.0              0.0263121871614  0.100215253623      0.995698393078  2.618            0.0290297937357\n",
       "     2016-06-01 17:03:47  4.353 sec   230.0              0.025410502997   0.0970644143936     0.996106304079  2.618            0.0282658517953\n",
       "     2016-06-01 17:03:47  4.424 sec   238.0              0.024742035678   0.0946858792667     0.99643881335   2.618            0.0282658517953"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "See the whole table with table.as_data_frame()\n",
      "\n",
      "Variable Importances: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>variable</b></td>\n",
       "<td><b>relative_importance</b></td>\n",
       "<td><b>scaled_importance</b></td>\n",
       "<td><b>percentage</b></td></tr>\n",
       "<tr><td>boat</td>\n",
       "<td>1276.1845703</td>\n",
       "<td>1.0</td>\n",
       "<td>0.5200953</td></tr>\n",
       "<tr><td>sex</td>\n",
       "<td>443.5411987</td>\n",
       "<td>0.3475525</td>\n",
       "<td>0.1807605</td></tr>\n",
       "<tr><td>fare</td>\n",
       "<td>116.3196335</td>\n",
       "<td>0.0911464</td>\n",
       "<td>0.0474048</td></tr>\n",
       "<tr><td>cabin</td>\n",
       "<td>104.0673981</td>\n",
       "<td>0.0815457</td>\n",
       "<td>0.0424116</td></tr>\n",
       "<tr><td>ticket</td>\n",
       "<td>102.6859894</td>\n",
       "<td>0.0804633</td>\n",
       "<td>0.0418486</td></tr>\n",
       "<tr><td>age</td>\n",
       "<td>92.1821823</td>\n",
       "<td>0.0722326</td>\n",
       "<td>0.0375679</td></tr>\n",
       "<tr><td>home.dest</td>\n",
       "<td>79.9298096</td>\n",
       "<td>0.0626319</td>\n",
       "<td>0.0325745</td></tr>\n",
       "<tr><td>pclass</td>\n",
       "<td>78.4117355</td>\n",
       "<td>0.0614423</td>\n",
       "<td>0.0319559</td></tr>\n",
       "<tr><td>body</td>\n",
       "<td>52.3205261</td>\n",
       "<td>0.0409976</td>\n",
       "<td>0.0213227</td></tr>\n",
       "<tr><td>embarked</td>\n",
       "<td>48.0121422</td>\n",
       "<td>0.0376216</td>\n",
       "<td>0.0195668</td></tr>\n",
       "<tr><td>sibsp</td>\n",
       "<td>31.7163696</td>\n",
       "<td>0.0248525</td>\n",
       "<td>0.0129257</td></tr>\n",
       "<tr><td>parch</td>\n",
       "<td>28.3796196</td>\n",
       "<td>0.0222379</td>\n",
       "<td>0.0115658</td></tr></table></div>"
      ],
      "text/plain": [
       "variable    relative_importance    scaled_importance    percentage\n",
       "----------  ---------------------  -------------------  ------------\n",
       "boat        1276.18                1                    0.520095\n",
       "sex         443.541                0.347553             0.18076\n",
       "fare        116.32                 0.0911464            0.0474048\n",
       "cabin       104.067                0.0815457            0.0424116\n",
       "ticket      102.686                0.0804633            0.0418486\n",
       "age         92.1822                0.0722326            0.0375679\n",
       "home.dest   79.9298                0.0626319            0.0325745\n",
       "pclass      78.4117                0.0614423            0.0319559\n",
       "body        52.3205                0.0409976            0.0213227\n",
       "embarked    48.0121                0.0376216            0.0195668\n",
       "sibsp       31.7164                0.0248525            0.0129257\n",
       "parch       28.3796                0.0222379            0.0115658"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method H2OGradientBoostingEstimator.cross_validation_metrics_summary of >\n"
     ]
    }
   ],
   "source": [
    "print gbm_best.cross_validation_metrics_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keeping the same \"best\" model, we can make test set predictions as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "gbm prediction Progress: [##################################################] 100%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th style=\"text-align: right;\">  predict</th><th style=\"text-align: right;\">       p0</th><th style=\"text-align: right;\">       p1</th></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.97708  </td><td style=\"text-align: right;\">0.0229197</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.987267 </td><td style=\"text-align: right;\">0.0127335</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.755024 </td><td style=\"text-align: right;\">0.244976 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">0.0164609</td><td style=\"text-align: right;\">0.983539 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">0.0164099</td><td style=\"text-align: right;\">0.98359  </td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.77207  </td><td style=\"text-align: right;\">0.22793  </td></tr>\n",
       "<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">0.0581372</td><td style=\"text-align: right;\">0.941863 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">0.019667 </td><td style=\"text-align: right;\">0.980333 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">0.0273786</td><td style=\"text-align: right;\">0.972621 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.962789 </td><td style=\"text-align: right;\">0.0372105</td></tr>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm = h2o.get_model('grid_tune_model_32')\n",
    "preds = gbm.predict(test)\n",
    "preds.head()\n",
    "#gbm@model$validation_metrics@metrics$max_criteria_and_metric_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the label (survived or not) is predicted as well (in the first predict column), and it uses the threshold with the highest F1 score (here: 0.4811222) to make labels from the probabilities for survival (p1). The probability for death (p0) is given for convenience, as it is just 1-p1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details\n",
      "=============\n",
      "H2OGradientBoostingEstimator :  Gradient Boosting Method\n",
      "Model Key:  grid_tune_model_32\n",
      "\n",
      "Model Summary: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>number_of_trees</b></td>\n",
       "<td><b>model_size_in_bytes</b></td>\n",
       "<td><b>min_depth</b></td>\n",
       "<td><b>max_depth</b></td>\n",
       "<td><b>mean_depth</b></td>\n",
       "<td><b>min_leaves</b></td>\n",
       "<td><b>max_leaves</b></td>\n",
       "<td><b>mean_leaves</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>130.0</td>\n",
       "<td>350279.0</td>\n",
       "<td>12.0</td>\n",
       "<td>25.0</td>\n",
       "<td>18.007692</td>\n",
       "<td>64.0</td>\n",
       "<td>329.0</td>\n",
       "<td>222.06154</td></tr></table></div>"
      ],
      "text/plain": [
       "    number_of_trees    model_size_in_bytes    min_depth    max_depth    mean_depth    min_leaves    max_leaves    mean_leaves\n",
       "--  -----------------  ---------------------  -----------  -----------  ------------  ------------  ------------  -------------\n",
       "    130                350279                 12           25           18.0077       64            329           222.062"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomial: gbm\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.0103541333846\n",
      "R^2: 0.956308097912\n",
      "LogLoss: 0.0617033059212\n",
      "AUC: 0.999868219366\n",
      "Gini: 0.999736438732\n",
      "\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.393763950946: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>0</b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>0</td>\n",
       "<td>477.0</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0042</td>\n",
       "<td> (2.0/479.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>1.0</td>\n",
       "<td>300.0</td>\n",
       "<td>0.0033</td>\n",
       "<td> (1.0/301.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>478.0</td>\n",
       "<td>302.0</td>\n",
       "<td>0.0038</td>\n",
       "<td> (3.0/780.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       0    1    Error    Rate\n",
       "-----  ---  ---  -------  -----------\n",
       "0      477  2    0.0042   (2.0/479.0)\n",
       "1      1    300  0.0033   (1.0/301.0)\n",
       "Total  478  302  0.0038   (3.0/780.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.3937640</td>\n",
       "<td>0.9950249</td>\n",
       "<td>173.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.3663009</td>\n",
       "<td>0.9966887</td>\n",
       "<td>177.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.4567333</td>\n",
       "<td>0.9953240</td>\n",
       "<td>170.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.3937640</td>\n",
       "<td>0.9961538</td>\n",
       "<td>173.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9848078</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.3663009</td>\n",
       "<td>1.0</td>\n",
       "<td>177.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9848078</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_MCC</td>\n",
       "<td>0.3937640</td>\n",
       "<td>0.9918937</td>\n",
       "<td>173.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.3937640</td>\n",
       "<td>0.9958246</td>\n",
       "<td>173.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                      threshold    value     idx\n",
       "--------------------------  -----------  --------  -----\n",
       "max f1                      0.393764     0.995025  173\n",
       "max f2                      0.366301     0.996689  177\n",
       "max f0point5                0.456733     0.995324  170\n",
       "max accuracy                0.393764     0.996154  173\n",
       "max precision               0.984808     1         0\n",
       "max recall                  0.366301     1         177\n",
       "max specificity             0.984808     1         0\n",
       "max absolute_MCC            0.393764     0.991894  173\n",
       "max min_per_class_accuracy  0.393764     0.995825  173"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gains/Lift Table: Avg response rate: 38.59 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0102564</td>\n",
       "<td>0.9845962</td>\n",
       "<td>2.5913621</td>\n",
       "<td>2.5913621</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0265781</td>\n",
       "<td>0.0265781</td>\n",
       "<td>159.1362126</td>\n",
       "<td>159.1362126</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0205128</td>\n",
       "<td>0.9844180</td>\n",
       "<td>2.5913621</td>\n",
       "<td>2.5913621</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0265781</td>\n",
       "<td>0.0531561</td>\n",
       "<td>159.1362126</td>\n",
       "<td>159.1362126</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0307692</td>\n",
       "<td>0.9841610</td>\n",
       "<td>2.5913621</td>\n",
       "<td>2.5913621</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0265781</td>\n",
       "<td>0.0797342</td>\n",
       "<td>159.1362126</td>\n",
       "<td>159.1362126</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0410256</td>\n",
       "<td>0.9839015</td>\n",
       "<td>2.5913621</td>\n",
       "<td>2.5913621</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0265781</td>\n",
       "<td>0.1063123</td>\n",
       "<td>159.1362126</td>\n",
       "<td>159.1362126</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.05</td>\n",
       "<td>0.9836057</td>\n",
       "<td>2.5913621</td>\n",
       "<td>2.5913621</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0232558</td>\n",
       "<td>0.1295681</td>\n",
       "<td>159.1362126</td>\n",
       "<td>159.1362126</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1</td>\n",
       "<td>0.9822774</td>\n",
       "<td>2.5913621</td>\n",
       "<td>2.5913621</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.1295681</td>\n",
       "<td>0.2591362</td>\n",
       "<td>159.1362126</td>\n",
       "<td>159.1362126</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.15</td>\n",
       "<td>0.9798541</td>\n",
       "<td>2.5913621</td>\n",
       "<td>2.5913621</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.1295681</td>\n",
       "<td>0.3887043</td>\n",
       "<td>159.1362126</td>\n",
       "<td>159.1362126</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2</td>\n",
       "<td>0.9761270</td>\n",
       "<td>2.5913621</td>\n",
       "<td>2.5913621</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.1295681</td>\n",
       "<td>0.5182724</td>\n",
       "<td>159.1362126</td>\n",
       "<td>159.1362126</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.3</td>\n",
       "<td>0.9319450</td>\n",
       "<td>2.5913621</td>\n",
       "<td>2.5913621</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.2591362</td>\n",
       "<td>0.7774086</td>\n",
       "<td>159.1362126</td>\n",
       "<td>159.1362126</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.4</td>\n",
       "<td>0.2157580</td>\n",
       "<td>2.2259136</td>\n",
       "<td>2.5</td>\n",
       "<td>0.8589744</td>\n",
       "<td>0.9647436</td>\n",
       "<td>0.2225914</td>\n",
       "<td>1.0</td>\n",
       "<td>122.5913621</td>\n",
       "<td>150.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0530803</td>\n",
       "<td>0.0</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.7717949</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>100.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.6</td>\n",
       "<td>0.0321566</td>\n",
       "<td>0.0</td>\n",
       "<td>1.6666667</td>\n",
       "<td>0.0</td>\n",
       "<td>0.6431624</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>66.6666667</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.7</td>\n",
       "<td>0.0249083</td>\n",
       "<td>0.0</td>\n",
       "<td>1.4285714</td>\n",
       "<td>0.0</td>\n",
       "<td>0.5512821</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>42.8571429</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.8</td>\n",
       "<td>0.0195182</td>\n",
       "<td>0.0</td>\n",
       "<td>1.25</td>\n",
       "<td>0.0</td>\n",
       "<td>0.4823718</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>25.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.9</td>\n",
       "<td>0.0162865</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1111111</td>\n",
       "<td>0.0</td>\n",
       "<td>0.4287749</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>11.1111111</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0109127</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.3858974</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift     cumulative_lift    response_rate    cumulative_response_rate    capture_rate    cumulative_capture_rate    gain     cumulative_gain\n",
       "--  -------  --------------------------  -----------------  -------  -----------------  ---------------  --------------------------  --------------  -------------------------  -------  -----------------\n",
       "    1        0.0102564                   0.984596           2.59136  2.59136            1                1                           0.0265781       0.0265781                  159.136  159.136\n",
       "    2        0.0205128                   0.984418           2.59136  2.59136            1                1                           0.0265781       0.0531561                  159.136  159.136\n",
       "    3        0.0307692                   0.984161           2.59136  2.59136            1                1                           0.0265781       0.0797342                  159.136  159.136\n",
       "    4        0.0410256                   0.983902           2.59136  2.59136            1                1                           0.0265781       0.106312                   159.136  159.136\n",
       "    5        0.05                        0.983606           2.59136  2.59136            1                1                           0.0232558       0.129568                   159.136  159.136\n",
       "    6        0.1                         0.982277           2.59136  2.59136            1                1                           0.129568        0.259136                   159.136  159.136\n",
       "    7        0.15                        0.979854           2.59136  2.59136            1                1                           0.129568        0.388704                   159.136  159.136\n",
       "    8        0.2                         0.976127           2.59136  2.59136            1                1                           0.129568        0.518272                   159.136  159.136\n",
       "    9        0.3                         0.931945           2.59136  2.59136            1                1                           0.259136        0.777409                   159.136  159.136\n",
       "    10       0.4                         0.215758           2.22591  2.5                0.858974         0.964744                    0.222591        1                          122.591  150\n",
       "    11       0.5                         0.0530803          0        2                  0                0.771795                    0               1                          -100     100\n",
       "    12       0.6                         0.0321566          0        1.66667            0                0.643162                    0               1                          -100     66.6667\n",
       "    13       0.7                         0.0249083          0        1.42857            0                0.551282                    0               1                          -100     42.8571\n",
       "    14       0.8                         0.0195182          0        1.25               0                0.482372                    0               1                          -100     25\n",
       "    15       0.9                         0.0162865          0        1.11111            0                0.428775                    0               1                          -100     11.1111\n",
       "    16       1                           0.0109127          0        1                  0                0.385897                    0               1                          -100     0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomial: gbm\n",
      "** Reported on validation data. **\n",
      "\n",
      "MSE: 0.0504959021911\n",
      "R^2: 0.786360645089\n",
      "LogLoss: 0.190423970435\n",
      "AUC: 0.970386024232\n",
      "Gini: 0.940772048464\n",
      "\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.481122236956: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>0</b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>0</td>\n",
       "<td>167.0</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0118</td>\n",
       "<td> (2.0/169.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>13.0</td>\n",
       "<td>92.0</td>\n",
       "<td>0.1238</td>\n",
       "<td> (13.0/105.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>180.0</td>\n",
       "<td>94.0</td>\n",
       "<td>0.0547</td>\n",
       "<td> (15.0/274.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       0    1    Error    Rate\n",
       "-----  ---  ---  -------  ------------\n",
       "0      167  2    0.0118   (2.0/169.0)\n",
       "1      13   92   0.1238   (13.0/105.0)\n",
       "Total  180  94   0.0547   (15.0/274.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.4811222</td>\n",
       "<td>0.9246231</td>\n",
       "<td>93.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.0857740</td>\n",
       "<td>0.9082734</td>\n",
       "<td>135.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.6209273</td>\n",
       "<td>0.9619450</td>\n",
       "<td>91.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.6209273</td>\n",
       "<td>0.9452555</td>\n",
       "<td>91.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9845675</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0173907</td>\n",
       "<td>1.0</td>\n",
       "<td>254.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9845675</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_MCC</td>\n",
       "<td>0.6209273</td>\n",
       "<td>0.8861050</td>\n",
       "<td>91.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.2501180</td>\n",
       "<td>0.9142857</td>\n",
       "<td>109.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                      threshold    value     idx\n",
       "--------------------------  -----------  --------  -----\n",
       "max f1                      0.481122     0.924623  93\n",
       "max f2                      0.085774     0.908273  135\n",
       "max f0point5                0.620927     0.961945  91\n",
       "max accuracy                0.620927     0.945255  91\n",
       "max precision               0.984568     1         0\n",
       "max recall                  0.0173907    1         254\n",
       "max specificity             0.984568     1         0\n",
       "max absolute_MCC            0.620927     0.886105  91\n",
       "max min_per_class_accuracy  0.250118     0.914286  109"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gains/Lift Table: Avg response rate: 38.32 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0109489</td>\n",
       "<td>0.9837571</td>\n",
       "<td>2.6095238</td>\n",
       "<td>2.6095238</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0285714</td>\n",
       "<td>0.0285714</td>\n",
       "<td>160.9523810</td>\n",
       "<td>160.9523810</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0218978</td>\n",
       "<td>0.9832969</td>\n",
       "<td>2.6095238</td>\n",
       "<td>2.6095238</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0285714</td>\n",
       "<td>0.0571429</td>\n",
       "<td>160.9523810</td>\n",
       "<td>160.9523810</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0328467</td>\n",
       "<td>0.9823665</td>\n",
       "<td>2.6095238</td>\n",
       "<td>2.6095238</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0285714</td>\n",
       "<td>0.0857143</td>\n",
       "<td>160.9523810</td>\n",
       "<td>160.9523810</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0401460</td>\n",
       "<td>0.9796526</td>\n",
       "<td>2.6095238</td>\n",
       "<td>2.6095238</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0190476</td>\n",
       "<td>0.1047619</td>\n",
       "<td>160.9523810</td>\n",
       "<td>160.9523810</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.0510949</td>\n",
       "<td>0.9786444</td>\n",
       "<td>2.6095238</td>\n",
       "<td>2.6095238</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0285714</td>\n",
       "<td>0.1333333</td>\n",
       "<td>160.9523810</td>\n",
       "<td>160.9523810</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1021898</td>\n",
       "<td>0.9751848</td>\n",
       "<td>2.6095238</td>\n",
       "<td>2.6095238</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.1333333</td>\n",
       "<td>0.2666667</td>\n",
       "<td>160.9523810</td>\n",
       "<td>160.9523810</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.1496350</td>\n",
       "<td>0.9707483</td>\n",
       "<td>2.6095238</td>\n",
       "<td>2.6095238</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.1238095</td>\n",
       "<td>0.3904762</td>\n",
       "<td>160.9523810</td>\n",
       "<td>160.9523810</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2007299</td>\n",
       "<td>0.9386312</td>\n",
       "<td>2.6095238</td>\n",
       "<td>2.6095238</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.1333333</td>\n",
       "<td>0.5238095</td>\n",
       "<td>160.9523810</td>\n",
       "<td>160.9523810</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.2992701</td>\n",
       "<td>0.8001349</td>\n",
       "<td>2.6095238</td>\n",
       "<td>2.6095238</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.2571429</td>\n",
       "<td>0.7809524</td>\n",
       "<td>160.9523810</td>\n",
       "<td>160.9523810</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.4014599</td>\n",
       "<td>0.2500209</td>\n",
       "<td>1.3047619</td>\n",
       "<td>2.2774026</td>\n",
       "<td>0.5</td>\n",
       "<td>0.8727273</td>\n",
       "<td>0.1333333</td>\n",
       "<td>0.9142857</td>\n",
       "<td>30.4761905</td>\n",
       "<td>127.7402597</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0742899</td>\n",
       "<td>0.4832451</td>\n",
       "<td>1.9238095</td>\n",
       "<td>0.1851852</td>\n",
       "<td>0.7372263</td>\n",
       "<td>0.0476190</td>\n",
       "<td>0.9619048</td>\n",
       "<td>-51.6754850</td>\n",
       "<td>92.3809524</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.5985401</td>\n",
       "<td>0.0416719</td>\n",
       "<td>0.1932981</td>\n",
       "<td>1.6389082</td>\n",
       "<td>0.0740741</td>\n",
       "<td>0.6280488</td>\n",
       "<td>0.0190476</td>\n",
       "<td>0.9809524</td>\n",
       "<td>-80.6701940</td>\n",
       "<td>63.8908246</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.7007299</td>\n",
       "<td>0.0318777</td>\n",
       "<td>0.0931973</td>\n",
       "<td>1.4134921</td>\n",
       "<td>0.0357143</td>\n",
       "<td>0.5416667</td>\n",
       "<td>0.0095238</td>\n",
       "<td>0.9904762</td>\n",
       "<td>-90.6802721</td>\n",
       "<td>41.3492063</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.7992701</td>\n",
       "<td>0.0260437</td>\n",
       "<td>0.0</td>\n",
       "<td>1.2392259</td>\n",
       "<td>0.0</td>\n",
       "<td>0.4748858</td>\n",
       "<td>0.0</td>\n",
       "<td>0.9904762</td>\n",
       "<td>-100.0</td>\n",
       "<td>23.9225919</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.8978102</td>\n",
       "<td>0.0192641</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1032133</td>\n",
       "<td>0.0</td>\n",
       "<td>0.4227642</td>\n",
       "<td>0.0</td>\n",
       "<td>0.9904762</td>\n",
       "<td>-100.0</td>\n",
       "<td>10.3213318</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0119079</td>\n",
       "<td>0.0931973</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0357143</td>\n",
       "<td>0.3832117</td>\n",
       "<td>0.0095238</td>\n",
       "<td>1.0</td>\n",
       "<td>-90.6802721</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    cumulative_response_rate    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  --------------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.0109489                   0.983757           2.60952    2.60952            1                1                           0.0285714       0.0285714                  160.952   160.952\n",
       "    2        0.0218978                   0.983297           2.60952    2.60952            1                1                           0.0285714       0.0571429                  160.952   160.952\n",
       "    3        0.0328467                   0.982366           2.60952    2.60952            1                1                           0.0285714       0.0857143                  160.952   160.952\n",
       "    4        0.040146                    0.979653           2.60952    2.60952            1                1                           0.0190476       0.104762                   160.952   160.952\n",
       "    5        0.0510949                   0.978644           2.60952    2.60952            1                1                           0.0285714       0.133333                   160.952   160.952\n",
       "    6        0.10219                     0.975185           2.60952    2.60952            1                1                           0.133333        0.266667                   160.952   160.952\n",
       "    7        0.149635                    0.970748           2.60952    2.60952            1                1                           0.12381         0.390476                   160.952   160.952\n",
       "    8        0.20073                     0.938631           2.60952    2.60952            1                1                           0.133333        0.52381                    160.952   160.952\n",
       "    9        0.29927                     0.800135           2.60952    2.60952            1                1                           0.257143        0.780952                   160.952   160.952\n",
       "    10       0.40146                     0.250021           1.30476    2.2774             0.5              0.872727                    0.133333        0.914286                   30.4762   127.74\n",
       "    11       0.5                         0.0742899          0.483245   1.92381            0.185185         0.737226                    0.047619        0.961905                   -51.6755  92.381\n",
       "    12       0.59854                     0.0416719          0.193298   1.63891            0.0740741        0.628049                    0.0190476       0.980952                   -80.6702  63.8908\n",
       "    13       0.70073                     0.0318777          0.0931973  1.41349            0.0357143        0.541667                    0.00952381      0.990476                   -90.6803  41.3492\n",
       "    14       0.79927                     0.0260437          0          1.23923            0                0.474886                    0               0.990476                   -100      23.9226\n",
       "    15       0.89781                     0.0192641          0          1.10321            0                0.422764                    0               0.990476                   -100      10.3213\n",
       "    16       1                           0.0119079          0.0931973  1                  0.0357143        0.383212                    0.00952381      1                          -90.6803  0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Scoring History: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>timestamp</b></td>\n",
       "<td><b>duration</b></td>\n",
       "<td><b>number_of_trees</b></td>\n",
       "<td><b>training_MSE</b></td>\n",
       "<td><b>training_logloss</b></td>\n",
       "<td><b>training_AUC</b></td>\n",
       "<td><b>training_lift</b></td>\n",
       "<td><b>training_classification_error</b></td>\n",
       "<td><b>validation_MSE</b></td>\n",
       "<td><b>validation_logloss</b></td>\n",
       "<td><b>validation_AUC</b></td>\n",
       "<td><b>validation_lift</b></td>\n",
       "<td><b>validation_classification_error</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-06-01 17:02:24</td>\n",
       "<td> 1 min 23.402 sec</td>\n",
       "<td>0.0</td>\n",
       "<td>0.2369806</td>\n",
       "<td>0.6668775</td>\n",
       "<td>0.5</td>\n",
       "<td>1.0</td>\n",
       "<td>0.6141026</td>\n",
       "<td>0.2363677</td>\n",
       "<td>0.6656298</td>\n",
       "<td>0.5</td>\n",
       "<td>1.0</td>\n",
       "<td>0.6167883</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-06-01 17:02:24</td>\n",
       "<td> 1 min 23.475 sec</td>\n",
       "<td>10.0</td>\n",
       "<td>0.1143514</td>\n",
       "<td>0.4046775</td>\n",
       "<td>0.9983458</td>\n",
       "<td>2.5913621</td>\n",
       "<td>0.0166667</td>\n",
       "<td>0.1411322</td>\n",
       "<td>0.4617331</td>\n",
       "<td>0.9578755</td>\n",
       "<td>2.6095238</td>\n",
       "<td>0.0729927</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-06-01 17:02:24</td>\n",
       "<td> 1 min 23.524 sec</td>\n",
       "<td>20.0</td>\n",
       "<td>0.0646629</td>\n",
       "<td>0.2798682</td>\n",
       "<td>0.9987516</td>\n",
       "<td>2.5913621</td>\n",
       "<td>0.0179487</td>\n",
       "<td>0.0966420</td>\n",
       "<td>0.3540958</td>\n",
       "<td>0.9653142</td>\n",
       "<td>2.6095238</td>\n",
       "<td>0.0693431</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-06-01 17:02:24</td>\n",
       "<td> 1 min 23.579 sec</td>\n",
       "<td>30.0</td>\n",
       "<td>0.0428596</td>\n",
       "<td>0.2123646</td>\n",
       "<td>0.9992371</td>\n",
       "<td>2.5913621</td>\n",
       "<td>0.0128205</td>\n",
       "<td>0.0783698</td>\n",
       "<td>0.3006264</td>\n",
       "<td>0.9689772</td>\n",
       "<td>2.6095238</td>\n",
       "<td>0.0620438</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-06-01 17:02:24</td>\n",
       "<td> 1 min 23.642 sec</td>\n",
       "<td>40.0</td>\n",
       "<td>0.0306994</td>\n",
       "<td>0.1677444</td>\n",
       "<td>0.9995006</td>\n",
       "<td>2.5913621</td>\n",
       "<td>0.0102564</td>\n",
       "<td>0.0685441</td>\n",
       "<td>0.2669445</td>\n",
       "<td>0.9692026</td>\n",
       "<td>2.6095238</td>\n",
       "<td>0.0656934</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-06-01 17:02:24</td>\n",
       "<td> 1 min 23.705 sec</td>\n",
       "<td>50.0</td>\n",
       "<td>0.0236269</td>\n",
       "<td>0.1368956</td>\n",
       "<td>0.9996532</td>\n",
       "<td>2.5913621</td>\n",
       "<td>0.0089744</td>\n",
       "<td>0.0615856</td>\n",
       "<td>0.2411748</td>\n",
       "<td>0.9708932</td>\n",
       "<td>2.6095238</td>\n",
       "<td>0.0620438</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-06-01 17:02:24</td>\n",
       "<td> 1 min 23.773 sec</td>\n",
       "<td>60.0</td>\n",
       "<td>0.0192380</td>\n",
       "<td>0.1153113</td>\n",
       "<td>0.9997226</td>\n",
       "<td>2.5913621</td>\n",
       "<td>0.0076923</td>\n",
       "<td>0.0577490</td>\n",
       "<td>0.2248451</td>\n",
       "<td>0.9705551</td>\n",
       "<td>2.6095238</td>\n",
       "<td>0.0620438</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-06-01 17:02:24</td>\n",
       "<td> 1 min 23.845 sec</td>\n",
       "<td>70.0</td>\n",
       "<td>0.0166284</td>\n",
       "<td>0.1005205</td>\n",
       "<td>0.9997468</td>\n",
       "<td>2.5913621</td>\n",
       "<td>0.0076923</td>\n",
       "<td>0.0551495</td>\n",
       "<td>0.2134503</td>\n",
       "<td>0.9702170</td>\n",
       "<td>2.6095238</td>\n",
       "<td>0.0583942</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-06-01 17:02:24</td>\n",
       "<td> 1 min 23.920 sec</td>\n",
       "<td>80.0</td>\n",
       "<td>0.0149023</td>\n",
       "<td>0.0901975</td>\n",
       "<td>0.9997885</td>\n",
       "<td>2.5913621</td>\n",
       "<td>0.0064103</td>\n",
       "<td>0.0538631</td>\n",
       "<td>0.2067295</td>\n",
       "<td>0.9701606</td>\n",
       "<td>2.6095238</td>\n",
       "<td>0.0547445</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-06-01 17:02:25</td>\n",
       "<td> 1 min 24.001 sec</td>\n",
       "<td>90.0</td>\n",
       "<td>0.0135935</td>\n",
       "<td>0.0821052</td>\n",
       "<td>0.9997885</td>\n",
       "<td>2.5913621</td>\n",
       "<td>0.0064103</td>\n",
       "<td>0.0535149</td>\n",
       "<td>0.2041672</td>\n",
       "<td>0.9690899</td>\n",
       "<td>2.6095238</td>\n",
       "<td>0.0547445</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-06-01 17:02:25</td>\n",
       "<td> 1 min 24.086 sec</td>\n",
       "<td>100.0</td>\n",
       "<td>0.0124645</td>\n",
       "<td>0.0747913</td>\n",
       "<td>0.9998023</td>\n",
       "<td>2.5913621</td>\n",
       "<td>0.0064103</td>\n",
       "<td>0.0522157</td>\n",
       "<td>0.1985886</td>\n",
       "<td>0.9695971</td>\n",
       "<td>2.6095238</td>\n",
       "<td>0.0547445</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-06-01 17:02:25</td>\n",
       "<td> 1 min 24.176 sec</td>\n",
       "<td>110.0</td>\n",
       "<td>0.0116081</td>\n",
       "<td>0.0694886</td>\n",
       "<td>0.9998231</td>\n",
       "<td>2.5913621</td>\n",
       "<td>0.0064103</td>\n",
       "<td>0.0513245</td>\n",
       "<td>0.1946959</td>\n",
       "<td>0.9699915</td>\n",
       "<td>2.6095238</td>\n",
       "<td>0.0547445</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-06-01 17:02:25</td>\n",
       "<td> 1 min 24.268 sec</td>\n",
       "<td>120.0</td>\n",
       "<td>0.0109608</td>\n",
       "<td>0.0654042</td>\n",
       "<td>0.9998439</td>\n",
       "<td>2.5913621</td>\n",
       "<td>0.0051282</td>\n",
       "<td>0.0508572</td>\n",
       "<td>0.1924170</td>\n",
       "<td>0.9698788</td>\n",
       "<td>2.6095238</td>\n",
       "<td>0.0547445</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-06-01 17:02:25</td>\n",
       "<td> 1 min 24.365 sec</td>\n",
       "<td>130.0</td>\n",
       "<td>0.0103541</td>\n",
       "<td>0.0617033</td>\n",
       "<td>0.9998682</td>\n",
       "<td>2.5913621</td>\n",
       "<td>0.0038462</td>\n",
       "<td>0.0504959</td>\n",
       "<td>0.1904240</td>\n",
       "<td>0.9703860</td>\n",
       "<td>2.6095238</td>\n",
       "<td>0.0547445</td></tr></table></div>"
      ],
      "text/plain": [
       "    timestamp            duration          number_of_trees    training_MSE    training_logloss    training_AUC    training_lift    training_classification_error    validation_MSE    validation_logloss    validation_AUC    validation_lift    validation_classification_error\n",
       "--  -------------------  ----------------  -----------------  --------------  ------------------  --------------  ---------------  -------------------------------  ----------------  --------------------  ----------------  -----------------  ---------------------------------\n",
       "    2016-06-01 17:02:24  1 min 23.402 sec  0                  0.236981        0.666878            0.5             1                0.614103                         0.236368          0.66563               0.5               1                  0.616788\n",
       "    2016-06-01 17:02:24  1 min 23.475 sec  10                 0.114351        0.404677            0.998346        2.59136          0.0166667                        0.141132          0.461733              0.957875          2.60952            0.0729927\n",
       "    2016-06-01 17:02:24  1 min 23.524 sec  20                 0.0646629       0.279868            0.998752        2.59136          0.0179487                        0.096642          0.354096              0.965314          2.60952            0.0693431\n",
       "    2016-06-01 17:02:24  1 min 23.579 sec  30                 0.0428596       0.212365            0.999237        2.59136          0.0128205                        0.0783698         0.300626              0.968977          2.60952            0.0620438\n",
       "    2016-06-01 17:02:24  1 min 23.642 sec  40                 0.0306994       0.167744            0.999501        2.59136          0.0102564                        0.0685441         0.266944              0.969203          2.60952            0.0656934\n",
       "    2016-06-01 17:02:24  1 min 23.705 sec  50                 0.0236269       0.136896            0.999653        2.59136          0.00897436                       0.0615856         0.241175              0.970893          2.60952            0.0620438\n",
       "    2016-06-01 17:02:24  1 min 23.773 sec  60                 0.019238        0.115311            0.999723        2.59136          0.00769231                       0.057749          0.224845              0.970555          2.60952            0.0620438\n",
       "    2016-06-01 17:02:24  1 min 23.845 sec  70                 0.0166284       0.10052             0.999747        2.59136          0.00769231                       0.0551495         0.21345               0.970217          2.60952            0.0583942\n",
       "    2016-06-01 17:02:24  1 min 23.920 sec  80                 0.0149023       0.0901975           0.999788        2.59136          0.00641026                       0.0538631         0.206729              0.970161          2.60952            0.0547445\n",
       "    2016-06-01 17:02:25  1 min 24.001 sec  90                 0.0135935       0.0821052           0.999788        2.59136          0.00641026                       0.0535149         0.204167              0.96909           2.60952            0.0547445\n",
       "    2016-06-01 17:02:25  1 min 24.086 sec  100                0.0124645       0.0747913           0.999802        2.59136          0.00641026                       0.0522157         0.198589              0.969597          2.60952            0.0547445\n",
       "    2016-06-01 17:02:25  1 min 24.176 sec  110                0.0116081       0.0694886           0.999823        2.59136          0.00641026                       0.0513245         0.194696              0.969992          2.60952            0.0547445\n",
       "    2016-06-01 17:02:25  1 min 24.268 sec  120                0.0109608       0.0654042           0.999844        2.59136          0.00512821                       0.0508572         0.192417              0.969879          2.60952            0.0547445\n",
       "    2016-06-01 17:02:25  1 min 24.365 sec  130                0.0103541       0.0617033           0.999868        2.59136          0.00384615                       0.0504959         0.190424              0.970386          2.60952            0.0547445"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Variable Importances: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>variable</b></td>\n",
       "<td><b>relative_importance</b></td>\n",
       "<td><b>scaled_importance</b></td>\n",
       "<td><b>percentage</b></td></tr>\n",
       "<tr><td>boat</td>\n",
       "<td>716.0181274</td>\n",
       "<td>1.0</td>\n",
       "<td>0.3567185</td></tr>\n",
       "<tr><td>sex</td>\n",
       "<td>298.2000122</td>\n",
       "<td>0.4164699</td>\n",
       "<td>0.1485625</td></tr>\n",
       "<tr><td>fare</td>\n",
       "<td>177.8346710</td>\n",
       "<td>0.2483662</td>\n",
       "<td>0.0885968</td></tr>\n",
       "<tr><td>ticket</td>\n",
       "<td>174.5613251</td>\n",
       "<td>0.2437946</td>\n",
       "<td>0.0869660</td></tr>\n",
       "<tr><td>age</td>\n",
       "<td>155.2628021</td>\n",
       "<td>0.2168420</td>\n",
       "<td>0.0773516</td></tr>\n",
       "<tr><td>home.dest</td>\n",
       "<td>131.7727051</td>\n",
       "<td>0.1840354</td>\n",
       "<td>0.0656489</td></tr>\n",
       "<tr><td>cabin</td>\n",
       "<td>96.1860046</td>\n",
       "<td>0.1343346</td>\n",
       "<td>0.0479196</td></tr>\n",
       "<tr><td>pclass</td>\n",
       "<td>71.6239929</td>\n",
       "<td>0.1000310</td>\n",
       "<td>0.0356829</td></tr>\n",
       "<tr><td>parch</td>\n",
       "<td>54.4130287</td>\n",
       "<td>0.0759939</td>\n",
       "<td>0.0271084</td></tr>\n",
       "<tr><td>embarked</td>\n",
       "<td>54.1479073</td>\n",
       "<td>0.0756237</td>\n",
       "<td>0.0269764</td></tr>\n",
       "<tr><td>sibsp</td>\n",
       "<td>53.7264786</td>\n",
       "<td>0.0750351</td>\n",
       "<td>0.0267664</td></tr>\n",
       "<tr><td>body</td>\n",
       "<td>23.4884453</td>\n",
       "<td>0.0328043</td>\n",
       "<td>0.0117019</td></tr></table></div>"
      ],
      "text/plain": [
       "variable    relative_importance    scaled_importance    percentage\n",
       "----------  ---------------------  -------------------  ------------\n",
       "boat        716.018                1                    0.356719\n",
       "sex         298.2                  0.41647              0.148563\n",
       "fare        177.835                0.248366             0.0885968\n",
       "ticket      174.561                0.243795             0.086966\n",
       "age         155.263                0.216842             0.0773516\n",
       "home.dest   131.773                0.184035             0.0656489\n",
       "cabin       96.186                 0.134335             0.0479196\n",
       "pclass      71.624                 0.100031             0.0356829\n",
       "parch       54.413                 0.0759939            0.0271084\n",
       "embarked    54.1479                0.0756237            0.0269764\n",
       "sibsp       53.7265                0.0750351            0.0267664\n",
       "body        23.4884                0.0328043            0.0117019"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<bound method H2OGradientBoostingEstimator.model_performance of >"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm.model_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model and the predictions can be saved to file as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Export File Progress: [##################################################] 100%\n"
     ]
    }
   ],
   "source": [
    "h2o.save_model(gbm, \"/tmp/bestModel.csv\", force=True)\n",
    "h2o.export_file(preds, \"/tmp/bestPreds.csv\", force=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model can also be exported as a plain old Java object (POJO) for H2O-independent (standalone/Storm/Kafka/UDF) scoring in any Java environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h2o.download_pojo(gbm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "We learned how to build H2O GBM models for a binary classification task on a small but realistic dataset with numerical and categorical variables, with the goal to maximize the AUC (ranges from 0.5 to 1). We first established a baseline with the default model, then carefully tuned the remaining hyper-parameters without \"too much\" human guess-work. We used both Cartesian and Random hyper-parameter searches to find good models. We were able to get the AUC on a holdout test set from the low 94% range with the default model to the mid 97% after tuning.\n",
    "\n",
    "Note that this script and the findings therein are directly transferrable to large datasets on distributed clusters including Spark/Hadoop environments.\n",
    "\n",
    "More information can be found here [http://www.h2o.ai/docs/](http://www.h2o.ai/docs/)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
