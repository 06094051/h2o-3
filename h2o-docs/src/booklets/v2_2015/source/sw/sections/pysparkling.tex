\section{What is PySparkling Water?}

PySparkling Water is an integration of Python with Sparkling water. It allows user to start H2O services on a spark cluster from Python API.

In the PySparkling Water driver program, the Spark context(sc) that uses Py4J to start the driver JVM and the JAVA spark Context, is used to create H2O context(hc).  This in turn starts the H2O cloud in the Spark ecosystem. Once the H2O cluster is up, H2O-Python package is used to interact with the cloud and run H2O algorithms. All pure H2O calls are executed via H2O's rest api interface. Users can easily integrate their regular PySpark workflow with H2O algorithms using PySparkling Water.

PySparkling Water programs can be launched as an application, or in an interactive shell, or notebook environment.

\textbf{To get started:}

\begin{enumerate}
\item Download Spark (if not already installed) from the Spark Downloads Page.

Choose Spark release : 1.6.1

Choose a package type: Pre-built for Hadoop 2.4 and later

\item Point SPARK\_HOME to the existing installation of Spark and export variable MASTER.

\begin{lstlisting}[style=Bash]
export SPARK_HOME="/path/to/spark/installation" 
\end{lstlisting}

Launch a local Spark cluster with 3 worker nodes with 2 cores and 1g per node.
\begin{lstlisting}[style=Bash]
export MASTER="local-cluster[3,2,1024]" 
\end{lstlisting}

\item From your terminal, run:

\begin{lstlisting}[style=Bash]
cd ~/Downloads
unzip sparkling-water-1.6.10.zip
cd sparkling-water-1.6.10
\end{lstlisting}

Start an interactive Python terminal:
\begin{lstlisting}[style=Bash]
bin/pysparkling
\end{lstlisting}

Or start a notebook:
\begin{lstlisting}[style=Bash]
IPYTHON_OPTS="notebook" bin/pysparkling
\end{lstlisting}

\item Create an H2O cloud inside the Spark cluster and import H2O-Python package:

\begin{lstlisting}[style=Scala]
from pysparkling import *
hc= H2OContext(sc).start()
import h2o
\end{lstlisting}

\item Follow this demo (\url{https://github.com/h2oai/h2o-world-2015-training/blob/master/tutorials/pysparkling/Chicago_Crime_Demo.ipynb}), which imports Chicago crime, census and weather data and predicts the probability of arrest.


\item To launch on YARN:

\begin{lstlisting}[style=Bash]
wget http://h2o-release.s3.amazonaws.com/sparkling-water/rel-1.5/10/sparkling-water-1.5.10.zip
unzip sparkling-water-1.5.10.zip
 
export SPARK_HOME="/path/to/spark/installation"
export HADOOP_CONF_DIR=/etc/hadoop/conf
export SPARKLING_HOME="/path/to/SparklingWater/installation"
$SPARKLING_HOME/bin/pysparkling --num-executors 3 --executor-memory 20g --executor-cores 10 --driver-memory 20g --master yarn-client
\end{lstlisting}
    
Create an H2O cloud inside the Spark cluster and import H2O-Python package:
\begin{lstlisting}[style=Scala]
from pysparkling import *
hc= H2OContext(sc).start()
import h2o
\end{lstlisting}

\item To launch as a Spark Package application
\begin{lstlisting}[style=Bash]
$SPARK_HOME/bin/spark-submit --packages ai.h2o:sparkling-water-core_2.10:1.5.10 --py-files $SPARKLING_HOME/py/dist/pySparkling-1.5.10-py2.7.egg
$SPARKLING_HOME/py/examples/scripts/H2OContextDemo.py 
\end{lstlisting}
\end{enumerate}

\textbf{H2O Frame as Spark's Data Source}

The way a H2O Frame can be used as Spark's data source differs a little bit in Python and Scala.

\textbf{Usage in Python - pySparkling}

\textbf{Reading from H2O Frame}

Let's suppose we have an H2O frame. There are two ways how the data frame can be loaded from H2OFrame in pySparkling:
\begin{lstlisting}[style=Scala]
df = sqlContext.read.format("h2o").option("key",frame.frame_id).load()
\end{lstlisting}
or
\begin{lstlisting}[style=Scala]
df = sqlContext.read.format("h2o").load(frame.frame_id)
\end{lstlisting}

\textbf{Saving to H2O Frame}

Let's suppose we have a DataFrame df. There are two ways how data frame can be saved as 
H2OFrame in pySparkling:

\begin{lstlisting}[style=Scala]
df.write.format("h2o").option("key","new_key").save()
\end{lstlisting}
or
\begin{lstlisting}[style=Scala]
df.write.format("h2o").save("new_key")
\end{lstlisting}

Both variants save data frame as H2OFrame with key "new\_key". They won't succeed if the H2OFrame with the same key already exists.

\textbf{Loading \& Saving Options}

If the key is specified as 'key' option and also in the load/save method, the option 'key' is preferred:
\begin{lstlisting}[style=Scala]
df = sqlContext.read.from("h2o").option("key","key_one").load("key_two")
\end{lstlisting}
or
\begin{lstlisting}[style=Scala]
df = sqlContext.read.from("h2o").option("key","key_one").save("key_two")
\end{lstlisting}

In both examples, "key\_one" is used.

\textbf{Usage in Scala}

\textbf{Reading from H2O Frame}

Let's suppose we have an H2O frame. The shortest way to load a data frame from H2OFrame with default settings is:
\begin{lstlisting}[style=Scala]
val df = sqlContext.read.h2o(frame.key)
\end{lstlisting}

There are two more ways to load a data frame from H2OFrame allowing us to specify additional options:
\begin{lstlisting}[style=Scala]
val df = sqlContext.read.format("h2o").option("key",frame.key.toString).load()
\end{lstlisting}
or
\begin{lstlisting}[style=Scala]
val df = sqlContext.read.format("h2o").load(frame.key.toString)
\end{lstlisting}

\textbf{Saving to H2O Frame}

Let's suppose we have DataFrame df. The shortest way to save the data frame as H2O Frame with default settings is:
\begin{lstlisting}[style=Scala]
df.write.h2o("new_key")
\end{lstlisting}

There are two more ways to save the data frame as H2OFrame allowing us to specify additional options:
\begin{lstlisting}[style=Scala]
df.write.format("h2o").option("key","new_key").save()
\end{lstlisting}
or
\begin{lstlisting}[style=Scala]
df.write.format("h2o").save("new_key")
\end{lstlisting}

All three variants save the data frame as H2OFrame with the key "new\_key". They won't succeed if the H2O Frame with the same key already exists.

\textbf{Loading \& Saving Options}

If the key is specified as 'key' option, and also in the load/save method, the option 'key' is preferred:
\begin{lstlisting}[style=Scala]
val df = sqlContext.read.from("h2o").option("key","key_one").load("key_two")
\end{lstlisting}
or
\begin{lstlisting}[style=Scala]
val df = sqlContext.read.from("h2o").option("key","key_one").save("key_two")
\end{lstlisting}

In both examples, "key\_one" is used.

\textbf{Specifying Saving Mode}

There are four save modes available when saving data using Data Source API- see \url{http://spark.apache.org/docs/latest/sql-programming-guide.html#save-modes}

\begin{itemize}
\item If "append" mode is used, an existing H2OFrame with the same key is deleted, and a new one created with the same key. The new frame contains the union of all rows from the original H2O Frame and the appended data frame.
\item If "overwrite" mode is used, an existing H2OFrame with the same key is deleted, and new one with the new rows is created with the same key.
\item If "error" mode is used, and a H2OFrame with the specified key already exists, an exception is thrown.
\item If "ignore" mode is used, and a H2OFrame with the specified key already exists, no data are changed.
\end{itemize}

