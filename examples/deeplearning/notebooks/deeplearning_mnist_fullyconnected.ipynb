{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepLearning\n",
    "\n",
    "## MNIST Dataset\n",
    "The MNIST database is a well-known academic dataset used to benchmark\n",
    "classification performance. The data consists of 60,000 training images and\n",
    "10,000 test images. Each image is a standardized $28^2$ pixel greyscale image of\n",
    "a single handwritten digit. An example of the scanned handwritten digits is\n",
    "shown\n",
    "![Example MNIST digit images](images/mnist.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321. connected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime:</td>\n",
       "<td>03 secs</td></tr>\n",
       "<tr><td>H2O cluster version:</td>\n",
       "<td>3.11.0.99999</td></tr>\n",
       "<tr><td>H2O cluster version age:</td>\n",
       "<td>39 minutes </td></tr>\n",
       "<tr><td>H2O cluster name:</td>\n",
       "<td>arno</td></tr>\n",
       "<tr><td>H2O cluster total nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster free memory:</td>\n",
       "<td>13.96 Gb</td></tr>\n",
       "<tr><td>H2O cluster total cores:</td>\n",
       "<td>12</td></tr>\n",
       "<tr><td>H2O cluster allowed cores:</td>\n",
       "<td>12</td></tr>\n",
       "<tr><td>H2O cluster status:</td>\n",
       "<td>accepting new members, healthy</td></tr>\n",
       "<tr><td>H2O connection url:</td>\n",
       "<td>http://localhost:54321</td></tr>\n",
       "<tr><td>H2O connection proxy:</td>\n",
       "<td>None</td></tr>\n",
       "<tr><td>Python version:</td>\n",
       "<td>2.7.12 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ------------------------------\n",
       "H2O cluster uptime:         03 secs\n",
       "H2O cluster version:        3.11.0.99999\n",
       "H2O cluster version age:    39 minutes\n",
       "H2O cluster name:           arno\n",
       "H2O cluster total nodes:    1\n",
       "H2O cluster free memory:    13.96 Gb\n",
       "H2O cluster total cores:    12\n",
       "H2O cluster allowed cores:  12\n",
       "H2O cluster status:         accepting new members, healthy\n",
       "H2O connection url:         http://localhost:54321\n",
       "H2O connection proxy:\n",
       "Python version:             2.7.12 final\n",
       "--------------------------  ------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import h2o\n",
    "h2o.init(nthreads=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "test_df = h2o.import_file(\"https://h2o-public-test-data.s3.amazonaws.com/bigdata/laptop/mnist/test.csv.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "train_df = h2o.import_file(\"https://h2o-public-test-data.s3.amazonaws.com/bigdata/laptop/mnist/train.csv.gz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the response and predictor columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = \"C785\"\n",
    "x = train_df.names[0:784]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df[y] = train_df[y].asfactor()\n",
    "test_df[y] = test_df[y].asfactor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Deep Learning model and validate on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from h2o.estimators.deepwater import H2ODeepWaterEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = H2ODeepWaterEstimator(\n",
    "   distribution=\"multinomial\",\n",
    "   activation=\"rectifier\",\n",
    "   mini_batch_size=128,\n",
    "   hidden=[1024,1024],\n",
    "   hidden_dropout_ratios=[0.5,0.5],      ## for better generalization\n",
    "   input_dropout_ratio=0.1,\n",
    "   sparse=True,                          ## can result in speedup for sparse data\n",
    "   epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deepwater Model Build progress: |█████████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "model.train(\n",
    "    x=x, \n",
    "    y=y,\n",
    "    training_frame=train_df,\n",
    "    validation_frame=test_df\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>duration</th>\n",
       "      <th>training_speed</th>\n",
       "      <th>epochs</th>\n",
       "      <th>iterations</th>\n",
       "      <th>samples</th>\n",
       "      <th>training_rmse</th>\n",
       "      <th>training_logloss</th>\n",
       "      <th>training_classification_error</th>\n",
       "      <th>validation_rmse</th>\n",
       "      <th>validation_logloss</th>\n",
       "      <th>validation_classification_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>2016-10-22 16:15:38</td>\n",
       "      <td>0.000 sec</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>2016-10-22 16:15:38</td>\n",
       "      <td>3.944 sec</td>\n",
       "      <td>7772 obs/sec</td>\n",
       "      <td>0.068267</td>\n",
       "      <td>1</td>\n",
       "      <td>4096.0</td>\n",
       "      <td>0.441615</td>\n",
       "      <td>6.724641</td>\n",
       "      <td>0.195023</td>\n",
       "      <td>0.435390</td>\n",
       "      <td>6.528768</td>\n",
       "      <td>0.1897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>2016-10-22 16:15:52</td>\n",
       "      <td>16.772 sec</td>\n",
       "      <td>28589 obs/sec</td>\n",
       "      <td>6.075733</td>\n",
       "      <td>89</td>\n",
       "      <td>364544.0</td>\n",
       "      <td>0.117783</td>\n",
       "      <td>0.474103</td>\n",
       "      <td>0.013881</td>\n",
       "      <td>0.216529</td>\n",
       "      <td>1.616629</td>\n",
       "      <td>0.0470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>2016-10-22 16:15:58</td>\n",
       "      <td>22.934 sec</td>\n",
       "      <td>29308 obs/sec</td>\n",
       "      <td>8.942933</td>\n",
       "      <td>131</td>\n",
       "      <td>536576.0</td>\n",
       "      <td>0.073171</td>\n",
       "      <td>0.181555</td>\n",
       "      <td>0.005354</td>\n",
       "      <td>0.201246</td>\n",
       "      <td>1.393379</td>\n",
       "      <td>0.0405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>2016-10-22 16:16:01</td>\n",
       "      <td>25.660 sec</td>\n",
       "      <td>29454 obs/sec</td>\n",
       "      <td>10.035200</td>\n",
       "      <td>147</td>\n",
       "      <td>602112.0</td>\n",
       "      <td>0.082110</td>\n",
       "      <td>0.229697</td>\n",
       "      <td>0.006742</td>\n",
       "      <td>0.207599</td>\n",
       "      <td>1.482130</td>\n",
       "      <td>0.0431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td>2016-10-22 16:16:01</td>\n",
       "      <td>26.327 sec</td>\n",
       "      <td>29410 obs/sec</td>\n",
       "      <td>10.035200</td>\n",
       "      <td>147</td>\n",
       "      <td>602112.0</td>\n",
       "      <td>0.073171</td>\n",
       "      <td>0.181555</td>\n",
       "      <td>0.005354</td>\n",
       "      <td>0.201246</td>\n",
       "      <td>1.393379</td>\n",
       "      <td>0.0405</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               timestamp    duration training_speed     epochs  iterations  \\\n",
       "0    2016-10-22 16:15:38   0.000 sec           None   0.000000           0   \n",
       "1    2016-10-22 16:15:38   3.944 sec   7772 obs/sec   0.068267           1   \n",
       "2    2016-10-22 16:15:52  16.772 sec  28589 obs/sec   6.075733          89   \n",
       "3    2016-10-22 16:15:58  22.934 sec  29308 obs/sec   8.942933         131   \n",
       "4    2016-10-22 16:16:01  25.660 sec  29454 obs/sec  10.035200         147   \n",
       "5    2016-10-22 16:16:01  26.327 sec  29410 obs/sec  10.035200         147   \n",
       "\n",
       "    samples  training_rmse  training_logloss  training_classification_error  \\\n",
       "0       0.0            NaN               NaN                            NaN   \n",
       "1    4096.0       0.441615          6.724641                       0.195023   \n",
       "2  364544.0       0.117783          0.474103                       0.013881   \n",
       "3  536576.0       0.073171          0.181555                       0.005354   \n",
       "4  602112.0       0.082110          0.229697                       0.006742   \n",
       "5  602112.0       0.073171          0.181555                       0.005354   \n",
       "\n",
       "   validation_rmse  validation_logloss  validation_classification_error  \n",
       "0              NaN                 NaN                              NaN  \n",
       "1         0.435390            6.528768                           0.1897  \n",
       "2         0.216529            1.616629                           0.0470  \n",
       "3         0.201246            1.393379                           0.0405  \n",
       "4         0.207599            1.482130                           0.0431  \n",
       "5         0.201246            1.393379                           0.0405  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.scoring_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ModelMetricsMultinomial: deepwater\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.00535395537483\n",
      "RMSE: 0.0731707275817\n",
      "LogLoss: 0.181555204236\n",
      "Mean Per-Class Error: 0.0054896656786\n",
      "Confusion Matrix: vertical: actual; across: predicted\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>0</b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>2</b></td>\n",
       "<td><b>3</b></td>\n",
       "<td><b>4</b></td>\n",
       "<td><b>5</b></td>\n",
       "<td><b>6</b></td>\n",
       "<td><b>7</b></td>\n",
       "<td><b>8</b></td>\n",
       "<td><b>9</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>1031.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0 / 1,031</td></tr>\n",
       "<tr><td>0.0</td>\n",
       "<td>1083.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0036799</td>\n",
       "<td>4 / 1,087</td></tr>\n",
       "<tr><td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>978.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0010215</td>\n",
       "<td>1 / 979</td></tr>\n",
       "<tr><td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1016.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>2.0</td>\n",
       "<td>2.0</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0078125</td>\n",
       "<td>8 / 1,024</td></tr>\n",
       "<tr><td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>987.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0</td>\n",
       "<td>6.0</td>\n",
       "<td>0.0080402</td>\n",
       "<td>8 / 995</td></tr>\n",
       "<tr><td>2.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>882.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>4.0</td>\n",
       "<td>4.0</td>\n",
       "<td>0.015625</td>\n",
       "<td>14 / 896</td></tr>\n",
       "<tr><td>2.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1021.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0048733</td>\n",
       "<td>5 / 1,026</td></tr>\n",
       "<tr><td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1027.0</td>\n",
       "<td>0.0</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0029126</td>\n",
       "<td>3 / 1,030</td></tr>\n",
       "<tr><td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>3.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>995.0</td>\n",
       "<td>4.0</td>\n",
       "<td>0.0079761</td>\n",
       "<td>8 / 1,003</td></tr>\n",
       "<tr><td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1012.0</td>\n",
       "<td>0.0029557</td>\n",
       "<td>3 / 1,015</td></tr>\n",
       "<tr><td>1036.0</td>\n",
       "<td>1085.0</td>\n",
       "<td>985.0</td>\n",
       "<td>1017.0</td>\n",
       "<td>989.0</td>\n",
       "<td>883.0</td>\n",
       "<td>1022.0</td>\n",
       "<td>1035.0</td>\n",
       "<td>1002.0</td>\n",
       "<td>1032.0</td>\n",
       "<td>0.0053540</td>\n",
       "<td>54 / 10,086</td></tr></table></div>"
      ],
      "text/plain": [
       "0     1     2    3     4    5    6     7     8     9     Error       Rate\n",
       "----  ----  ---  ----  ---  ---  ----  ----  ----  ----  ----------  -----------\n",
       "1031  0     0    0     0    0    0     0     0     0     0           0 / 1,031\n",
       "0     1083  1    0     1    0    0     0     1     1     0.00367985  4 / 1,087\n",
       "1     0     978  0     0    0    0     0     0     0     0.00102145  1 / 979\n",
       "0     0     1    1016  0    1    0     2     2     2     0.0078125   8 / 1,024\n",
       "0     0     0    0     987  0    0     2     0     6     0.0080402   8 / 995\n",
       "2     0     1    1     0    882  1     1     4     4     0.015625    14 / 896\n",
       "2     0     1    0     0    0    1021  1     0     1     0.00487329  5 / 1,026\n",
       "0     1     0    0     0    0    0     1027  0     2     0.00291262  3 / 1,030\n",
       "0     1     3    0     0    0    0     0     995   4     0.00797607  8 / 1,003\n",
       "0     0     0    0     1    0    0     2     0     1012  0.00295567  3 / 1,015\n",
       "1036  1085  985  1017  989  883  1022  1035  1002  1032  0.00535396  54 / 10,086"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-10 Hit Ratios: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>k</b></td>\n",
       "<td><b>hit_ratio</b></td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>0.9946461</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.9953401</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.9953401</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.9953401</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.9953401</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.9953401</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.9953401</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.9953401</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.9953401</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>1.0</td></tr></table></div>"
      ],
      "text/plain": [
       "k    hit_ratio\n",
       "---  -----------\n",
       "1    0.994646\n",
       "2    0.99534\n",
       "3    0.99534\n",
       "4    0.99534\n",
       "5    0.99534\n",
       "6    0.99534\n",
       "7    0.99534\n",
       "8    0.99534\n",
       "9    0.99534\n",
       "10   1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model_performance(train=True) # training metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ModelMetricsMultinomial: deepwater\n",
      "** Reported on validation data. **\n",
      "\n",
      "MSE: 0.0405000286035\n",
      "RMSE: 0.201246189041\n",
      "LogLoss: 1.39337901019\n",
      "Mean Per-Class Error: 0.0410887020497\n",
      "Confusion Matrix: vertical: actual; across: predicted\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>0</b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>2</b></td>\n",
       "<td><b>3</b></td>\n",
       "<td><b>4</b></td>\n",
       "<td><b>5</b></td>\n",
       "<td><b>6</b></td>\n",
       "<td><b>7</b></td>\n",
       "<td><b>8</b></td>\n",
       "<td><b>9</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>963.0</td>\n",
       "<td>1.0</td>\n",
       "<td>4.0</td>\n",
       "<td>1.0</td>\n",
       "<td>2.0</td>\n",
       "<td>1.0</td>\n",
       "<td>3.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>3.0</td>\n",
       "<td>0.0173469</td>\n",
       "<td>17 / 980</td></tr>\n",
       "<tr><td>1.0</td>\n",
       "<td>1116.0</td>\n",
       "<td>5.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>3.0</td>\n",
       "<td>2.0</td>\n",
       "<td>5.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0167401</td>\n",
       "<td>19 / 1,135</td></tr>\n",
       "<tr><td>5.0</td>\n",
       "<td>2.0</td>\n",
       "<td>997.0</td>\n",
       "<td>3.0</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0</td>\n",
       "<td>4.0</td>\n",
       "<td>7.0</td>\n",
       "<td>11.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0339147</td>\n",
       "<td>35 / 1,032</td></tr>\n",
       "<tr><td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>8.0</td>\n",
       "<td>972.0</td>\n",
       "<td>1.0</td>\n",
       "<td>6.0</td>\n",
       "<td>0.0</td>\n",
       "<td>8.0</td>\n",
       "<td>4.0</td>\n",
       "<td>10.0</td>\n",
       "<td>0.0376238</td>\n",
       "<td>38 / 1,010</td></tr>\n",
       "<tr><td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>8.0</td>\n",
       "<td>0.0</td>\n",
       "<td>938.0</td>\n",
       "<td>0.0</td>\n",
       "<td>7.0</td>\n",
       "<td>5.0</td>\n",
       "<td>3.0</td>\n",
       "<td>20.0</td>\n",
       "<td>0.0448065</td>\n",
       "<td>44 / 982</td></tr>\n",
       "<tr><td>5.0</td>\n",
       "<td>3.0</td>\n",
       "<td>1.0</td>\n",
       "<td>15.0</td>\n",
       "<td>4.0</td>\n",
       "<td>835.0</td>\n",
       "<td>10.0</td>\n",
       "<td>3.0</td>\n",
       "<td>13.0</td>\n",
       "<td>3.0</td>\n",
       "<td>0.0639013</td>\n",
       "<td>57 / 892</td></tr>\n",
       "<tr><td>15.0</td>\n",
       "<td>3.0</td>\n",
       "<td>2.0</td>\n",
       "<td>1.0</td>\n",
       "<td>7.0</td>\n",
       "<td>6.0</td>\n",
       "<td>913.0</td>\n",
       "<td>1.0</td>\n",
       "<td>8.0</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0469729</td>\n",
       "<td>45 / 958</td></tr>\n",
       "<tr><td>2.0</td>\n",
       "<td>4.0</td>\n",
       "<td>16.0</td>\n",
       "<td>4.0</td>\n",
       "<td>4.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>979.0</td>\n",
       "<td>2.0</td>\n",
       "<td>17.0</td>\n",
       "<td>0.0476654</td>\n",
       "<td>49 / 1,028</td></tr>\n",
       "<tr><td>4.0</td>\n",
       "<td>2.0</td>\n",
       "<td>8.0</td>\n",
       "<td>8.0</td>\n",
       "<td>6.0</td>\n",
       "<td>6.0</td>\n",
       "<td>1.0</td>\n",
       "<td>7.0</td>\n",
       "<td>923.0</td>\n",
       "<td>9.0</td>\n",
       "<td>0.0523614</td>\n",
       "<td>51 / 974</td></tr>\n",
       "<tr><td>4.0</td>\n",
       "<td>2.0</td>\n",
       "<td>5.0</td>\n",
       "<td>5.0</td>\n",
       "<td>7.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>18.0</td>\n",
       "<td>7.0</td>\n",
       "<td>959.0</td>\n",
       "<td>0.0495540</td>\n",
       "<td>50 / 1,009</td></tr>\n",
       "<tr><td>1001.0</td>\n",
       "<td>1133.0</td>\n",
       "<td>1054.0</td>\n",
       "<td>1010.0</td>\n",
       "<td>972.0</td>\n",
       "<td>856.0</td>\n",
       "<td>942.0</td>\n",
       "<td>1031.0</td>\n",
       "<td>977.0</td>\n",
       "<td>1024.0</td>\n",
       "<td>0.0405</td>\n",
       "<td>405 / 10,000</td></tr></table></div>"
      ],
      "text/plain": [
       "0     1     2     3     4    5    6    7     8    9     Error      Rate\n",
       "----  ----  ----  ----  ---  ---  ---  ----  ---  ----  ---------  ------------\n",
       "963   1     4     1     2    1    3    1     1    3     0.0173469  17 / 980\n",
       "1     1116  5     1     1    1    3    2     5    0     0.0167401  19 / 1,135\n",
       "5     2     997   3     2    0    4    7     11   1     0.0339147  35 / 1,032\n",
       "1     0     8     972   1    6    0    8     4    10    0.0376238  38 / 1,010\n",
       "1     0     8     0     938  0    7    5     3    20    0.0448065  44 / 982\n",
       "5     3     1     15    4    835  10   3     13   3     0.0639013  57 / 892\n",
       "15    3     2     1     7    6    913  1     8    2     0.0469729  45 / 958\n",
       "2     4     16    4     4    0    0    979   2    17    0.0476654  49 / 1,028\n",
       "4     2     8     8     6    6    1    7     923  9     0.0523614  51 / 974\n",
       "4     2     5     5     7    1    1    18    7    959   0.049554   50 / 1,009\n",
       "1001  1133  1054  1010  972  856  942  1031  977  1024  0.0405     405 / 10,000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-10 Hit Ratios: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>k</b></td>\n",
       "<td><b>hit_ratio</b></td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>0.9595</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.9641</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.9642</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.9642</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.9642</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.9642</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.9642</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.9642</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.9642</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>1.0</td></tr></table></div>"
      ],
      "text/plain": [
       "k    hit_ratio\n",
       "---  -----------\n",
       "1    0.9595\n",
       "2    0.9641\n",
       "3    0.9642\n",
       "4    0.9642\n",
       "5    0.9642\n",
       "6    0.9642\n",
       "7    0.9642\n",
       "8    0.9642\n",
       "9    0.9642\n",
       "10   1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model_performance(valid=True) # validation metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Crossvalidation\n",
    "\n",
    "If the value specified for nfolds is a positive integer, N-fold cross-validation is\n",
    "performed on the training frame and the cross-validation metrics are computed\n",
    "and stored as model output. \n",
    "\n",
    "To disable cross-validation, use `nfolds=0`, which is the default value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Advanced users can also specify a fold column that defines the holdout\n",
    "fold associated with each row. By default, the holdout fold assignment is\n",
    "random. H2O supports other schemes such as round-robin assignment using the modulo\n",
    "operator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform 3-fold cross-validation on training_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_crossvalidated = H2ODeepWaterEstimator(\n",
    "   distribution=\"multinomial\",\n",
    "   activation=\"rectifier\",\n",
    "   mini_batch_size=128,\n",
    "   hidden=[1024,1024],\n",
    "   hidden_dropout_ratios=[0.5,0.5],\n",
    "   input_dropout_ratio=0.1,\n",
    "   sparse=True,\n",
    "   epochs=10,\n",
    "   nfolds=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deepwater Model Build progress: |█████████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "model_crossvalidated.train(\n",
    "    x=x,\n",
    "    y=y,\n",
    "    training_frame=train_df\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting and Handling the Results\n",
    "\n",
    "We can now extract the parameters of our model, examine the scoring process,\n",
    "and make predictions on new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# View specified parameters of the Deep Learning model\n",
    "model_crossvalidated.params;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details\n",
      "=============\n",
      "H2ODeepWaterEstimator :  Deep Water\n",
      "Model Key:  DeepWater_model_python_1477177984287_2\n",
      "Status of Deep Learning Model: MLP: [1024, 1024], 6.9 MB, predicting C785, 10-class classification, 606,208 training samples, mini-batch size 128\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>input_neurons</b></td>\n",
       "<td><b>rate</b></td>\n",
       "<td><b>momentum</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>717</td>\n",
       "<td>0.0031129</td>\n",
       "<td>0.99</td></tr></table></div>"
      ],
      "text/plain": [
       "    input_neurons    rate        momentum\n",
       "--  ---------------  ----------  ----------\n",
       "    717              0.00311292  0.99"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsMultinomial: deepwater\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.00443951165372\n",
      "RMSE: 0.0666296604653\n",
      "LogLoss: 0.153033117617\n",
      "Mean Per-Class Error: 0.00445641515867\n",
      "Confusion Matrix: vertical: actual; across: predicted\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>0</b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>2</b></td>\n",
       "<td><b>3</b></td>\n",
       "<td><b>4</b></td>\n",
       "<td><b>5</b></td>\n",
       "<td><b>6</b></td>\n",
       "<td><b>7</b></td>\n",
       "<td><b>8</b></td>\n",
       "<td><b>9</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>938.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0010650</td>\n",
       "<td>1 / 939</td></tr>\n",
       "<tr><td>0.0</td>\n",
       "<td>1112.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0026906</td>\n",
       "<td>3 / 1,115</td></tr>\n",
       "<tr><td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>980.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0010194</td>\n",
       "<td>1 / 981</td></tr>\n",
       "<tr><td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>957.0</td>\n",
       "<td>1.0</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0062305</td>\n",
       "<td>6 / 963</td></tr>\n",
       "<tr><td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>996.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0010030</td>\n",
       "<td>1 / 997</td></tr>\n",
       "<tr><td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>901.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0022148</td>\n",
       "<td>2 / 903</td></tr>\n",
       "<tr><td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>4.0</td>\n",
       "<td>957.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0051975</td>\n",
       "<td>5 / 962</td></tr>\n",
       "<tr><td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1041.0</td>\n",
       "<td>0.0</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0047801</td>\n",
       "<td>5 / 1,046</td></tr>\n",
       "<tr><td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>2.0</td>\n",
       "<td>5.0</td>\n",
       "<td>2.0</td>\n",
       "<td>3.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>949.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0155602</td>\n",
       "<td>15 / 964</td></tr>\n",
       "<tr><td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>3.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1036.0</td>\n",
       "<td>0.0048031</td>\n",
       "<td>5 / 1,041</td></tr>\n",
       "<tr><td>940.0</td>\n",
       "<td>1112.0</td>\n",
       "<td>984.0</td>\n",
       "<td>964.0</td>\n",
       "<td>1002.0</td>\n",
       "<td>912.0</td>\n",
       "<td>958.0</td>\n",
       "<td>1045.0</td>\n",
       "<td>955.0</td>\n",
       "<td>1039.0</td>\n",
       "<td>0.0044395</td>\n",
       "<td>44 / 9,911</td></tr></table></div>"
      ],
      "text/plain": [
       "0    1     2    3    4     5    6    7     8    9     Error       Rate\n",
       "---  ----  ---  ---  ----  ---  ---  ----  ---  ----  ----------  ----------\n",
       "938  0     0    0    0     1    0    0     0    0     0.00106496  1 / 939\n",
       "0    1112  0    0    0     0    0    1     2    0     0.00269058  3 / 1,115\n",
       "0    0     980  1    0     0    0    0     0    0     0.00101937  1 / 981\n",
       "0    0     1    957  1     2    0    0     2    0     0.00623053  6 / 963\n",
       "1    0     0    0    996   0    0    0     0    0     0.00100301  1 / 997\n",
       "0    0     0    1    0     901  0    0     1    0     0.00221484  2 / 903\n",
       "0    0     0    0    0     4    957  0     1    0     0.00519751  5 / 962\n",
       "1    0     1    0    0     1    0    1041  0    2     0.00478011  5 / 1,046\n",
       "0    0     2    5    2     3    1    1     949  1     0.0155602   15 / 964\n",
       "0    0     0    0    3     0    0    2     0    1036  0.00480307  5 / 1,041\n",
       "940  1112  984  964  1002  912  958  1045  955  1039  0.00443951  44 / 9,911"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-10 Hit Ratios: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>k</b></td>\n",
       "<td><b>hit_ratio</b></td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>0.9955605</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.9961659</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.9961659</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.9961659</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.9961659</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.9961659</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.9961659</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.9961659</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.9961659</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>1.0</td></tr></table></div>"
      ],
      "text/plain": [
       "k    hit_ratio\n",
       "---  -----------\n",
       "1    0.99556\n",
       "2    0.996166\n",
       "3    0.996166\n",
       "4    0.996166\n",
       "5    0.996166\n",
       "6    0.996166\n",
       "7    0.996166\n",
       "8    0.996166\n",
       "9    0.996166\n",
       "10   1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ModelMetricsMultinomial: deepwater\n",
      "** Reported on cross-validation data. **\n",
      "\n",
      "MSE: 0.0497036014142\n",
      "RMSE: 0.222943045225\n",
      "LogLoss: 1.70928167007\n",
      "Mean Per-Class Error: 0.0502742055267\n",
      "Confusion Matrix: vertical: actual; across: predicted\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>0</b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>2</b></td>\n",
       "<td><b>3</b></td>\n",
       "<td><b>4</b></td>\n",
       "<td><b>5</b></td>\n",
       "<td><b>6</b></td>\n",
       "<td><b>7</b></td>\n",
       "<td><b>8</b></td>\n",
       "<td><b>9</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>5793.0</td>\n",
       "<td>2.0</td>\n",
       "<td>20.0</td>\n",
       "<td>11.0</td>\n",
       "<td>5.0</td>\n",
       "<td>22.0</td>\n",
       "<td>33.0</td>\n",
       "<td>10.0</td>\n",
       "<td>19.0</td>\n",
       "<td>8.0</td>\n",
       "<td>0.0219483</td>\n",
       "<td>130 / 5,923</td></tr>\n",
       "<tr><td>2.0</td>\n",
       "<td>6589.0</td>\n",
       "<td>44.0</td>\n",
       "<td>21.0</td>\n",
       "<td>10.0</td>\n",
       "<td>8.0</td>\n",
       "<td>10.0</td>\n",
       "<td>25.0</td>\n",
       "<td>29.0</td>\n",
       "<td>4.0</td>\n",
       "<td>0.0226936</td>\n",
       "<td>153 / 6,742</td></tr>\n",
       "<tr><td>28.0</td>\n",
       "<td>25.0</td>\n",
       "<td>5647.0</td>\n",
       "<td>61.0</td>\n",
       "<td>36.0</td>\n",
       "<td>15.0</td>\n",
       "<td>27.0</td>\n",
       "<td>52.0</td>\n",
       "<td>57.0</td>\n",
       "<td>10.0</td>\n",
       "<td>0.0521987</td>\n",
       "<td>311 / 5,958</td></tr>\n",
       "<tr><td>8.0</td>\n",
       "<td>8.0</td>\n",
       "<td>85.0</td>\n",
       "<td>5805.0</td>\n",
       "<td>5.0</td>\n",
       "<td>73.0</td>\n",
       "<td>4.0</td>\n",
       "<td>35.0</td>\n",
       "<td>72.0</td>\n",
       "<td>36.0</td>\n",
       "<td>0.0531724</td>\n",
       "<td>326 / 6,131</td></tr>\n",
       "<tr><td>10.0</td>\n",
       "<td>24.0</td>\n",
       "<td>43.0</td>\n",
       "<td>7.0</td>\n",
       "<td>5521.0</td>\n",
       "<td>13.0</td>\n",
       "<td>43.0</td>\n",
       "<td>32.0</td>\n",
       "<td>26.0</td>\n",
       "<td>123.0</td>\n",
       "<td>0.0549469</td>\n",
       "<td>321 / 5,842</td></tr>\n",
       "<tr><td>31.0</td>\n",
       "<td>8.0</td>\n",
       "<td>13.0</td>\n",
       "<td>124.0</td>\n",
       "<td>20.0</td>\n",
       "<td>5068.0</td>\n",
       "<td>56.0</td>\n",
       "<td>17.0</td>\n",
       "<td>62.0</td>\n",
       "<td>22.0</td>\n",
       "<td>0.0651171</td>\n",
       "<td>353 / 5,421</td></tr>\n",
       "<tr><td>35.0</td>\n",
       "<td>14.0</td>\n",
       "<td>36.0</td>\n",
       "<td>9.0</td>\n",
       "<td>22.0</td>\n",
       "<td>59.0</td>\n",
       "<td>5721.0</td>\n",
       "<td>1.0</td>\n",
       "<td>21.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0332883</td>\n",
       "<td>197 / 5,918</td></tr>\n",
       "<tr><td>14.0</td>\n",
       "<td>23.0</td>\n",
       "<td>47.0</td>\n",
       "<td>31.0</td>\n",
       "<td>32.0</td>\n",
       "<td>12.0</td>\n",
       "<td>4.0</td>\n",
       "<td>6025.0</td>\n",
       "<td>14.0</td>\n",
       "<td>63.0</td>\n",
       "<td>0.0383081</td>\n",
       "<td>240 / 6,265</td></tr>\n",
       "<tr><td>24.0</td>\n",
       "<td>20.0</td>\n",
       "<td>49.0</td>\n",
       "<td>95.0</td>\n",
       "<td>17.0</td>\n",
       "<td>75.0</td>\n",
       "<td>37.0</td>\n",
       "<td>16.0</td>\n",
       "<td>5481.0</td>\n",
       "<td>37.0</td>\n",
       "<td>0.0632371</td>\n",
       "<td>370 / 5,851</td></tr>\n",
       "<tr><td>23.0</td>\n",
       "<td>14.0</td>\n",
       "<td>27.0</td>\n",
       "<td>66.0</td>\n",
       "<td>119.0</td>\n",
       "<td>50.0</td>\n",
       "<td>1.0</td>\n",
       "<td>219.0</td>\n",
       "<td>63.0</td>\n",
       "<td>5367.0</td>\n",
       "<td>0.0978316</td>\n",
       "<td>582 / 5,949</td></tr>\n",
       "<tr><td>5968.0</td>\n",
       "<td>6727.0</td>\n",
       "<td>6011.0</td>\n",
       "<td>6230.0</td>\n",
       "<td>5787.0</td>\n",
       "<td>5395.0</td>\n",
       "<td>5936.0</td>\n",
       "<td>6432.0</td>\n",
       "<td>5844.0</td>\n",
       "<td>5670.0</td>\n",
       "<td>0.0497167</td>\n",
       "<td>2,983 / 60,000</td></tr></table></div>"
      ],
      "text/plain": [
       "0     1     2     3     4     5     6     7     8     9     Error      Rate\n",
       "----  ----  ----  ----  ----  ----  ----  ----  ----  ----  ---------  --------------\n",
       "5793  2     20    11    5     22    33    10    19    8     0.0219483  130 / 5,923\n",
       "2     6589  44    21    10    8     10    25    29    4     0.0226936  153 / 6,742\n",
       "28    25    5647  61    36    15    27    52    57    10    0.0521987  311 / 5,958\n",
       "8     8     85    5805  5     73    4     35    72    36    0.0531724  326 / 6,131\n",
       "10    24    43    7     5521  13    43    32    26    123   0.0549469  321 / 5,842\n",
       "31    8     13    124   20    5068  56    17    62    22    0.0651171  353 / 5,421\n",
       "35    14    36    9     22    59    5721  1     21    0     0.0332883  197 / 5,918\n",
       "14    23    47    31    32    12    4     6025  14    63    0.0383081  240 / 6,265\n",
       "24    20    49    95    17    75    37    16    5481  37    0.0632371  370 / 5,851\n",
       "23    14    27    66    119   50    1     219   63    5367  0.0978316  582 / 5,949\n",
       "5968  6727  6011  6230  5787  5395  5936  6432  5844  5670  0.0497167  2,983 / 60,000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-10 Hit Ratios: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>k</b></td>\n",
       "<td><b>hit_ratio</b></td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>0.9502833</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.9559</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.9560000</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.9560000</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.9560000</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.9560000</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.9560000</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.9560000</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.9560000</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>1.0</td></tr></table></div>"
      ],
      "text/plain": [
       "k    hit_ratio\n",
       "---  -----------\n",
       "1    0.950283\n",
       "2    0.9559\n",
       "3    0.956\n",
       "4    0.956\n",
       "5    0.956\n",
       "6    0.956\n",
       "7    0.956\n",
       "8    0.956\n",
       "9    0.956\n",
       "10   1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Metrics Summary: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>mean</b></td>\n",
       "<td><b>sd</b></td>\n",
       "<td><b>cv_1_valid</b></td>\n",
       "<td><b>cv_2_valid</b></td>\n",
       "<td><b>cv_3_valid</b></td></tr>\n",
       "<tr><td>accuracy</td>\n",
       "<td>0.9502770</td>\n",
       "<td>0.0012299</td>\n",
       "<td>0.9527195</td>\n",
       "<td>0.9488038</td>\n",
       "<td>0.9493078</td></tr>\n",
       "<tr><td>err</td>\n",
       "<td>0.0497230</td>\n",
       "<td>0.0012299</td>\n",
       "<td>0.0472805</td>\n",
       "<td>0.0511962</td>\n",
       "<td>0.0506922</td></tr>\n",
       "<tr><td>err_count</td>\n",
       "<td>994.3333</td>\n",
       "<td>22.281033</td>\n",
       "<td>951.0</td>\n",
       "<td>1025.0</td>\n",
       "<td>1007.0</td></tr>\n",
       "<tr><td>logloss</td>\n",
       "<td>1.7095025</td>\n",
       "<td>0.0429481</td>\n",
       "<td>1.6241807</td>\n",
       "<td>1.7607509</td>\n",
       "<td>1.743576</td></tr>\n",
       "<tr><td>max_per_class_error</td>\n",
       "<td>0.1052511</td>\n",
       "<td>0.0151969</td>\n",
       "<td>0.0754148</td>\n",
       "<td>0.1151515</td>\n",
       "<td>0.1251870</td></tr>\n",
       "<tr><td>mean_per_class_accuracy</td>\n",
       "<td>0.9497648</td>\n",
       "<td>0.0012523</td>\n",
       "<td>0.9522545</td>\n",
       "<td>0.9482830</td>\n",
       "<td>0.9487571</td></tr>\n",
       "<tr><td>mean_per_class_error</td>\n",
       "<td>0.0502352</td>\n",
       "<td>0.0012523</td>\n",
       "<td>0.0477455</td>\n",
       "<td>0.0517170</td>\n",
       "<td>0.0512429</td></tr>\n",
       "<tr><td>mse</td>\n",
       "<td>0.0497099</td>\n",
       "<td>0.0012312</td>\n",
       "<td>0.0472664</td>\n",
       "<td>0.0511962</td>\n",
       "<td>0.0506670</td></tr>\n",
       "<tr><td>r2</td>\n",
       "<td>0.9940445</td>\n",
       "<td>0.0001528</td>\n",
       "<td>0.9943481</td>\n",
       "<td>0.9938622</td>\n",
       "<td>0.9939232</td></tr>\n",
       "<tr><td>rmse</td>\n",
       "<td>0.2229225</td>\n",
       "<td>0.0027777</td>\n",
       "<td>0.2174084</td>\n",
       "<td>0.2262657</td>\n",
       "<td>0.2250934</td></tr></table></div>"
      ],
      "text/plain": [
       "                         mean       sd           cv_1_valid    cv_2_valid    cv_3_valid\n",
       "-----------------------  ---------  -----------  ------------  ------------  ------------\n",
       "accuracy                 0.950277   0.00122987   0.95272       0.948804      0.949308\n",
       "err                      0.049723   0.00122987   0.0472805     0.0511962     0.0506922\n",
       "err_count                994.333    22.281       951           1025          1007\n",
       "logloss                  1.7095     0.0429481    1.62418       1.76075       1.74358\n",
       "max_per_class_error      0.105251   0.0151969    0.0754148     0.115152      0.125187\n",
       "mean_per_class_accuracy  0.949765   0.00125231   0.952255      0.948283      0.948757\n",
       "mean_per_class_error     0.0502352  0.00125231   0.0477455     0.051717      0.0512429\n",
       "mse                      0.0497099  0.00123124   0.0472664     0.0511962     0.050667\n",
       "r2                       0.994044   0.000152811  0.994348      0.993862      0.993923\n",
       "rmse                     0.222922   0.00277774   0.217408      0.226266      0.225093"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring History: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>timestamp</b></td>\n",
       "<td><b>duration</b></td>\n",
       "<td><b>training_speed</b></td>\n",
       "<td><b>epochs</b></td>\n",
       "<td><b>iterations</b></td>\n",
       "<td><b>samples</b></td>\n",
       "<td><b>training_rmse</b></td>\n",
       "<td><b>training_logloss</b></td>\n",
       "<td><b>training_classification_error</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-10-22 16:17:25</td>\n",
       "<td> 0.000 sec</td>\n",
       "<td>None</td>\n",
       "<td>0.0</td>\n",
       "<td>0</td>\n",
       "<td>0.0</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-10-22 16:17:25</td>\n",
       "<td>58.765 sec</td>\n",
       "<td>8904 obs/sec</td>\n",
       "<td>0.0682667</td>\n",
       "<td>1</td>\n",
       "<td>4096.0</td>\n",
       "<td>0.4678275</td>\n",
       "<td>7.5501838</td>\n",
       "<td>0.2188477</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-10-22 16:17:31</td>\n",
       "<td> 1 min  3.761 sec</td>\n",
       "<td>22187 obs/sec</td>\n",
       "<td>1.9114667</td>\n",
       "<td>28</td>\n",
       "<td>114688.0</td>\n",
       "<td>0.2033903</td>\n",
       "<td>1.4237567</td>\n",
       "<td>0.0413682</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-10-22 16:17:36</td>\n",
       "<td> 1 min  8.891 sec</td>\n",
       "<td>26288 obs/sec</td>\n",
       "<td>4.3690667</td>\n",
       "<td>64</td>\n",
       "<td>262144.0</td>\n",
       "<td>0.1454039</td>\n",
       "<td>0.7274323</td>\n",
       "<td>0.0211886</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-10-22 16:17:41</td>\n",
       "<td> 1 min 13.994 sec</td>\n",
       "<td>27225 obs/sec</td>\n",
       "<td>6.6901333</td>\n",
       "<td>98</td>\n",
       "<td>401408.0</td>\n",
       "<td>0.1039042</td>\n",
       "<td>0.3688878</td>\n",
       "<td>0.0107961</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-10-22 16:17:46</td>\n",
       "<td> 1 min 19.110 sec</td>\n",
       "<td>28097 obs/sec</td>\n",
       "<td>9.1477333</td>\n",
       "<td>134</td>\n",
       "<td>548864.0</td>\n",
       "<td>0.0834384</td>\n",
       "<td>0.2397173</td>\n",
       "<td>0.0069620</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-10-22 16:17:48</td>\n",
       "<td> 1 min 21.342 sec</td>\n",
       "<td>28257 obs/sec</td>\n",
       "<td>10.1034667</td>\n",
       "<td>148</td>\n",
       "<td>606208.0</td>\n",
       "<td>0.0666297</td>\n",
       "<td>0.1530331</td>\n",
       "<td>0.0044395</td></tr></table></div>"
      ],
      "text/plain": [
       "    timestamp            duration          training_speed    epochs     iterations    samples    training_rmse    training_logloss    training_classification_error\n",
       "--  -------------------  ----------------  ----------------  ---------  ------------  ---------  ---------------  ------------------  -------------------------------\n",
       "    2016-10-22 16:17:25  0.000 sec                           0          0             0          nan              nan                 nan\n",
       "    2016-10-22 16:17:25  58.765 sec        8904 obs/sec      0.0682667  1             4096       0.467828         7.55018             0.218848\n",
       "    2016-10-22 16:17:31  1 min  3.761 sec  22187 obs/sec     1.91147    28            114688     0.20339          1.42376             0.0413682\n",
       "    2016-10-22 16:17:36  1 min  8.891 sec  26288 obs/sec     4.36907    64            262144     0.145404         0.727432            0.0211886\n",
       "    2016-10-22 16:17:41  1 min 13.994 sec  27225 obs/sec     6.69013    98            401408     0.103904         0.368888            0.0107961\n",
       "    2016-10-22 16:17:46  1 min 19.110 sec  28097 obs/sec     9.14773    134           548864     0.0834384        0.239717            0.00696196\n",
       "    2016-10-22 16:17:48  1 min 21.342 sec  28257 obs/sec     10.1035    148           606208     0.0666297        0.153033            0.00443951"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine the trained model\n",
    "model_crossvalidated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The validation error is based on the\n",
    "parameter `score validation samples`, which configures the same value\n",
    "on the validation set (by default, this is the entire validation set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.041088702049682575"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Validation error of the original model (using a train/valid split)\n",
    "model.mean_per_class_error(valid=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004456415158673083"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Training error of the model trained on 100% of the data\n",
    "model_crossvalidated.mean_per_class_error(train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05027420552670313"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Estimated generalization error of the cross-validated model\n",
    "model_crossvalidated.mean_per_class_error(xval=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#ls ../../h2o-docs/src/booklets/v2_2015/source/images/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Predicting\n",
    "\n",
    "Once we have a satisfactory model (as determined by the validation or crossvalidation\n",
    "metrics), use the `h2o.predict()` command to compute and store\n",
    "predictions on new data for additional refinements in the interactive data science\n",
    "process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deepwater prediction progress: |██████████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "predictions = model_crossvalidated.predict(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows:10000\n",
      "Cols:11\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>       </th><th>predict  </th><th>p0            </th><th>p1            </th><th>p2            </th><th>p3            </th><th>p4            </th><th>p5             </th><th>p6           </th><th>p7            </th><th>p8             </th><th>p9             </th></tr>\n",
       "<tr><td>type   </td><td>enum     </td><td>int           </td><td>int           </td><td>real          </td><td>real          </td><td>real          </td><td>real           </td><td>real         </td><td>real          </td><td>real           </td><td>real           </td></tr>\n",
       "<tr><td>mins   </td><td>0.0      </td><td>0.0           </td><td>0.0           </td><td>0.0           </td><td>0.0           </td><td>0.0           </td><td>0.0            </td><td>0.0          </td><td>0.0           </td><td>0.0            </td><td>0.0            </td></tr>\n",
       "<tr><td>mean   </td><td>NaN      </td><td>0.0982        </td><td>0.1138        </td><td>0.103076418841</td><td>0.101199999976</td><td>0.1004        </td><td>0.0922235811847</td><td>0.0947       </td><td>0.102301612182</td><td>0.0943000000032</td><td>0.0997983878136</td></tr>\n",
       "<tr><td>maxs   </td><td>9.0      </td><td>1.0           </td><td>1.0           </td><td>1.0           </td><td>1.0           </td><td>1.0           </td><td>1.0            </td><td>1.0          </td><td>1.0           </td><td>1.0            </td><td>1.0            </td></tr>\n",
       "<tr><td>sigma  </td><td>NaN      </td><td>0.297599759008</td><td>0.317584077001</td><td>0.304044231257</td><td>0.301608449356</td><td>0.300547621663</td><td>0.289324631959 </td><td>0.29281476064</td><td>0.30305707465 </td><td>0.292260246364 </td><td>0.299743336899 </td></tr>\n",
       "<tr><td>zeros  </td><td>982      </td><td>9018          </td><td>8862          </td><td>8968          </td><td>8987          </td><td>8994          </td><td>9071           </td><td>9052         </td><td>8975          </td><td>9055           </td><td>9000           </td></tr>\n",
       "<tr><td>missing</td><td>0        </td><td>0             </td><td>0             </td><td>0             </td><td>0             </td><td>0             </td><td>0              </td><td>0            </td><td>0             </td><td>0              </td><td>0              </td></tr>\n",
       "<tr><td>0      </td><td>8        </td><td>0.0           </td><td>0.0           </td><td>0.0           </td><td>0.0           </td><td>0.0           </td><td>0.0            </td><td>0.0          </td><td>0.0           </td><td>1.0            </td><td>0.0            </td></tr>\n",
       "<tr><td>1      </td><td>3        </td><td>0.0           </td><td>0.0           </td><td>0.0           </td><td>1.0           </td><td>0.0           </td><td>0.0            </td><td>0.0          </td><td>0.0           </td><td>0.0            </td><td>0.0            </td></tr>\n",
       "<tr><td>2      </td><td>6        </td><td>0.0           </td><td>0.0           </td><td>0.0           </td><td>0.0           </td><td>0.0           </td><td>0.0            </td><td>1.0          </td><td>0.0           </td><td>0.0            </td><td>0.0            </td></tr>\n",
       "<tr><td>3      </td><td>0        </td><td>1.0           </td><td>0.0           </td><td>0.0           </td><td>0.0           </td><td>0.0           </td><td>0.0            </td><td>0.0          </td><td>0.0           </td><td>0.0            </td><td>0.0            </td></tr>\n",
       "<tr><td>4      </td><td>1        </td><td>0.0           </td><td>1.0           </td><td>0.0           </td><td>0.0           </td><td>0.0           </td><td>0.0            </td><td>0.0          </td><td>0.0           </td><td>0.0            </td><td>0.0            </td></tr>\n",
       "<tr><td>5      </td><td>5        </td><td>0.0           </td><td>0.0           </td><td>0.0           </td><td>0.0           </td><td>0.0           </td><td>1.0            </td><td>0.0          </td><td>0.0           </td><td>0.0            </td><td>0.0            </td></tr>\n",
       "<tr><td>6      </td><td>0        </td><td>1.0           </td><td>0.0           </td><td>0.0           </td><td>0.0           </td><td>0.0           </td><td>0.0            </td><td>0.0          </td><td>0.0           </td><td>0.0            </td><td>0.0            </td></tr>\n",
       "<tr><td>7      </td><td>1        </td><td>0.0           </td><td>1.0           </td><td>0.0           </td><td>0.0           </td><td>0.0           </td><td>0.0            </td><td>0.0          </td><td>0.0           </td><td>0.0            </td><td>0.0            </td></tr>\n",
       "<tr><td>8      </td><td>5        </td><td>0.0           </td><td>0.0           </td><td>0.0           </td><td>0.0           </td><td>0.0           </td><td>1.0            </td><td>0.0          </td><td>0.0           </td><td>0.0            </td><td>0.0            </td></tr>\n",
       "<tr><td>9      </td><td>2        </td><td>0.0           </td><td>0.0           </td><td>1.0           </td><td>0.0           </td><td>0.0           </td><td>0.0            </td><td>0.0          </td><td>0.0           </td><td>0.0            </td><td>0.0            </td></tr>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable Importance\n",
    "\n",
    "Variable importance allows us to view the absolute and relative predictive strength of\n",
    "each feature in the prediction task.\n",
    "Each H2O algorithm class has its own methodology for computing variable importance.\n",
    "\n",
    "You can enable the variable importance, by setting the `variable_importances` parameter to `True`.\n",
    "\n",
    "H2O’s Deep Learning uses the Gedeon method [Gedeon, 1997](http://users.cecs.anu.edu.au/~Tom.Gedeon/pdfs/ContribDataMinv2.pdf), which is disabled\n",
    "by default since it can be slow for large networks. \n",
    "\n",
    "If variable importance is a top priority in your analysis, consider training a Distributed Random Forest (DRF) model and compare the generated variable importances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train Deep Learning model and validate on test set and save the variable importances\n",
    "from h2o.estimators.deeplearning import H2ODeepLearningEstimator\n",
    "\n",
    "model_variable_importances = H2ODeepLearningEstimator(\n",
    "     distribution=\"multinomial\",\n",
    "     activation=\"RectifierWithDropout\",  ## shortcut for hidden_dropout_ratios=[0.5,0.5,0.5]\n",
    "     hidden=[32,32,32],         ## smaller number of neurons to be fast enough on the CPU\n",
    "     input_dropout_ratio=0.1,\n",
    "     sparse=True,\n",
    "     epochs=1,                  ## not interested in a good model here\n",
    "     variable_importances=True) ## this is not yet implemented for DeepWaterEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deeplearning Model Build progress: |██████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "model_variable_importances.train(\n",
    "         x=x,\n",
    "         y=y,\n",
    "         training_frame=train_df,\n",
    "         validation_frame=test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C376</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.002370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C404</td>\n",
       "      <td>0.962016</td>\n",
       "      <td>0.962016</td>\n",
       "      <td>0.002280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C403</td>\n",
       "      <td>0.938726</td>\n",
       "      <td>0.938726</td>\n",
       "      <td>0.002225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C491</td>\n",
       "      <td>0.909402</td>\n",
       "      <td>0.909402</td>\n",
       "      <td>0.002155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C437</td>\n",
       "      <td>0.908268</td>\n",
       "      <td>0.908268</td>\n",
       "      <td>0.002153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>C383</td>\n",
       "      <td>0.898209</td>\n",
       "      <td>0.898209</td>\n",
       "      <td>0.002129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>C409</td>\n",
       "      <td>0.893138</td>\n",
       "      <td>0.893138</td>\n",
       "      <td>0.002117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>C349</td>\n",
       "      <td>0.869302</td>\n",
       "      <td>0.869302</td>\n",
       "      <td>0.002060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>C490</td>\n",
       "      <td>0.865967</td>\n",
       "      <td>0.865967</td>\n",
       "      <td>0.002053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>C462</td>\n",
       "      <td>0.865739</td>\n",
       "      <td>0.865739</td>\n",
       "      <td>0.002052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>C266</td>\n",
       "      <td>0.864127</td>\n",
       "      <td>0.864127</td>\n",
       "      <td>0.002048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>C405</td>\n",
       "      <td>0.850818</td>\n",
       "      <td>0.850818</td>\n",
       "      <td>0.002017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>C430</td>\n",
       "      <td>0.850699</td>\n",
       "      <td>0.850699</td>\n",
       "      <td>0.002016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>C438</td>\n",
       "      <td>0.834764</td>\n",
       "      <td>0.834764</td>\n",
       "      <td>0.001979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>C435</td>\n",
       "      <td>0.831321</td>\n",
       "      <td>0.831321</td>\n",
       "      <td>0.001970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>C377</td>\n",
       "      <td>0.830762</td>\n",
       "      <td>0.830762</td>\n",
       "      <td>0.001969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>C461</td>\n",
       "      <td>0.828658</td>\n",
       "      <td>0.828658</td>\n",
       "      <td>0.001964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>C489</td>\n",
       "      <td>0.825370</td>\n",
       "      <td>0.825370</td>\n",
       "      <td>0.001956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>C432</td>\n",
       "      <td>0.820596</td>\n",
       "      <td>0.820596</td>\n",
       "      <td>0.001945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>C379</td>\n",
       "      <td>0.817922</td>\n",
       "      <td>0.817922</td>\n",
       "      <td>0.001939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>C487</td>\n",
       "      <td>0.811135</td>\n",
       "      <td>0.811135</td>\n",
       "      <td>0.001923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>C296</td>\n",
       "      <td>0.808639</td>\n",
       "      <td>0.808639</td>\n",
       "      <td>0.001917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>C551</td>\n",
       "      <td>0.806746</td>\n",
       "      <td>0.806746</td>\n",
       "      <td>0.001912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>C517</td>\n",
       "      <td>0.803764</td>\n",
       "      <td>0.803764</td>\n",
       "      <td>0.001905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>C185</td>\n",
       "      <td>0.799801</td>\n",
       "      <td>0.799801</td>\n",
       "      <td>0.001896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>C434</td>\n",
       "      <td>0.798407</td>\n",
       "      <td>0.798407</td>\n",
       "      <td>0.001892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>C351</td>\n",
       "      <td>0.798210</td>\n",
       "      <td>0.798210</td>\n",
       "      <td>0.001892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>C657</td>\n",
       "      <td>0.797321</td>\n",
       "      <td>0.797321</td>\n",
       "      <td>0.001890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>C544</td>\n",
       "      <td>0.796860</td>\n",
       "      <td>0.796860</td>\n",
       "      <td>0.001889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>C402</td>\n",
       "      <td>0.793473</td>\n",
       "      <td>0.793473</td>\n",
       "      <td>0.001881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>C671</td>\n",
       "      <td>0.448475</td>\n",
       "      <td>0.448475</td>\n",
       "      <td>0.001063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>C280</td>\n",
       "      <td>0.448111</td>\n",
       "      <td>0.448111</td>\n",
       "      <td>0.001062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>C777</td>\n",
       "      <td>0.447102</td>\n",
       "      <td>0.447102</td>\n",
       "      <td>0.001060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>C642</td>\n",
       "      <td>0.445417</td>\n",
       "      <td>0.445417</td>\n",
       "      <td>0.001056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>691</th>\n",
       "      <td>C252</td>\n",
       "      <td>0.442050</td>\n",
       "      <td>0.442050</td>\n",
       "      <td>0.001048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>692</th>\n",
       "      <td>C148</td>\n",
       "      <td>0.439204</td>\n",
       "      <td>0.439204</td>\n",
       "      <td>0.001041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693</th>\n",
       "      <td>C639</td>\n",
       "      <td>0.438524</td>\n",
       "      <td>0.438524</td>\n",
       "      <td>0.001039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>C34</td>\n",
       "      <td>0.436605</td>\n",
       "      <td>0.436605</td>\n",
       "      <td>0.001035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>C46</td>\n",
       "      <td>0.434665</td>\n",
       "      <td>0.434665</td>\n",
       "      <td>0.001030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>C135</td>\n",
       "      <td>0.434551</td>\n",
       "      <td>0.434551</td>\n",
       "      <td>0.001030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>C739</td>\n",
       "      <td>0.434410</td>\n",
       "      <td>0.434410</td>\n",
       "      <td>0.001030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>C710</td>\n",
       "      <td>0.433959</td>\n",
       "      <td>0.433959</td>\n",
       "      <td>0.001029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>C168</td>\n",
       "      <td>0.429736</td>\n",
       "      <td>0.429736</td>\n",
       "      <td>0.001019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>C500</td>\n",
       "      <td>0.426615</td>\n",
       "      <td>0.426615</td>\n",
       "      <td>0.001011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701</th>\n",
       "      <td>C61</td>\n",
       "      <td>0.425845</td>\n",
       "      <td>0.425845</td>\n",
       "      <td>0.001009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>702</th>\n",
       "      <td>C190</td>\n",
       "      <td>0.424383</td>\n",
       "      <td>0.424383</td>\n",
       "      <td>0.001006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>703</th>\n",
       "      <td>C603</td>\n",
       "      <td>0.423849</td>\n",
       "      <td>0.423849</td>\n",
       "      <td>0.001005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>C421</td>\n",
       "      <td>0.423479</td>\n",
       "      <td>0.423479</td>\n",
       "      <td>0.001004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>C665</td>\n",
       "      <td>0.422059</td>\n",
       "      <td>0.422059</td>\n",
       "      <td>0.001000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>C695</td>\n",
       "      <td>0.418057</td>\n",
       "      <td>0.418057</td>\n",
       "      <td>0.000991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707</th>\n",
       "      <td>C196</td>\n",
       "      <td>0.415833</td>\n",
       "      <td>0.415833</td>\n",
       "      <td>0.000986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>C335</td>\n",
       "      <td>0.415396</td>\n",
       "      <td>0.415396</td>\n",
       "      <td>0.000985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>C361</td>\n",
       "      <td>0.414638</td>\n",
       "      <td>0.414638</td>\n",
       "      <td>0.000983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>C75</td>\n",
       "      <td>0.414393</td>\n",
       "      <td>0.414393</td>\n",
       "      <td>0.000982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>C147</td>\n",
       "      <td>0.412164</td>\n",
       "      <td>0.412164</td>\n",
       "      <td>0.000977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>C623</td>\n",
       "      <td>0.412055</td>\n",
       "      <td>0.412055</td>\n",
       "      <td>0.000977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>713</th>\n",
       "      <td>C448</td>\n",
       "      <td>0.406959</td>\n",
       "      <td>0.406959</td>\n",
       "      <td>0.000965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714</th>\n",
       "      <td>C91</td>\n",
       "      <td>0.404607</td>\n",
       "      <td>0.404607</td>\n",
       "      <td>0.000959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>C204</td>\n",
       "      <td>0.402561</td>\n",
       "      <td>0.402561</td>\n",
       "      <td>0.000954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>C562</td>\n",
       "      <td>0.392367</td>\n",
       "      <td>0.392367</td>\n",
       "      <td>0.000930</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>717 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3\n",
       "0    C376  1.000000  1.000000  0.002370\n",
       "1    C404  0.962016  0.962016  0.002280\n",
       "2    C403  0.938726  0.938726  0.002225\n",
       "3    C491  0.909402  0.909402  0.002155\n",
       "4    C437  0.908268  0.908268  0.002153\n",
       "5    C383  0.898209  0.898209  0.002129\n",
       "6    C409  0.893138  0.893138  0.002117\n",
       "7    C349  0.869302  0.869302  0.002060\n",
       "8    C490  0.865967  0.865967  0.002053\n",
       "9    C462  0.865739  0.865739  0.002052\n",
       "10   C266  0.864127  0.864127  0.002048\n",
       "11   C405  0.850818  0.850818  0.002017\n",
       "12   C430  0.850699  0.850699  0.002016\n",
       "13   C438  0.834764  0.834764  0.001979\n",
       "14   C435  0.831321  0.831321  0.001970\n",
       "15   C377  0.830762  0.830762  0.001969\n",
       "16   C461  0.828658  0.828658  0.001964\n",
       "17   C489  0.825370  0.825370  0.001956\n",
       "18   C432  0.820596  0.820596  0.001945\n",
       "19   C379  0.817922  0.817922  0.001939\n",
       "20   C487  0.811135  0.811135  0.001923\n",
       "21   C296  0.808639  0.808639  0.001917\n",
       "22   C551  0.806746  0.806746  0.001912\n",
       "23   C517  0.803764  0.803764  0.001905\n",
       "24   C185  0.799801  0.799801  0.001896\n",
       "25   C434  0.798407  0.798407  0.001892\n",
       "26   C351  0.798210  0.798210  0.001892\n",
       "27   C657  0.797321  0.797321  0.001890\n",
       "28   C544  0.796860  0.796860  0.001889\n",
       "29   C402  0.793473  0.793473  0.001881\n",
       "..    ...       ...       ...       ...\n",
       "687  C671  0.448475  0.448475  0.001063\n",
       "688  C280  0.448111  0.448111  0.001062\n",
       "689  C777  0.447102  0.447102  0.001060\n",
       "690  C642  0.445417  0.445417  0.001056\n",
       "691  C252  0.442050  0.442050  0.001048\n",
       "692  C148  0.439204  0.439204  0.001041\n",
       "693  C639  0.438524  0.438524  0.001039\n",
       "694   C34  0.436605  0.436605  0.001035\n",
       "695   C46  0.434665  0.434665  0.001030\n",
       "696  C135  0.434551  0.434551  0.001030\n",
       "697  C739  0.434410  0.434410  0.001030\n",
       "698  C710  0.433959  0.433959  0.001029\n",
       "699  C168  0.429736  0.429736  0.001019\n",
       "700  C500  0.426615  0.426615  0.001011\n",
       "701   C61  0.425845  0.425845  0.001009\n",
       "702  C190  0.424383  0.424383  0.001006\n",
       "703  C603  0.423849  0.423849  0.001005\n",
       "704  C421  0.423479  0.423479  0.001004\n",
       "705  C665  0.422059  0.422059  0.001000\n",
       "706  C695  0.418057  0.418057  0.000991\n",
       "707  C196  0.415833  0.415833  0.000986\n",
       "708  C335  0.415396  0.415396  0.000985\n",
       "709  C361  0.414638  0.414638  0.000983\n",
       "710   C75  0.414393  0.414393  0.000982\n",
       "711  C147  0.412164  0.412164  0.000977\n",
       "712  C623  0.412055  0.412055  0.000977\n",
       "713  C448  0.406959  0.406959  0.000965\n",
       "714   C91  0.404607  0.404607  0.000959\n",
       "715  C204  0.402561  0.402561  0.000954\n",
       "716  C562  0.392367  0.392367  0.000930\n",
       "\n",
       "[717 rows x 4 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve the variable importance\n",
    "import pandas as pd\n",
    "pd.DataFrame(model_variable_importances.varimp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABIUAAANLCAYAAADfCS3nAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQ6IQAAAAQEOiEAAAAEBD/wX9vmVCqS9GkgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4e4ed9b050>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_variable_importances.varimp_plot(num_of_features=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Comparison with Grid Search\n",
    "\n",
    "Grid search provides more subtle insights into the model tuning and selection\n",
    "process by inspecting and comparing our trained models after the grid search process is complete. \n",
    "\n",
    "To learn when and how to select different parameter\n",
    "configurations in a grid search, refer to Parameters for parameter descriptions\n",
    "and configurable values.\n",
    "\n",
    "There are different strategies to explore the hyperparameter combinatorial space:\n",
    "\n",
    "- Cartesian Search: test *every* single combination\n",
    "- Random Search: sample combinations\n",
    "\n",
    "## Cartesian Search\n",
    "In this example, two different network topologies and two different learning rates are specified. This grid search model trains all 4 different models (all possible combinations of these parameters); other parameter combinations can\n",
    "be specified for a larger space of models. Note that the models will most likely\n",
    "converge before the default value of epochs, since early stopping is enabled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from h2o.grid.grid_search import H2OGridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hyper_parameters = {\n",
    "    \"hidden\":[[200,200,200],[300,300]], \n",
    "    \"learning_rate\":[1e-3,5e-3],\n",
    "}\n",
    "\n",
    "model_grid = H2OGridSearch(H2ODeepWaterEstimator, hyper_params=hyper_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deepwater Grid Build progress: |██████████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "model_grid.train(\n",
    "    x=x, \n",
    "    y=y,\n",
    "    distribution=\"multinomial\", \n",
    "    epochs=50,   ## might stop earlier since we enable early stopping below\n",
    "    training_frame=train_df, \n",
    "    validation_frame=test_df,\n",
    "    score_interval=2,                ## score no more than every 2 seconds\n",
    "    score_duty_cycle=0.5,            ## score up to 50% of the time - to enable early stopping\n",
    "    score_training_samples=1000,     ## use a subset of the training frame for faster scoring\n",
    "    score_validation_samples=1000,   ## use a subset of the validation frame for faster scoring\n",
    "    stopping_rounds=3,\n",
    "    stopping_tolerance=0.05,\n",
    "    stopping_metric=\"misclassification\",\n",
    "    sparse = True,\n",
    "    mini_batch_size=256\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              hidden learning_rate  \\\n",
      "0         [300, 300]         0.005   \n",
      "1         [300, 300]         0.001   \n",
      "2    [200, 200, 200]         0.005   \n",
      "3    [200, 200, 200]         0.001   \n",
      "\n",
      "                                                           model_ids  \\\n",
      "0  Grid_DeepWater_py_2_sid_b972_model_python_1477177984287_9_model_3   \n",
      "1  Grid_DeepWater_py_2_sid_b972_model_python_1477177984287_9_model_1   \n",
      "2  Grid_DeepWater_py_2_sid_b972_model_python_1477177984287_9_model_2   \n",
      "3  Grid_DeepWater_py_2_sid_b972_model_python_1477177984287_9_model_0   \n",
      "\n",
      "              logloss  \n",
      "0   2.540532413363614  \n",
      "1   2.890133394916092  \n",
      "2   3.094028654656067  \n",
      "3  3.4866005573233423  \n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print model grid search results\n",
    "model_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid_DeepWater_py_2_sid_b972_model_python_1477177984287_9_model_3 mean per class error: 0.0213260170276\n",
      "Grid_DeepWater_py_2_sid_b972_model_python_1477177984287_9_model_1 mean per class error: 0.0755123461905\n",
      "Grid_DeepWater_py_2_sid_b972_model_python_1477177984287_9_model_2 mean per class error: 0.0326985036086\n",
      "Grid_DeepWater_py_2_sid_b972_model_python_1477177984287_9_model_0 mean per class error: 0.0855142847753\n"
     ]
    }
   ],
   "source": [
    "for model in model_grid:\n",
    "    print model.model_id + \" mean per class error: \" + str(model.mean_per_class_error())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Grid_DeepWater_py_2_sid_b972_model_python_1477177984287_9_model_3</td>\n",
       "      <td>0.076350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Grid_DeepWater_py_2_sid_b972_model_python_1477177984287_9_model_1</td>\n",
       "      <td>0.084042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Grid_DeepWater_py_2_sid_b972_model_python_1477177984287_9_model_2</td>\n",
       "      <td>0.091444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Grid_DeepWater_py_2_sid_b972_model_python_1477177984287_9_model_0</td>\n",
       "      <td>0.104300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                   0         1\n",
       "0  Grid_DeepWater_py_2_sid_b972_model_python_1477177984287_9_model_3  0.076350\n",
       "1  Grid_DeepWater_py_2_sid_b972_model_python_1477177984287_9_model_1  0.084042\n",
       "2  Grid_DeepWater_py_2_sid_b972_model_python_1477177984287_9_model_2  0.091444\n",
       "3  Grid_DeepWater_py_2_sid_b972_model_python_1477177984287_9_model_0  0.104300"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_results = pd.DataFrame([[m.model_id, m.mean_per_class_error(valid=True)] for m in model_grid])\n",
    "grid_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Grid Search\n",
    "\n",
    "If the search space is too large you can let the GridSearch algorithm select the parameter, by sampling from the parameter space. \n",
    "\n",
    "Just specify how many models (and/or how much training time) you want, and provide a seed to make the random selection deterministic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hyper_parameters = {\n",
    "    \"hidden\":[[1000,1000],[2000]],\n",
    "    \"learning_rate\":[s*1e-3 for s in range(30,100)],\n",
    "    \"momentum_start\":[s*1e-3 for s in range(0,900)],\n",
    "    \"momentum_stable\":[s*1e-3 for s in range(900,1000)],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "search_criteria = {\"strategy\":\"RandomDiscrete\", \"max_models\":10, \"max_runtime_secs\":100, \"seed\":123456}\n",
    "\n",
    "model_grid_random_search = H2OGridSearch(H2ODeepWaterEstimator,\n",
    "    hyper_params=hyper_parameters,\n",
    "    search_criteria=search_criteria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deepwater Grid Build progress: |██████████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "model_grid_random_search.train(\n",
    "    x=x, y=y,\n",
    "    distribution=\"multinomial\", \n",
    "    epochs=50,   ## might stop earlier since we enable early stopping below\n",
    "    training_frame=train_df, \n",
    "    validation_frame=test_df,\n",
    "    score_interval=2,                ## score no more than every 2 seconds\n",
    "    score_duty_cycle=0.5,            ## score up to 50% of the wall clock time - scoring is needed for early stopping\n",
    "    score_training_samples=1000,     ## use a subset of the training frame for faster scoring\n",
    "    score_validation_samples=1000,   ## use a subset of the validation frame for faster scoring\n",
    "    stopping_rounds=3,\n",
    "    stopping_tolerance=0.05,\n",
    "    stopping_metric=\"misclassification\",\n",
    "    sparse = True,\n",
    "    mini_batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid_results = pd.DataFrame([[m.model_id, m.mean_per_class_error(valid=True)] for m in model_grid_random_search])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Grid_DeepWater_py_2_sid_b972_model_python_1477177984287_11_model_0</td>\n",
       "      <td>0.019816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Grid_DeepWater_py_2_sid_b972_model_python_1477177984287_11_model_2</td>\n",
       "      <td>0.022739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Grid_DeepWater_py_2_sid_b972_model_python_1477177984287_11_model_3</td>\n",
       "      <td>0.041271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Grid_DeepWater_py_2_sid_b972_model_python_1477177984287_11_model_4</td>\n",
       "      <td>0.066077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Grid_DeepWater_py_2_sid_b972_model_python_1477177984287_11_model_5</td>\n",
       "      <td>0.162954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Grid_DeepWater_py_2_sid_b972_model_python_1477177984287_11_model_1</td>\n",
       "      <td>0.199744</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                    0  \\\n",
       "0  Grid_DeepWater_py_2_sid_b972_model_python_1477177984287_11_model_0   \n",
       "1  Grid_DeepWater_py_2_sid_b972_model_python_1477177984287_11_model_2   \n",
       "2  Grid_DeepWater_py_2_sid_b972_model_python_1477177984287_11_model_3   \n",
       "3  Grid_DeepWater_py_2_sid_b972_model_python_1477177984287_11_model_4   \n",
       "4  Grid_DeepWater_py_2_sid_b972_model_python_1477177984287_11_model_5   \n",
       "5  Grid_DeepWater_py_2_sid_b972_model_python_1477177984287_11_model_1   \n",
       "\n",
       "          1  \n",
       "0  0.019816  \n",
       "1  0.022739  \n",
       "2  0.041271  \n",
       "3  0.066077  \n",
       "4  0.162954  \n",
       "5  0.199744  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Checkpoints \n",
    "\n",
    "\n",
    "\n",
    "H2O supporst model checkpoints. You can store the `state` of training and resume it later.\n",
    "Checkpointing can be used to reload existing models that were saved to\n",
    "disk in a previous session. \n",
    "\n",
    "To resume model training, use checkpoint model keys (model id) to incrementally\n",
    "train a specific model using more iterations, more data, different data, and\n",
    "so forth. To further train the initial model, use it (or its key) as a checkpoint\n",
    "argument for a new model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To improve this initial model, start from the previous model and add iterations by\n",
    "building another model, specifying checkpoint=previous model id, and\n",
    "changing train samples per iteration, target ratio comm to comp,\n",
    "or other parameters. Many parameters can be changed between checkpoints,\n",
    "especially those that affect regularization or performance tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use GridSearch with checkpoint restarts to scan a broader range of hyperparameter combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Re-start the training process on a saved DL model using the ‘checkpoint‘ argument\n",
    "model_checkpoint = H2ODeepWaterEstimator(\n",
    "     checkpoint=model.model_id,\n",
    "     distribution=\"multinomial\",\n",
    "     activation=\"rectifier\",\n",
    "     mini_batch_size=128,\n",
    "     hidden=[1024,1024],\n",
    "     hidden_dropout_ratios=[0.5,0.5],\n",
    "     input_dropout_ratio=0.1,\n",
    "     sparse=True,\n",
    "     epochs=20)  ## previous model had 10 epochs, so we need to only train for 10 more to get to 20 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deepwater Model Build progress: |█████████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "model_checkpoint.train(\n",
    " x=x,\n",
    " y=y,\n",
    " training_frame=train_df,\n",
    " validation_frame=test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>duration</th>\n",
       "      <th>training_speed</th>\n",
       "      <th>epochs</th>\n",
       "      <th>iterations</th>\n",
       "      <th>samples</th>\n",
       "      <th>training_rmse</th>\n",
       "      <th>training_logloss</th>\n",
       "      <th>training_classification_error</th>\n",
       "      <th>validation_rmse</th>\n",
       "      <th>validation_logloss</th>\n",
       "      <th>validation_classification_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>2016-10-22 16:43:19</td>\n",
       "      <td>0.000 sec</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>2016-10-22 16:43:20</td>\n",
       "      <td>3.655 sec</td>\n",
       "      <td>7953 obs/sec</td>\n",
       "      <td>0.068267</td>\n",
       "      <td>1</td>\n",
       "      <td>4096.0</td>\n",
       "      <td>0.437065</td>\n",
       "      <td>6.595456</td>\n",
       "      <td>0.191026</td>\n",
       "      <td>0.442109</td>\n",
       "      <td>6.736326</td>\n",
       "      <td>0.1955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>2016-10-22 16:43:32</td>\n",
       "      <td>15.324 sec</td>\n",
       "      <td>24227 obs/sec</td>\n",
       "      <td>4.437333</td>\n",
       "      <td>65</td>\n",
       "      <td>266240.0</td>\n",
       "      <td>0.135399</td>\n",
       "      <td>0.629897</td>\n",
       "      <td>0.018333</td>\n",
       "      <td>0.214942</td>\n",
       "      <td>1.593245</td>\n",
       "      <td>0.0462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>2016-10-22 16:43:43</td>\n",
       "      <td>26.498 sec</td>\n",
       "      <td>27942 obs/sec</td>\n",
       "      <td>10.035200</td>\n",
       "      <td>147</td>\n",
       "      <td>602112.0</td>\n",
       "      <td>0.093329</td>\n",
       "      <td>0.294170</td>\n",
       "      <td>0.008711</td>\n",
       "      <td>0.211899</td>\n",
       "      <td>1.546729</td>\n",
       "      <td>0.0449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>2016-10-22 16:44:12</td>\n",
       "      <td>28.457 sec</td>\n",
       "      <td>27806 obs/sec</td>\n",
       "      <td>10.103467</td>\n",
       "      <td>148</td>\n",
       "      <td>606208.0</td>\n",
       "      <td>0.111641</td>\n",
       "      <td>0.423550</td>\n",
       "      <td>0.012454</td>\n",
       "      <td>0.220221</td>\n",
       "      <td>1.665133</td>\n",
       "      <td>0.0485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td>2016-10-22 16:44:22</td>\n",
       "      <td>38.399 sec</td>\n",
       "      <td>27232 obs/sec</td>\n",
       "      <td>14.131200</td>\n",
       "      <td>207</td>\n",
       "      <td>847872.0</td>\n",
       "      <td>0.146356</td>\n",
       "      <td>0.729553</td>\n",
       "      <td>0.021421</td>\n",
       "      <td>0.195965</td>\n",
       "      <td>1.322237</td>\n",
       "      <td>0.0384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td>2016-10-22 16:44:28</td>\n",
       "      <td>44.595 sec</td>\n",
       "      <td>27992 obs/sec</td>\n",
       "      <td>17.134933</td>\n",
       "      <td>251</td>\n",
       "      <td>1028096.0</td>\n",
       "      <td>0.111149</td>\n",
       "      <td>0.420023</td>\n",
       "      <td>0.012354</td>\n",
       "      <td>0.184538</td>\n",
       "      <td>1.162109</td>\n",
       "      <td>0.0341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "      <td>2016-10-22 16:44:35</td>\n",
       "      <td>50.744 sec</td>\n",
       "      <td>28198 obs/sec</td>\n",
       "      <td>19.865600</td>\n",
       "      <td>291</td>\n",
       "      <td>1191936.0</td>\n",
       "      <td>0.080474</td>\n",
       "      <td>0.222153</td>\n",
       "      <td>0.006476</td>\n",
       "      <td>0.173003</td>\n",
       "      <td>1.024147</td>\n",
       "      <td>0.0300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td></td>\n",
       "      <td>2016-10-22 16:44:36</td>\n",
       "      <td>51.657 sec</td>\n",
       "      <td>28195 obs/sec</td>\n",
       "      <td>20.002133</td>\n",
       "      <td>293</td>\n",
       "      <td>1200128.0</td>\n",
       "      <td>0.080474</td>\n",
       "      <td>0.219504</td>\n",
       "      <td>0.006476</td>\n",
       "      <td>0.165528</td>\n",
       "      <td>0.941545</td>\n",
       "      <td>0.0274</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               timestamp    duration training_speed     epochs  iterations  \\\n",
       "0    2016-10-22 16:43:19   0.000 sec           None   0.000000           0   \n",
       "1    2016-10-22 16:43:20   3.655 sec   7953 obs/sec   0.068267           1   \n",
       "2    2016-10-22 16:43:32  15.324 sec  24227 obs/sec   4.437333          65   \n",
       "3    2016-10-22 16:43:43  26.498 sec  27942 obs/sec  10.035200         147   \n",
       "4    2016-10-22 16:44:12  28.457 sec  27806 obs/sec  10.103467         148   \n",
       "5    2016-10-22 16:44:22  38.399 sec  27232 obs/sec  14.131200         207   \n",
       "6    2016-10-22 16:44:28  44.595 sec  27992 obs/sec  17.134933         251   \n",
       "7    2016-10-22 16:44:35  50.744 sec  28198 obs/sec  19.865600         291   \n",
       "8    2016-10-22 16:44:36  51.657 sec  28195 obs/sec  20.002133         293   \n",
       "\n",
       "     samples  training_rmse  training_logloss  training_classification_error  \\\n",
       "0        0.0            NaN               NaN                            NaN   \n",
       "1     4096.0       0.437065          6.595456                       0.191026   \n",
       "2   266240.0       0.135399          0.629897                       0.018333   \n",
       "3   602112.0       0.093329          0.294170                       0.008711   \n",
       "4   606208.0       0.111641          0.423550                       0.012454   \n",
       "5   847872.0       0.146356          0.729553                       0.021421   \n",
       "6  1028096.0       0.111149          0.420023                       0.012354   \n",
       "7  1191936.0       0.080474          0.222153                       0.006476   \n",
       "8  1200128.0       0.080474          0.219504                       0.006476   \n",
       "\n",
       "   validation_rmse  validation_logloss  validation_classification_error  \n",
       "0              NaN                 NaN                              NaN  \n",
       "1         0.442109            6.736326                           0.1955  \n",
       "2         0.214942            1.593245                           0.0462  \n",
       "3         0.211899            1.546729                           0.0449  \n",
       "4         0.220221            1.665133                           0.0485  \n",
       "5         0.195965            1.322237                           0.0384  \n",
       "6         0.184538            1.162109                           0.0341  \n",
       "7         0.173003            1.024147                           0.0300  \n",
       "8         0.165528            0.941545                           0.0274  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_checkpoint.scoring_history()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify a model and a file path. The default path is the current working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/arno/h2o-3/examples/deeplearning/notebooks/DeepWater_model_python_1477179782032_1\n"
     ]
    }
   ],
   "source": [
    "model_path = h2o.save_model(\n",
    "     model = model,\n",
    "     #path = \"/tmp/mymodel\",\n",
    "     force = True)\n",
    "\n",
    "print model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-rw-r-- 1 arno arno 7.0M Oct 22 16:45 /home/arno/h2o-3/examples/deeplearning/notebooks/DeepWater_model_python_1477179782032_1\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lah $model_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After restarting H2O, you can load the saved model by specifying the host and model file path. \n",
    "\n",
    "Note: The saved model must be the same version used to save the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load model from disk\n",
    "saved_model = h2o.load_model(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use the following commands to retrieve a model from its H2O key.\n",
    "This is useful if you have created an H2O model using the web interface and\n",
    "want to continue the modeling process in another language, for example **R**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details\n",
      "=============\n",
      "H2ODeepWaterEstimator :  Deep Water\n",
      "Model Key:  DeepWater_model_python_1477179782032_3\n",
      "Status of Deep Learning Model: MLP: [1024, 1024], 6.9 MB, predicting C785, 10-class classification, 1,200,128 training samples, mini-batch size 128\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>input_neurons</b></td>\n",
       "<td><b>rate</b></td>\n",
       "<td><b>momentum</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>717</td>\n",
       "<td>0.0022726</td>\n",
       "<td>0.99</td></tr></table></div>"
      ],
      "text/plain": [
       "    input_neurons    rate       momentum\n",
       "--  ---------------  ---------  ----------\n",
       "    717              0.0022726  0.99"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsMultinomial: deepwater\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.00647603750669\n",
      "RMSE: 0.0804738311918\n",
      "LogLoss: 0.21950361285\n",
      "Mean Per-Class Error: 0.00655568304453\n",
      "Confusion Matrix: vertical: actual; across: predicted\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>0</b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>2</b></td>\n",
       "<td><b>3</b></td>\n",
       "<td><b>4</b></td>\n",
       "<td><b>5</b></td>\n",
       "<td><b>6</b></td>\n",
       "<td><b>7</b></td>\n",
       "<td><b>8</b></td>\n",
       "<td><b>9</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>984.0</td>\n",
       "<td>0.0</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0070636</td>\n",
       "<td>7 / 991</td></tr>\n",
       "<tr><td>0.0</td>\n",
       "<td>1149.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>4.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0043328</td>\n",
       "<td>5 / 1,154</td></tr>\n",
       "<tr><td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1016.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0039216</td>\n",
       "<td>4 / 1,020</td></tr>\n",
       "<tr><td>0.0</td>\n",
       "<td>2.0</td>\n",
       "<td>3.0</td>\n",
       "<td>1030.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>2.0</td>\n",
       "<td>1.0</td>\n",
       "<td>4.0</td>\n",
       "<td>0.0124640</td>\n",
       "<td>13 / 1,043</td></tr>\n",
       "<tr><td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>967.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0 / 967</td></tr>\n",
       "<tr><td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>3.0</td>\n",
       "<td>0.0</td>\n",
       "<td>890.0</td>\n",
       "<td>0.0</td>\n",
       "<td>2.0</td>\n",
       "<td>5.0</td>\n",
       "<td>4.0</td>\n",
       "<td>0.0154867</td>\n",
       "<td>14 / 904</td></tr>\n",
       "<tr><td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>965.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0010352</td>\n",
       "<td>1 / 966</td></tr>\n",
       "<tr><td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1023.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0019512</td>\n",
       "<td>2 / 1,025</td></tr>\n",
       "<tr><td>0.0</td>\n",
       "<td>2.0</td>\n",
       "<td>4.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>2.0</td>\n",
       "<td>2.0</td>\n",
       "<td>2.0</td>\n",
       "<td>970.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0152284</td>\n",
       "<td>15 / 985</td></tr>\n",
       "<tr><td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>3.0</td>\n",
       "<td>0.0</td>\n",
       "<td>978.0</td>\n",
       "<td>0.0040733</td>\n",
       "<td>4 / 982</td></tr>\n",
       "<tr><td>984.0</td>\n",
       "<td>1154.0</td>\n",
       "<td>1025.0</td>\n",
       "<td>1034.0</td>\n",
       "<td>972.0</td>\n",
       "<td>894.0</td>\n",
       "<td>969.0</td>\n",
       "<td>1037.0</td>\n",
       "<td>978.0</td>\n",
       "<td>990.0</td>\n",
       "<td>0.0064760</td>\n",
       "<td>65 / 10,037</td></tr></table></div>"
      ],
      "text/plain": [
       "0    1     2     3     4    5    6    7     8    9    Error       Rate\n",
       "---  ----  ----  ----  ---  ---  ---  ----  ---  ---  ----------  -----------\n",
       "984  0     2     0     1    0    2    0     0    2    0.00706357  7 / 991\n",
       "0    1149  0     0     1    0    0    4     0    0    0.00433276  5 / 1,154\n",
       "0    0     1016  0     1    0    0    1     2    0    0.00392157  4 / 1,020\n",
       "0    2     3     1030  0    1    0    2     1    4    0.012464    13 / 1,043\n",
       "0    0     0     0     967  0    0    0     0    0    0           0 / 967\n",
       "0    0     0     3     0    890  0    2     5    4    0.0154867   14 / 904\n",
       "0    0     0     0     0    1    965  0     0    0    0.0010352   1 / 966\n",
       "0    1     0     0     0    0    0    1023  0    1    0.00195122  2 / 1,025\n",
       "0    2     4     1     1    2    2    2     970  1    0.0152284   15 / 985\n",
       "0    0     0     0     1    0    0    3     0    978  0.00407332  4 / 982\n",
       "984  1154  1025  1034  972  894  969  1037  978  990  0.00647604  65 / 10,037"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-10 Hit Ratios: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>k</b></td>\n",
       "<td><b>hit_ratio</b></td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>0.9935240</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.9948192</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.9948192</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.9948192</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.9948192</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.9948192</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.9948192</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.9948192</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.9948192</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>1.0</td></tr></table></div>"
      ],
      "text/plain": [
       "k    hit_ratio\n",
       "---  -----------\n",
       "1    0.993524\n",
       "2    0.994819\n",
       "3    0.994819\n",
       "4    0.994819\n",
       "5    0.994819\n",
       "6    0.994819\n",
       "7    0.994819\n",
       "8    0.994819\n",
       "9    0.994819\n",
       "10   1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ModelMetricsMultinomial: deepwater\n",
      "** Reported on validation data. **\n",
      "\n",
      "MSE: 0.0273996641587\n",
      "RMSE: 0.165528439124\n",
      "LogLoss: 0.941545364671\n",
      "Mean Per-Class Error: 0.0277742924787\n",
      "Confusion Matrix: vertical: actual; across: predicted\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>0</b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>2</b></td>\n",
       "<td><b>3</b></td>\n",
       "<td><b>4</b></td>\n",
       "<td><b>5</b></td>\n",
       "<td><b>6</b></td>\n",
       "<td><b>7</b></td>\n",
       "<td><b>8</b></td>\n",
       "<td><b>9</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>963.0</td>\n",
       "<td>1.0</td>\n",
       "<td>3.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>2.0</td>\n",
       "<td>3.0</td>\n",
       "<td>0.0</td>\n",
       "<td>3.0</td>\n",
       "<td>3.0</td>\n",
       "<td>0.0173469</td>\n",
       "<td>17 / 980</td></tr>\n",
       "<tr><td>0.0</td>\n",
       "<td>1124.0</td>\n",
       "<td>4.0</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>2.0</td>\n",
       "<td>1.0</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0096916</td>\n",
       "<td>11 / 1,135</td></tr>\n",
       "<tr><td>7.0</td>\n",
       "<td>2.0</td>\n",
       "<td>996.0</td>\n",
       "<td>6.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>2.0</td>\n",
       "<td>9.0</td>\n",
       "<td>8.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0348837</td>\n",
       "<td>36 / 1,032</td></tr>\n",
       "<tr><td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>8.0</td>\n",
       "<td>979.0</td>\n",
       "<td>0.0</td>\n",
       "<td>9.0</td>\n",
       "<td>0.0</td>\n",
       "<td>6.0</td>\n",
       "<td>3.0</td>\n",
       "<td>4.0</td>\n",
       "<td>0.0306931</td>\n",
       "<td>31 / 1,010</td></tr>\n",
       "<tr><td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>5.0</td>\n",
       "<td>0.0</td>\n",
       "<td>951.0</td>\n",
       "<td>1.0</td>\n",
       "<td>2.0</td>\n",
       "<td>7.0</td>\n",
       "<td>1.0</td>\n",
       "<td>14.0</td>\n",
       "<td>0.0315682</td>\n",
       "<td>31 / 982</td></tr>\n",
       "<tr><td>2.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>10.0</td>\n",
       "<td>0.0</td>\n",
       "<td>856.0</td>\n",
       "<td>6.0</td>\n",
       "<td>2.0</td>\n",
       "<td>8.0</td>\n",
       "<td>6.0</td>\n",
       "<td>0.0403587</td>\n",
       "<td>36 / 892</td></tr>\n",
       "<tr><td>4.0</td>\n",
       "<td>3.0</td>\n",
       "<td>4.0</td>\n",
       "<td>0.0</td>\n",
       "<td>3.0</td>\n",
       "<td>5.0</td>\n",
       "<td>936.0</td>\n",
       "<td>0.0</td>\n",
       "<td>3.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0229645</td>\n",
       "<td>22 / 958</td></tr>\n",
       "<tr><td>1.0</td>\n",
       "<td>3.0</td>\n",
       "<td>8.0</td>\n",
       "<td>0.0</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1005.0</td>\n",
       "<td>2.0</td>\n",
       "<td>7.0</td>\n",
       "<td>0.0223735</td>\n",
       "<td>23 / 1,028</td></tr>\n",
       "<tr><td>2.0</td>\n",
       "<td>0.0</td>\n",
       "<td>7.0</td>\n",
       "<td>10.0</td>\n",
       "<td>3.0</td>\n",
       "<td>8.0</td>\n",
       "<td>3.0</td>\n",
       "<td>4.0</td>\n",
       "<td>933.0</td>\n",
       "<td>4.0</td>\n",
       "<td>0.0420945</td>\n",
       "<td>41 / 974</td></tr>\n",
       "<tr><td>1.0</td>\n",
       "<td>3.0</td>\n",
       "<td>1.0</td>\n",
       "<td>2.0</td>\n",
       "<td>6.0</td>\n",
       "<td>3.0</td>\n",
       "<td>0.0</td>\n",
       "<td>10.0</td>\n",
       "<td>0.0</td>\n",
       "<td>983.0</td>\n",
       "<td>0.0257681</td>\n",
       "<td>26 / 1,009</td></tr>\n",
       "<tr><td>980.0</td>\n",
       "<td>1139.0</td>\n",
       "<td>1037.0</td>\n",
       "<td>1010.0</td>\n",
       "<td>967.0</td>\n",
       "<td>884.0</td>\n",
       "<td>954.0</td>\n",
       "<td>1044.0</td>\n",
       "<td>963.0</td>\n",
       "<td>1022.0</td>\n",
       "<td>0.0274</td>\n",
       "<td>274 / 10,000</td></tr></table></div>"
      ],
      "text/plain": [
       "0    1     2     3     4    5    6    7     8    9     Error       Rate\n",
       "---  ----  ----  ----  ---  ---  ---  ----  ---  ----  ----------  ------------\n",
       "963  1     3     1     1    2    3    0     3    3     0.0173469   17 / 980\n",
       "0    1124  4     2     0    0    2    1     2    0     0.00969163  11 / 1,135\n",
       "7    2     996   6     1    0    2    9     8    1     0.0348837   36 / 1,032\n",
       "0    1     8     979   0    9    0    6     3    4     0.0306931   31 / 1,010\n",
       "0    1     5     0     951  1    2    7     1    14    0.0315682   31 / 982\n",
       "2    1     1     10    0    856  6    2     8    6     0.0403587   36 / 892\n",
       "4    3     4     0     3    5    936  0     3    0     0.0229645   22 / 958\n",
       "1    3     8     0     2    0    0    1005  2    7     0.0223735   23 / 1,028\n",
       "2    0     7     10    3    8    3    4     933  4     0.0420945   41 / 974\n",
       "1    3     1     2     6    3    0    10    0    983   0.0257681   26 / 1,009\n",
       "980  1139  1037  1010  967  884  954  1044  963  1022  0.0274      274 / 10,000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-10 Hit Ratios: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>k</b></td>\n",
       "<td><b>hit_ratio</b></td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>0.9726</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.9752</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.9753</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.9753</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.9753</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.9753</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.9753</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.9753</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.9753</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>1.0</td></tr></table></div>"
      ],
      "text/plain": [
       "k    hit_ratio\n",
       "---  -----------\n",
       "1    0.9726\n",
       "2    0.9752\n",
       "3    0.9753\n",
       "4    0.9753\n",
       "5    0.9753\n",
       "6    0.9753\n",
       "7    0.9753\n",
       "8    0.9753\n",
       "9    0.9753\n",
       "10   1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring History: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>timestamp</b></td>\n",
       "<td><b>duration</b></td>\n",
       "<td><b>training_speed</b></td>\n",
       "<td><b>epochs</b></td>\n",
       "<td><b>iterations</b></td>\n",
       "<td><b>samples</b></td>\n",
       "<td><b>training_rmse</b></td>\n",
       "<td><b>training_logloss</b></td>\n",
       "<td><b>training_classification_error</b></td>\n",
       "<td><b>validation_rmse</b></td>\n",
       "<td><b>validation_logloss</b></td>\n",
       "<td><b>validation_classification_error</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-10-22 16:43:19</td>\n",
       "<td> 0.000 sec</td>\n",
       "<td>None</td>\n",
       "<td>0.0</td>\n",
       "<td>0</td>\n",
       "<td>0.0</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-10-22 16:43:20</td>\n",
       "<td> 3.655 sec</td>\n",
       "<td>7953 obs/sec</td>\n",
       "<td>0.0682667</td>\n",
       "<td>1</td>\n",
       "<td>4096.0</td>\n",
       "<td>0.4370652</td>\n",
       "<td>6.5954557</td>\n",
       "<td>0.1910260</td>\n",
       "<td>0.4421092</td>\n",
       "<td>6.7363260</td>\n",
       "<td>0.1955</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-10-22 16:43:32</td>\n",
       "<td>15.324 sec</td>\n",
       "<td>24227 obs/sec</td>\n",
       "<td>4.4373333</td>\n",
       "<td>65</td>\n",
       "<td>266240.0</td>\n",
       "<td>0.1353988</td>\n",
       "<td>0.6298973</td>\n",
       "<td>0.0183328</td>\n",
       "<td>0.2149419</td>\n",
       "<td>1.5932451</td>\n",
       "<td>0.0462</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-10-22 16:43:43</td>\n",
       "<td>26.498 sec</td>\n",
       "<td>27942 obs/sec</td>\n",
       "<td>10.0352</td>\n",
       "<td>147</td>\n",
       "<td>602112.0</td>\n",
       "<td>0.0933289</td>\n",
       "<td>0.2941703</td>\n",
       "<td>0.0087106</td>\n",
       "<td>0.2118989</td>\n",
       "<td>1.5467293</td>\n",
       "<td>0.0449</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-10-22 16:44:12</td>\n",
       "<td>28.457 sec</td>\n",
       "<td>27806 obs/sec</td>\n",
       "<td>10.1034667</td>\n",
       "<td>148</td>\n",
       "<td>606208.0</td>\n",
       "<td>0.1116407</td>\n",
       "<td>0.4235503</td>\n",
       "<td>0.0124539</td>\n",
       "<td>0.2202207</td>\n",
       "<td>1.6651330</td>\n",
       "<td>0.0485</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-10-22 16:44:22</td>\n",
       "<td>38.399 sec</td>\n",
       "<td>27232 obs/sec</td>\n",
       "<td>14.1312</td>\n",
       "<td>207</td>\n",
       "<td>847872.0</td>\n",
       "<td>0.1463561</td>\n",
       "<td>0.7295526</td>\n",
       "<td>0.0214207</td>\n",
       "<td>0.1959646</td>\n",
       "<td>1.3222373</td>\n",
       "<td>0.0384</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-10-22 16:44:28</td>\n",
       "<td>44.595 sec</td>\n",
       "<td>27992 obs/sec</td>\n",
       "<td>17.1349333</td>\n",
       "<td>251</td>\n",
       "<td>1028096.0</td>\n",
       "<td>0.1111494</td>\n",
       "<td>0.4200229</td>\n",
       "<td>0.0123543</td>\n",
       "<td>0.1845377</td>\n",
       "<td>1.1621092</td>\n",
       "<td>0.0341</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-10-22 16:44:35</td>\n",
       "<td>50.744 sec</td>\n",
       "<td>28198 obs/sec</td>\n",
       "<td>19.8656</td>\n",
       "<td>291</td>\n",
       "<td>1191936.0</td>\n",
       "<td>0.0804738</td>\n",
       "<td>0.2221525</td>\n",
       "<td>0.0064760</td>\n",
       "<td>0.1730029</td>\n",
       "<td>1.0241470</td>\n",
       "<td>0.03</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-10-22 16:44:36</td>\n",
       "<td>51.657 sec</td>\n",
       "<td>28195 obs/sec</td>\n",
       "<td>20.0021333</td>\n",
       "<td>293</td>\n",
       "<td>1200128.0</td>\n",
       "<td>0.0804738</td>\n",
       "<td>0.2195036</td>\n",
       "<td>0.0064760</td>\n",
       "<td>0.1655284</td>\n",
       "<td>0.9415454</td>\n",
       "<td>0.0274</td></tr></table></div>"
      ],
      "text/plain": [
       "    timestamp            duration    training_speed    epochs     iterations    samples      training_rmse    training_logloss    training_classification_error    validation_rmse    validation_logloss    validation_classification_error\n",
       "--  -------------------  ----------  ----------------  ---------  ------------  -----------  ---------------  ------------------  -------------------------------  -----------------  --------------------  ---------------------------------\n",
       "    2016-10-22 16:43:19  0.000 sec                     0          0             0            nan              nan                 nan                              nan                nan                   nan\n",
       "    2016-10-22 16:43:20  3.655 sec   7953 obs/sec      0.0682667  1             4096         0.437065         6.59546             0.191026                         0.442109           6.73633               0.1955\n",
       "    2016-10-22 16:43:32  15.324 sec  24227 obs/sec     4.43733    65            266240       0.135399         0.629897            0.0183328                        0.214942           1.59325               0.0462\n",
       "    2016-10-22 16:43:43  26.498 sec  27942 obs/sec     10.0352    147           602112       0.0933289        0.29417             0.00871062                       0.211899           1.54673               0.0449\n",
       "    2016-10-22 16:44:12  28.457 sec  27806 obs/sec     10.1035    148           606208       0.111641         0.42355             0.0124539                        0.220221           1.66513               0.0485\n",
       "    2016-10-22 16:44:22  38.399 sec  27232 obs/sec     14.1312    207           847872       0.146356         0.729553            0.0214207                        0.195965           1.32224               0.0384\n",
       "    2016-10-22 16:44:28  44.595 sec  27992 obs/sec     17.1349    251           1.0281e+06   0.111149         0.420023            0.0123543                        0.184538           1.16211               0.0341\n",
       "    2016-10-22 16:44:35  50.744 sec  28198 obs/sec     19.8656    291           1.19194e+06  0.0804738        0.222153            0.00647604                       0.173003           1.02415               0.03\n",
       "    2016-10-22 16:44:36  51.657 sec  28195 obs/sec     20.0021    293           1.20013e+06  0.0804738        0.219504            0.00647604                       0.165528           0.941545              0.0274"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve model by H2O key\n",
    "model = h2o.get_model(model_id=model_checkpoint._id)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "In this jupyter you learned to:\n",
    "- use a deeplearning model\n",
    "- use GridSearch\n",
    "- use Checkpointing\n",
    "- use Early Stopping"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
