{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepLearning\n",
    "\n",
    "## MNIST Dataset\n",
    "The MNIST database is a well-known academic dataset used to benchmark\n",
    "classification performance. The data consists of 60,000 training images and\n",
    "10,000 test images. Each image is a standardized $28^2$ pixel greyscale image of\n",
    "a single handwritten digit. An example of the scanned handwritten digits is\n",
    "shown\n",
    "![Example MNIST digit images](images/mnist.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321. connected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime:</td>\n",
       "<td>13 mins 53 secs</td></tr>\n",
       "<tr><td>H2O cluster version:</td>\n",
       "<td>3.11.0.99999</td></tr>\n",
       "<tr><td>H2O cluster version age:</td>\n",
       "<td>1 hour and 15 minutes </td></tr>\n",
       "<tr><td>H2O cluster name:</td>\n",
       "<td>arno</td></tr>\n",
       "<tr><td>H2O cluster total nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster free memory:</td>\n",
       "<td>13.70 Gb</td></tr>\n",
       "<tr><td>H2O cluster total cores:</td>\n",
       "<td>12</td></tr>\n",
       "<tr><td>H2O cluster allowed cores:</td>\n",
       "<td>12</td></tr>\n",
       "<tr><td>H2O cluster status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O connection url:</td>\n",
       "<td>http://localhost:54321</td></tr>\n",
       "<tr><td>H2O connection proxy:</td>\n",
       "<td>None</td></tr>\n",
       "<tr><td>Python version:</td>\n",
       "<td>2.7.12 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ----------------------\n",
       "H2O cluster uptime:         13 mins 53 secs\n",
       "H2O cluster version:        3.11.0.99999\n",
       "H2O cluster version age:    1 hour and 15 minutes\n",
       "H2O cluster name:           arno\n",
       "H2O cluster total nodes:    1\n",
       "H2O cluster free memory:    13.70 Gb\n",
       "H2O cluster total cores:    12\n",
       "H2O cluster allowed cores:  12\n",
       "H2O cluster status:         locked, healthy\n",
       "H2O connection url:         http://localhost:54321\n",
       "H2O connection proxy:\n",
       "Python version:             2.7.12 final\n",
       "--------------------------  ----------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import h2o\n",
    "h2o.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "test_df = h2o.import_file(\"https://h2o-public-test-data.s3.amazonaws.com/bigdata/laptop/mnist/test.csv.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "train_df = h2o.import_file(\"https://h2o-public-test-data.s3.amazonaws.com/bigdata/laptop/mnist/train.csv.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from h2o.estimators.deepwater import H2ODeepWaterEstimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the response and predictor columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = \"C785\"\n",
    "x = train_df.names[0:784]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df[y] = train_df[y].asfactor()\n",
    "test_df[y] = test_df[y].asfactor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Deep Learning model and validate on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from h2o.estimators.deepwater import H2ODeepWaterEstimator\n",
    "\n",
    "model = H2ODeepWaterEstimator(\n",
    "   distribution=\"multinomial\",\n",
    "   activation=\"rectifier\",\n",
    "   hidden=[1024,1024,1024],\n",
    "   #hiden_dropout_ratios=[0.5,0.5,0.5],  ## for better generalization\n",
    "   input_dropout_ratio=0.1,\n",
    "   #sparse=True,                         ## can speed up\n",
    "   epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deepwater Model Build progress: |█████████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "model.train(\n",
    "    x=x, \n",
    "    y=y,\n",
    "    training_frame=train_df,\n",
    "    validation_frame=test_df\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>duration</th>\n",
       "      <th>training_speed</th>\n",
       "      <th>epochs</th>\n",
       "      <th>iterations</th>\n",
       "      <th>samples</th>\n",
       "      <th>training_rmse</th>\n",
       "      <th>training_logloss</th>\n",
       "      <th>training_classification_error</th>\n",
       "      <th>validation_rmse</th>\n",
       "      <th>validation_logloss</th>\n",
       "      <th>validation_classification_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>2016-10-22 14:05:27</td>\n",
       "      <td>0.000 sec</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>2016-10-22 14:05:27</td>\n",
       "      <td>2.943 sec</td>\n",
       "      <td>4000 obs/sec</td>\n",
       "      <td>0.017067</td>\n",
       "      <td>1</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.466294</td>\n",
       "      <td>7.509779</td>\n",
       "      <td>0.217430</td>\n",
       "      <td>0.461303</td>\n",
       "      <td>7.349852</td>\n",
       "      <td>0.2128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>2016-10-22 14:05:47</td>\n",
       "      <td>21.886 sec</td>\n",
       "      <td>15467 obs/sec</td>\n",
       "      <td>4.744533</td>\n",
       "      <td>278</td>\n",
       "      <td>284672.0</td>\n",
       "      <td>0.201571</td>\n",
       "      <td>1.403343</td>\n",
       "      <td>0.040631</td>\n",
       "      <td>0.233452</td>\n",
       "      <td>1.882363</td>\n",
       "      <td>0.0545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>2016-10-22 14:05:55</td>\n",
       "      <td>29.946 sec</td>\n",
       "      <td>15931 obs/sec</td>\n",
       "      <td>6.792533</td>\n",
       "      <td>398</td>\n",
       "      <td>407552.0</td>\n",
       "      <td>0.172769</td>\n",
       "      <td>1.030232</td>\n",
       "      <td>0.029849</td>\n",
       "      <td>0.214784</td>\n",
       "      <td>1.592321</td>\n",
       "      <td>0.0462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>2016-10-22 14:06:04</td>\n",
       "      <td>38.828 sec</td>\n",
       "      <td>16268 obs/sec</td>\n",
       "      <td>9.096533</td>\n",
       "      <td>533</td>\n",
       "      <td>545792.0</td>\n",
       "      <td>0.143408</td>\n",
       "      <td>0.710301</td>\n",
       "      <td>0.020565</td>\n",
       "      <td>0.205898</td>\n",
       "      <td>1.458663</td>\n",
       "      <td>0.0424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td>2016-10-22 14:06:08</td>\n",
       "      <td>43.276 sec</td>\n",
       "      <td>16196 obs/sec</td>\n",
       "      <td>10.001067</td>\n",
       "      <td>586</td>\n",
       "      <td>600064.0</td>\n",
       "      <td>0.153167</td>\n",
       "      <td>0.807716</td>\n",
       "      <td>0.023460</td>\n",
       "      <td>0.221811</td>\n",
       "      <td>1.699308</td>\n",
       "      <td>0.0492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td>2016-10-22 14:06:09</td>\n",
       "      <td>44.132 sec</td>\n",
       "      <td>16181 obs/sec</td>\n",
       "      <td>10.001067</td>\n",
       "      <td>586</td>\n",
       "      <td>600064.0</td>\n",
       "      <td>0.143408</td>\n",
       "      <td>0.710301</td>\n",
       "      <td>0.020565</td>\n",
       "      <td>0.205898</td>\n",
       "      <td>1.458663</td>\n",
       "      <td>0.0424</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               timestamp    duration training_speed     epochs  iterations  \\\n",
       "0    2016-10-22 14:05:27   0.000 sec           None   0.000000           0   \n",
       "1    2016-10-22 14:05:27   2.943 sec   4000 obs/sec   0.017067           1   \n",
       "2    2016-10-22 14:05:47  21.886 sec  15467 obs/sec   4.744533         278   \n",
       "3    2016-10-22 14:05:55  29.946 sec  15931 obs/sec   6.792533         398   \n",
       "4    2016-10-22 14:06:04  38.828 sec  16268 obs/sec   9.096533         533   \n",
       "5    2016-10-22 14:06:08  43.276 sec  16196 obs/sec  10.001067         586   \n",
       "6    2016-10-22 14:06:09  44.132 sec  16181 obs/sec  10.001067         586   \n",
       "\n",
       "    samples  training_rmse  training_logloss  training_classification_error  \\\n",
       "0       0.0            NaN               NaN                            NaN   \n",
       "1    1024.0       0.466294          7.509779                       0.217430   \n",
       "2  284672.0       0.201571          1.403343                       0.040631   \n",
       "3  407552.0       0.172769          1.030232                       0.029849   \n",
       "4  545792.0       0.143408          0.710301                       0.020565   \n",
       "5  600064.0       0.153167          0.807716                       0.023460   \n",
       "6  600064.0       0.143408          0.710301                       0.020565   \n",
       "\n",
       "   validation_rmse  validation_logloss  validation_classification_error  \n",
       "0              NaN                 NaN                              NaN  \n",
       "1         0.461303            7.349852                           0.2128  \n",
       "2         0.233452            1.882363                           0.0545  \n",
       "3         0.214784            1.592321                           0.0462  \n",
       "4         0.205898            1.458663                           0.0424  \n",
       "5         0.221811            1.699308                           0.0492  \n",
       "6         0.205898            1.458663                           0.0424  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.scoring_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ModelMetricsMultinomial: deepwater\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.0205658497306\n",
      "RMSE: 0.143407983497\n",
      "LogLoss: 0.710300723795\n",
      "Mean Per-Class Error: 0.0206263535198\n",
      "Confusion Matrix: vertical: actual; across: predicted\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>0</b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>2</b></td>\n",
       "<td><b>3</b></td>\n",
       "<td><b>4</b></td>\n",
       "<td><b>5</b></td>\n",
       "<td><b>6</b></td>\n",
       "<td><b>7</b></td>\n",
       "<td><b>8</b></td>\n",
       "<td><b>9</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>989.0</td>\n",
       "<td>0.0</td>\n",
       "<td>5.0</td>\n",
       "<td>0.0</td>\n",
       "<td>3.0</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0</td>\n",
       "<td>4.0</td>\n",
       "<td>2.0</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0178749</td>\n",
       "<td>18 / 1,007</td></tr>\n",
       "<tr><td>1.0</td>\n",
       "<td>1110.0</td>\n",
       "<td>2.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>2.0</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0089286</td>\n",
       "<td>10 / 1,120</td></tr>\n",
       "<tr><td>4.0</td>\n",
       "<td>0.0</td>\n",
       "<td>966.0</td>\n",
       "<td>1.0</td>\n",
       "<td>4.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0122699</td>\n",
       "<td>12 / 978</td></tr>\n",
       "<tr><td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>7.0</td>\n",
       "<td>988.0</td>\n",
       "<td>2.0</td>\n",
       "<td>6.0</td>\n",
       "<td>0.0</td>\n",
       "<td>5.0</td>\n",
       "<td>6.0</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0275591</td>\n",
       "<td>28 / 1,016</td></tr>\n",
       "<tr><td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>924.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>2.0</td>\n",
       "<td>1.0</td>\n",
       "<td>4.0</td>\n",
       "<td>0.0107066</td>\n",
       "<td>10 / 934</td></tr>\n",
       "<tr><td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>4.0</td>\n",
       "<td>0.0</td>\n",
       "<td>902.0</td>\n",
       "<td>3.0</td>\n",
       "<td>4.0</td>\n",
       "<td>4.0</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0195652</td>\n",
       "<td>18 / 920</td></tr>\n",
       "<tr><td>5.0</td>\n",
       "<td>1.0</td>\n",
       "<td>6.0</td>\n",
       "<td>0.0</td>\n",
       "<td>3.0</td>\n",
       "<td>3.0</td>\n",
       "<td>962.0</td>\n",
       "<td>0.0</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0203666</td>\n",
       "<td>20 / 982</td></tr>\n",
       "<tr><td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>5.0</td>\n",
       "<td>2.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1034.0</td>\n",
       "<td>0.0</td>\n",
       "<td>4.0</td>\n",
       "<td>0.0124164</td>\n",
       "<td>13 / 1,047</td></tr>\n",
       "<tr><td>5.0</td>\n",
       "<td>0.0</td>\n",
       "<td>3.0</td>\n",
       "<td>8.0</td>\n",
       "<td>0.0</td>\n",
       "<td>9.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>982.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0277228</td>\n",
       "<td>28 / 1,010</td></tr>\n",
       "<tr><td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>3.0</td>\n",
       "<td>17.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>23.0</td>\n",
       "<td>4.0</td>\n",
       "<td>954.0</td>\n",
       "<td>0.0488534</td>\n",
       "<td>49 / 1,003</td></tr>\n",
       "<tr><td>1007.0</td>\n",
       "<td>1113.0</td>\n",
       "<td>995.0</td>\n",
       "<td>1007.0</td>\n",
       "<td>955.0</td>\n",
       "<td>924.0</td>\n",
       "<td>966.0</td>\n",
       "<td>1075.0</td>\n",
       "<td>1004.0</td>\n",
       "<td>971.0</td>\n",
       "<td>0.0205650</td>\n",
       "<td>206 / 10,017</td></tr></table></div>"
      ],
      "text/plain": [
       "0     1     2    3     4    5    6    7     8     9    Error       Rate\n",
       "----  ----  ---  ----  ---  ---  ---  ----  ----  ---  ----------  ------------\n",
       "989   0     5    0     3    2    0    4     2     2    0.0178749   18 / 1,007\n",
       "1     1110  2    1     1    0    0    1     2     2    0.00892857  10 / 1,120\n",
       "4     0     966  1     4    1    0    1     1     0    0.0122699   12 / 978\n",
       "0     0     7    988   2    6    0    5     6     2    0.0275591   28 / 1,016\n",
       "1     1     1    0     924  0    0    2     1     4    0.0107066   10 / 934\n",
       "1     0     0    4     0    902  3    4     4     2    0.0195652   18 / 920\n",
       "5     1     6    0     3    3    962  0     2     0    0.0203666   20 / 982\n",
       "0     1     5    2     1    0    0    1034  0     4    0.0124164   13 / 1,047\n",
       "5     0     3    8     0    9    1    1     982   1    0.0277228   28 / 1,010\n",
       "1     0     0    3     17   1    0    23    4     954  0.0488534   49 / 1,003\n",
       "1007  1113  995  1007  955  924  966  1075  1004  971  0.020565    206 / 10,017"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-10 Hit Ratios: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>k</b></td>\n",
       "<td><b>hit_ratio</b></td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>0.9794350</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.9811321</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.9811321</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.9811321</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.9811321</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.9811321</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.9811321</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.9811321</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.9811321</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>1.0</td></tr></table></div>"
      ],
      "text/plain": [
       "k    hit_ratio\n",
       "---  -----------\n",
       "1    0.979435\n",
       "2    0.981132\n",
       "3    0.981132\n",
       "4    0.981132\n",
       "5    0.981132\n",
       "6    0.981132\n",
       "7    0.981132\n",
       "8    0.981132\n",
       "9    0.981132\n",
       "10   1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model_performance(train=True) # training metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ModelMetricsMultinomial: deepwater\n",
      "** Reported on validation data. **\n",
      "\n",
      "MSE: 0.0423941150908\n",
      "RMSE: 0.205898312501\n",
      "LogLoss: 1.45866322191\n",
      "Mean Per-Class Error: 0.0428466948895\n",
      "Confusion Matrix: vertical: actual; across: predicted\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>0</b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>2</b></td>\n",
       "<td><b>3</b></td>\n",
       "<td><b>4</b></td>\n",
       "<td><b>5</b></td>\n",
       "<td><b>6</b></td>\n",
       "<td><b>7</b></td>\n",
       "<td><b>8</b></td>\n",
       "<td><b>9</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>953.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>3.0</td>\n",
       "<td>5.0</td>\n",
       "<td>1.0</td>\n",
       "<td>6.0</td>\n",
       "<td>11.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0275510</td>\n",
       "<td>27 / 980</td></tr>\n",
       "<tr><td>0.0</td>\n",
       "<td>1123.0</td>\n",
       "<td>4.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>3.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0105727</td>\n",
       "<td>12 / 1,135</td></tr>\n",
       "<tr><td>4.0</td>\n",
       "<td>1.0</td>\n",
       "<td>998.0</td>\n",
       "<td>5.0</td>\n",
       "<td>7.0</td>\n",
       "<td>0.0</td>\n",
       "<td>2.0</td>\n",
       "<td>7.0</td>\n",
       "<td>7.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0329457</td>\n",
       "<td>34 / 1,032</td></tr>\n",
       "<tr><td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>12.0</td>\n",
       "<td>959.0</td>\n",
       "<td>0.0</td>\n",
       "<td>11.0</td>\n",
       "<td>0.0</td>\n",
       "<td>13.0</td>\n",
       "<td>13.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0504950</td>\n",
       "<td>51 / 1,010</td></tr>\n",
       "<tr><td>4.0</td>\n",
       "<td>1.0</td>\n",
       "<td>7.0</td>\n",
       "<td>0.0</td>\n",
       "<td>941.0</td>\n",
       "<td>1.0</td>\n",
       "<td>4.0</td>\n",
       "<td>5.0</td>\n",
       "<td>2.0</td>\n",
       "<td>17.0</td>\n",
       "<td>0.0417515</td>\n",
       "<td>41 / 982</td></tr>\n",
       "<tr><td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>3.0</td>\n",
       "<td>14.0</td>\n",
       "<td>1.0</td>\n",
       "<td>851.0</td>\n",
       "<td>6.0</td>\n",
       "<td>7.0</td>\n",
       "<td>7.0</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0459641</td>\n",
       "<td>41 / 892</td></tr>\n",
       "<tr><td>4.0</td>\n",
       "<td>2.0</td>\n",
       "<td>6.0</td>\n",
       "<td>0.0</td>\n",
       "<td>8.0</td>\n",
       "<td>7.0</td>\n",
       "<td>927.0</td>\n",
       "<td>0.0</td>\n",
       "<td>3.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0323591</td>\n",
       "<td>31 / 958</td></tr>\n",
       "<tr><td>1.0</td>\n",
       "<td>5.0</td>\n",
       "<td>15.0</td>\n",
       "<td>1.0</td>\n",
       "<td>3.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>993.0</td>\n",
       "<td>5.0</td>\n",
       "<td>5.0</td>\n",
       "<td>0.0340467</td>\n",
       "<td>35 / 1,028</td></tr>\n",
       "<tr><td>4.0</td>\n",
       "<td>2.0</td>\n",
       "<td>4.0</td>\n",
       "<td>11.0</td>\n",
       "<td>9.0</td>\n",
       "<td>17.0</td>\n",
       "<td>3.0</td>\n",
       "<td>8.0</td>\n",
       "<td>914.0</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0616016</td>\n",
       "<td>60 / 974</td></tr>\n",
       "<tr><td>0.0</td>\n",
       "<td>2.0</td>\n",
       "<td>3.0</td>\n",
       "<td>11.0</td>\n",
       "<td>28.0</td>\n",
       "<td>4.0</td>\n",
       "<td>0.0</td>\n",
       "<td>34.0</td>\n",
       "<td>10.0</td>\n",
       "<td>917.0</td>\n",
       "<td>0.0911794</td>\n",
       "<td>92 / 1,009</td></tr>\n",
       "<tr><td>971.0</td>\n",
       "<td>1137.0</td>\n",
       "<td>1052.0</td>\n",
       "<td>1005.0</td>\n",
       "<td>1002.0</td>\n",
       "<td>895.0</td>\n",
       "<td>949.0</td>\n",
       "<td>1079.0</td>\n",
       "<td>963.0</td>\n",
       "<td>947.0</td>\n",
       "<td>0.0424</td>\n",
       "<td>424 / 10,000</td></tr></table></div>"
      ],
      "text/plain": [
       "0    1     2     3     4     5    6    7     8    9    Error      Rate\n",
       "---  ----  ----  ----  ----  ---  ---  ----  ---  ---  ---------  ------------\n",
       "953  0     0     3     5     1    6    11    0    1    0.027551   27 / 980\n",
       "0    1123  4     1     0     3    1    1     2    0    0.0105727  12 / 1,135\n",
       "4    1     998   5     7     0    2    7     7    1    0.0329457  34 / 1,032\n",
       "0    1     12    959   0     11   0    13    13   1    0.050495   51 / 1,010\n",
       "4    1     7     0     941   1    4    5     2    17   0.0417515  41 / 982\n",
       "1    0     3     14    1     851  6    7     7    2    0.0459641  41 / 892\n",
       "4    2     6     0     8     7    927  0     3    1    0.0323591  31 / 958\n",
       "1    5     15    1     3     0    0    993   5    5    0.0340467  35 / 1,028\n",
       "4    2     4     11    9     17   3    8     914  2    0.0616016  60 / 974\n",
       "0    2     3     11    28    4    0    34    10   917  0.0911794  92 / 1,009\n",
       "971  1137  1052  1005  1002  895  949  1079  963  947  0.0424     424 / 10,000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-10 Hit Ratios: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>k</b></td>\n",
       "<td><b>hit_ratio</b></td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>0.9576</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.9618</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.9618</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.9618</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.9618</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.9618</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.9618</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.9618</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.9618</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>1.0</td></tr></table></div>"
      ],
      "text/plain": [
       "k    hit_ratio\n",
       "---  -----------\n",
       "1    0.9576\n",
       "2    0.9618\n",
       "3    0.9618\n",
       "4    0.9618\n",
       "5    0.9618\n",
       "6    0.9618\n",
       "7    0.9618\n",
       "8    0.9618\n",
       "9    0.9618\n",
       "10   1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model_performance(valid=True) # validation metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Crossvalidation\n",
    "\n",
    "If the value specified for nfolds is a positive integer, N-fold cross-validation is\n",
    "performed on the training frame and the cross-validation metrics are computed\n",
    "and stored as model output. \n",
    "\n",
    "To disable cross-validation, use `nfolds=0`, which is the default value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Advanced users can also specify a fold column that defines the holdout\n",
    "fold associated with each row. By default, the holdout fold assignment is\n",
    "random. H2O supports other schemes such as round-robin assignment using the modulo\n",
    "operator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform 5-fold cross-validation on training_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_crossvalidated = H2ODeepWaterEstimator(\n",
    "   distribution=\"multinomial\",\n",
    "   activation=\"rectifier\",\n",
    "   hidden=[1024,1024,1024],\n",
    "   #hidden_dropout_ratios=[0.5,0.5,0.5].  ## for better generalization\n",
    "   input_dropout_ratio=0.1,\n",
    "   #sparse=True,                          ## can speed up\n",
    "   epochs=10,\n",
    "   nfolds=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deepwater Model Build progress: |█████████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "model_crossvalidated.train(\n",
    "    x=x,\n",
    "    y=y,\n",
    "    training_frame=train_df\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting and Handling the Results\n",
    "\n",
    "We can now extract the parameters of our model, examine the scoring process,\n",
    "and make predictions on new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# View specified parameters of the Deep Learning model\n",
    "model_crossvalidated.params;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details\n",
      "=============\n",
      "H2ODeepWaterEstimator :  Deep Water\n",
      "Model Key:  DeepWater_model_python_1477169483588_4\n",
      "Status of Deep Learning Model: MLP: [1024, 1024, 1024], 10.9 MB, predicting C785, 10-class classification, 601,088 training samples, mini-batch size 32\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>input_neurons</b></td>\n",
       "<td><b>rate</b></td>\n",
       "<td><b>momentum</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>717</td>\n",
       "<td>0.0031229</td>\n",
       "<td>0.99</td></tr></table></div>"
      ],
      "text/plain": [
       "    input_neurons    rate        momentum\n",
       "--  ---------------  ----------  ----------\n",
       "    717              0.00312288  0.99"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsMultinomial: deepwater\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.634263995822\n",
      "RMSE: 0.796406928537\n",
      "LogLoss: 1.82055506483\n",
      "Mean Per-Class Error: 0.69103131075\n",
      "Confusion Matrix: vertical: actual; across: predicted\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>0</b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>2</b></td>\n",
       "<td><b>3</b></td>\n",
       "<td><b>4</b></td>\n",
       "<td><b>5</b></td>\n",
       "<td><b>6</b></td>\n",
       "<td><b>7</b></td>\n",
       "<td><b>8</b></td>\n",
       "<td><b>9</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>268.0</td>\n",
       "<td>0.0</td>\n",
       "<td>743.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.7349159</td>\n",
       "<td>743 / 1,011</td></tr>\n",
       "<tr><td>1.0</td>\n",
       "<td>584.0</td>\n",
       "<td>484.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.4542056</td>\n",
       "<td>486 / 1,070</td></tr>\n",
       "<tr><td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>946.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0010560</td>\n",
       "<td>1 / 947</td></tr>\n",
       "<tr><td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>865.0</td>\n",
       "<td>170.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.8359073</td>\n",
       "<td>866 / 1,036</td></tr>\n",
       "<tr><td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>773.0</td>\n",
       "<td>0.0</td>\n",
       "<td>243.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.7608268</td>\n",
       "<td>773 / 1,016</td></tr>\n",
       "<tr><td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>671.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>216.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.7567568</td>\n",
       "<td>672 / 888</td></tr>\n",
       "<tr><td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>781.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>207.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.7906977</td>\n",
       "<td>782 / 989</td></tr>\n",
       "<tr><td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>882.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>149.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.8554801</td>\n",
       "<td>882 / 1,031</td></tr>\n",
       "<tr><td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>789.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>207.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.7921687</td>\n",
       "<td>789 / 996</td></tr>\n",
       "<tr><td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>971.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>75.0</td>\n",
       "<td>0.9282983</td>\n",
       "<td>971 / 1,046</td></tr>\n",
       "<tr><td>270.0</td>\n",
       "<td>585.0</td>\n",
       "<td>7905.0</td>\n",
       "<td>171.0</td>\n",
       "<td>243.0</td>\n",
       "<td>217.0</td>\n",
       "<td>208.0</td>\n",
       "<td>149.0</td>\n",
       "<td>207.0</td>\n",
       "<td>75.0</td>\n",
       "<td>0.6944167</td>\n",
       "<td>6,965 / 10,030</td></tr></table></div>"
      ],
      "text/plain": [
       "0    1    2     3    4    5    6    7    8    9    Error       Rate\n",
       "---  ---  ----  ---  ---  ---  ---  ---  ---  ---  ----------  --------------\n",
       "268  0    743   0    0    0    0    0    0    0    0.734916    743 / 1,011\n",
       "1    584  484   1    0    0    0    0    0    0    0.454206    486 / 1,070\n",
       "1    0    946   0    0    0    0    0    0    0    0.00105597  1 / 947\n",
       "0    1    865   170  0    0    0    0    0    0    0.835907    866 / 1,036\n",
       "0    0    773   0    243  0    0    0    0    0    0.760827    773 / 1,016\n",
       "0    0    671   0    0    216  1    0    0    0    0.756757    672 / 888\n",
       "0    0    781   0    0    1    207  0    0    0    0.790698    782 / 989\n",
       "0    0    882   0    0    0    0    149  0    0    0.85548     882 / 1,031\n",
       "0    0    789   0    0    0    0    0    207  0    0.792169    789 / 996\n",
       "0    0    971   0    0    0    0    0    0    75   0.928298    971 / 1,046\n",
       "270  585  7905  171  243  217  208  149  207  75   0.694417    6,965 / 10,030"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-10 Hit Ratios: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>k</b></td>\n",
       "<td><b>hit_ratio</b></td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>0.3055832</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.3938185</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.4801595</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.5769691</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.6548355</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.7334995</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.8075773</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.8744766</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.9515454</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>1.0</td></tr></table></div>"
      ],
      "text/plain": [
       "k    hit_ratio\n",
       "---  -----------\n",
       "1    0.305583\n",
       "2    0.393819\n",
       "3    0.48016\n",
       "4    0.576969\n",
       "5    0.654835\n",
       "6    0.733499\n",
       "7    0.807577\n",
       "8    0.874477\n",
       "9    0.951545\n",
       "10   1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ModelMetricsMultinomial: deepwater\n",
      "** Reported on cross-validation data. **\n",
      "\n",
      "MSE: 0.0491166666667\n",
      "RMSE: 0.221622802678\n",
      "LogLoss: 1.69642956726\n",
      "Mean Per-Class Error: 0.0496408453366\n",
      "Confusion Matrix: vertical: actual; across: predicted\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>0</b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>2</b></td>\n",
       "<td><b>3</b></td>\n",
       "<td><b>4</b></td>\n",
       "<td><b>5</b></td>\n",
       "<td><b>6</b></td>\n",
       "<td><b>7</b></td>\n",
       "<td><b>8</b></td>\n",
       "<td><b>9</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>5804.0</td>\n",
       "<td>2.0</td>\n",
       "<td>19.0</td>\n",
       "<td>4.0</td>\n",
       "<td>7.0</td>\n",
       "<td>10.0</td>\n",
       "<td>48.0</td>\n",
       "<td>6.0</td>\n",
       "<td>15.0</td>\n",
       "<td>8.0</td>\n",
       "<td>0.0200912</td>\n",
       "<td>119 / 5,923</td></tr>\n",
       "<tr><td>0.0</td>\n",
       "<td>6582.0</td>\n",
       "<td>46.0</td>\n",
       "<td>24.0</td>\n",
       "<td>12.0</td>\n",
       "<td>7.0</td>\n",
       "<td>9.0</td>\n",
       "<td>16.0</td>\n",
       "<td>34.0</td>\n",
       "<td>12.0</td>\n",
       "<td>0.0237318</td>\n",
       "<td>160 / 6,742</td></tr>\n",
       "<tr><td>51.0</td>\n",
       "<td>13.0</td>\n",
       "<td>5623.0</td>\n",
       "<td>60.0</td>\n",
       "<td>22.0</td>\n",
       "<td>6.0</td>\n",
       "<td>74.0</td>\n",
       "<td>50.0</td>\n",
       "<td>48.0</td>\n",
       "<td>11.0</td>\n",
       "<td>0.0562269</td>\n",
       "<td>335 / 5,958</td></tr>\n",
       "<tr><td>24.0</td>\n",
       "<td>10.0</td>\n",
       "<td>76.0</td>\n",
       "<td>5738.0</td>\n",
       "<td>3.0</td>\n",
       "<td>137.0</td>\n",
       "<td>11.0</td>\n",
       "<td>31.0</td>\n",
       "<td>82.0</td>\n",
       "<td>19.0</td>\n",
       "<td>0.0641005</td>\n",
       "<td>393 / 6,131</td></tr>\n",
       "<tr><td>9.0</td>\n",
       "<td>10.0</td>\n",
       "<td>23.0</td>\n",
       "<td>3.0</td>\n",
       "<td>5576.0</td>\n",
       "<td>4.0</td>\n",
       "<td>54.0</td>\n",
       "<td>22.0</td>\n",
       "<td>33.0</td>\n",
       "<td>108.0</td>\n",
       "<td>0.0455324</td>\n",
       "<td>266 / 5,842</td></tr>\n",
       "<tr><td>55.0</td>\n",
       "<td>7.0</td>\n",
       "<td>12.0</td>\n",
       "<td>115.0</td>\n",
       "<td>15.0</td>\n",
       "<td>5032.0</td>\n",
       "<td>68.0</td>\n",
       "<td>9.0</td>\n",
       "<td>77.0</td>\n",
       "<td>31.0</td>\n",
       "<td>0.0717580</td>\n",
       "<td>389 / 5,421</td></tr>\n",
       "<tr><td>36.0</td>\n",
       "<td>10.0</td>\n",
       "<td>16.0</td>\n",
       "<td>1.0</td>\n",
       "<td>15.0</td>\n",
       "<td>25.0</td>\n",
       "<td>5798.0</td>\n",
       "<td>0.0</td>\n",
       "<td>17.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0202771</td>\n",
       "<td>120 / 5,918</td></tr>\n",
       "<tr><td>17.0</td>\n",
       "<td>13.0</td>\n",
       "<td>40.0</td>\n",
       "<td>50.0</td>\n",
       "<td>37.0</td>\n",
       "<td>13.0</td>\n",
       "<td>2.0</td>\n",
       "<td>5991.0</td>\n",
       "<td>20.0</td>\n",
       "<td>82.0</td>\n",
       "<td>0.0437350</td>\n",
       "<td>274 / 6,265</td></tr>\n",
       "<tr><td>41.0</td>\n",
       "<td>32.0</td>\n",
       "<td>57.0</td>\n",
       "<td>95.0</td>\n",
       "<td>13.0</td>\n",
       "<td>77.0</td>\n",
       "<td>39.0</td>\n",
       "<td>21.0</td>\n",
       "<td>5431.0</td>\n",
       "<td>45.0</td>\n",
       "<td>0.0717826</td>\n",
       "<td>420 / 5,851</td></tr>\n",
       "<tr><td>24.0</td>\n",
       "<td>11.0</td>\n",
       "<td>7.0</td>\n",
       "<td>43.0</td>\n",
       "<td>134.0</td>\n",
       "<td>32.0</td>\n",
       "<td>4.0</td>\n",
       "<td>96.0</td>\n",
       "<td>120.0</td>\n",
       "<td>5478.0</td>\n",
       "<td>0.0791730</td>\n",
       "<td>471 / 5,949</td></tr>\n",
       "<tr><td>6061.0</td>\n",
       "<td>6690.0</td>\n",
       "<td>5919.0</td>\n",
       "<td>6133.0</td>\n",
       "<td>5834.0</td>\n",
       "<td>5343.0</td>\n",
       "<td>6107.0</td>\n",
       "<td>6242.0</td>\n",
       "<td>5877.0</td>\n",
       "<td>5794.0</td>\n",
       "<td>0.0491167</td>\n",
       "<td>2,947 / 60,000</td></tr></table></div>"
      ],
      "text/plain": [
       "0     1     2     3     4     5     6     7     8     9     Error      Rate\n",
       "----  ----  ----  ----  ----  ----  ----  ----  ----  ----  ---------  --------------\n",
       "5804  2     19    4     7     10    48    6     15    8     0.0200912  119 / 5,923\n",
       "0     6582  46    24    12    7     9     16    34    12    0.0237318  160 / 6,742\n",
       "51    13    5623  60    22    6     74    50    48    11    0.0562269  335 / 5,958\n",
       "24    10    76    5738  3     137   11    31    82    19    0.0641005  393 / 6,131\n",
       "9     10    23    3     5576  4     54    22    33    108   0.0455324  266 / 5,842\n",
       "55    7     12    115   15    5032  68    9     77    31    0.071758   389 / 5,421\n",
       "36    10    16    1     15    25    5798  0     17    0     0.0202771  120 / 5,918\n",
       "17    13    40    50    37    13    2     5991  20    82    0.043735   274 / 6,265\n",
       "41    32    57    95    13    77    39    21    5431  45    0.0717826  420 / 5,851\n",
       "24    11    7     43    134   32    4     96    120   5478  0.079173   471 / 5,949\n",
       "6061  6690  5919  6133  5834  5343  6107  6242  5877  5794  0.0491167  2,947 / 60,000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-10 Hit Ratios: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>k</b></td>\n",
       "<td><b>hit_ratio</b></td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>0.9508833</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.95555</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.95555</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.95555</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.95555</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.95555</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.95555</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.95555</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.95555</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>1.0</td></tr></table></div>"
      ],
      "text/plain": [
       "k    hit_ratio\n",
       "---  -----------\n",
       "1    0.950883\n",
       "2    0.95555\n",
       "3    0.95555\n",
       "4    0.95555\n",
       "5    0.95555\n",
       "6    0.95555\n",
       "7    0.95555\n",
       "8    0.95555\n",
       "9    0.95555\n",
       "10   1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Metrics Summary: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>mean</b></td>\n",
       "<td><b>sd</b></td>\n",
       "<td><b>cv_1_valid</b></td>\n",
       "<td><b>cv_2_valid</b></td>\n",
       "<td><b>cv_3_valid</b></td></tr>\n",
       "<tr><td>accuracy</td>\n",
       "<td>0.9508791</td>\n",
       "<td>0.0006143</td>\n",
       "<td>0.951584</td>\n",
       "<td>0.9513983</td>\n",
       "<td>0.9496551</td></tr>\n",
       "<tr><td>err</td>\n",
       "<td>0.0491209</td>\n",
       "<td>0.0006143</td>\n",
       "<td>0.0484160</td>\n",
       "<td>0.0486018</td>\n",
       "<td>0.0503449</td></tr>\n",
       "<tr><td>err_count</td>\n",
       "<td>982.3333</td>\n",
       "<td>8.875685</td>\n",
       "<td>972.0</td>\n",
       "<td>975.0</td>\n",
       "<td>1000.0</td></tr>\n",
       "<tr><td>logloss</td>\n",
       "<td>1.6965752</td>\n",
       "<td>0.0212184</td>\n",
       "<td>1.67223</td>\n",
       "<td>1.6786455</td>\n",
       "<td>1.73885</td></tr>\n",
       "<tr><td>max_per_class_error</td>\n",
       "<td>0.0971907</td>\n",
       "<td>0.0044872</td>\n",
       "<td>0.1041162</td>\n",
       "<td>0.0887850</td>\n",
       "<td>0.0986708</td></tr>\n",
       "<tr><td>mean_per_class_accuracy</td>\n",
       "<td>0.9504780</td>\n",
       "<td>0.0005867</td>\n",
       "<td>0.9511799</td>\n",
       "<td>0.9509413</td>\n",
       "<td>0.9493127</td></tr>\n",
       "<tr><td>mean_per_class_error</td>\n",
       "<td>0.0495220</td>\n",
       "<td>0.0005867</td>\n",
       "<td>0.0488201</td>\n",
       "<td>0.0490587</td>\n",
       "<td>0.0506873</td></tr>\n",
       "<tr><td>mse</td>\n",
       "<td>0.0491209</td>\n",
       "<td>0.0006143</td>\n",
       "<td>0.0484160</td>\n",
       "<td>0.0486018</td>\n",
       "<td>0.0503449</td></tr>\n",
       "<tr><td>r2</td>\n",
       "<td>0.9941153</td>\n",
       "<td>0.0000685</td>\n",
       "<td>0.9942274</td>\n",
       "<td>0.9941276</td>\n",
       "<td>0.993991</td></tr>\n",
       "<tr><td>rmse</td>\n",
       "<td>0.2216237</td>\n",
       "<td>0.0013818</td>\n",
       "<td>0.2200364</td>\n",
       "<td>0.2204581</td>\n",
       "<td>0.2243766</td></tr></table></div>"
      ],
      "text/plain": [
       "                         mean       sd           cv_1_valid    cv_2_valid    cv_3_valid\n",
       "-----------------------  ---------  -----------  ------------  ------------  ------------\n",
       "accuracy                 0.950879   0.000614335  0.951584      0.951398      0.949655\n",
       "err                      0.0491209  0.000614335  0.048416      0.0486018     0.0503449\n",
       "err_count                982.333    8.87569      972           975           1000\n",
       "logloss                  1.69658    0.0212184    1.67223       1.67865       1.73885\n",
       "max_per_class_error      0.0971907  0.00448718   0.104116      0.088785      0.0986708\n",
       "mean_per_class_accuracy  0.950478   0.00058669   0.95118       0.950941      0.949313\n",
       "mean_per_class_error     0.049522   0.00058669   0.0488201     0.0490587     0.0506873\n",
       "mse                      0.0491209  0.000614335  0.048416      0.0486018     0.0503449\n",
       "r2                       0.994115   6.85229e-05  0.994227      0.994128      0.993991\n",
       "rmse                     0.221624   0.00138183   0.220036      0.220458      0.224377"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring History: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>timestamp</b></td>\n",
       "<td><b>duration</b></td>\n",
       "<td><b>training_speed</b></td>\n",
       "<td><b>epochs</b></td>\n",
       "<td><b>iterations</b></td>\n",
       "<td><b>samples</b></td>\n",
       "<td><b>training_rmse</b></td>\n",
       "<td><b>training_logloss</b></td>\n",
       "<td><b>training_classification_error</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-10-22 14:07:51</td>\n",
       "<td> 0.000 sec</td>\n",
       "<td>None</td>\n",
       "<td>0.0</td>\n",
       "<td>0</td>\n",
       "<td>0.0</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-10-22 14:07:52</td>\n",
       "<td> 1 min 41.109 sec</td>\n",
       "<td>8462 obs/sec</td>\n",
       "<td>0.0170667</td>\n",
       "<td>1</td>\n",
       "<td>1024.0</td>\n",
       "<td>0.4766743</td>\n",
       "<td>7.8478436</td>\n",
       "<td>0.2272183</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-10-22 14:07:58</td>\n",
       "<td> 1 min 47.674 sec</td>\n",
       "<td>13516 obs/sec</td>\n",
       "<td>1.4165333</td>\n",
       "<td>83</td>\n",
       "<td>84992.0</td>\n",
       "<td>0.2896596</td>\n",
       "<td>2.8912934</td>\n",
       "<td>0.0839482</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-10-22 14:08:03</td>\n",
       "<td> 1 min 52.741 sec</td>\n",
       "<td>14651 obs/sec</td>\n",
       "<td>2.6624</td>\n",
       "<td>156</td>\n",
       "<td>159744.0</td>\n",
       "<td>0.2185331</td>\n",
       "<td>1.6494590</td>\n",
       "<td>0.0477567</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-10-22 14:08:08</td>\n",
       "<td> 1 min 57.794 sec</td>\n",
       "<td>15398 obs/sec</td>\n",
       "<td>3.9765333</td>\n",
       "<td>233</td>\n",
       "<td>238592.0</td>\n",
       "<td>0.2205766</td>\n",
       "<td>1.6804509</td>\n",
       "<td>0.0486540</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-10-22 14:08:14</td>\n",
       "<td> 2 min  2.876 sec</td>\n",
       "<td>15849 obs/sec</td>\n",
       "<td>5.3077333</td>\n",
       "<td>311</td>\n",
       "<td>318464.0</td>\n",
       "<td>0.2139222</td>\n",
       "<td>1.5799959</td>\n",
       "<td>0.0457627</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-10-22 14:08:19</td>\n",
       "<td> 2 min  7.920 sec</td>\n",
       "<td>16145 obs/sec</td>\n",
       "<td>6.6389333</td>\n",
       "<td>389</td>\n",
       "<td>398336.0</td>\n",
       "<td>0.2146202</td>\n",
       "<td>1.5908554</td>\n",
       "<td>0.0460618</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-10-22 14:08:24</td>\n",
       "<td> 2 min 12.978 sec</td>\n",
       "<td>16161 obs/sec</td>\n",
       "<td>7.8848</td>\n",
       "<td>462</td>\n",
       "<td>473088.0</td>\n",
       "<td>0.5248475</td>\n",
       "<td>2.1057897</td>\n",
       "<td>0.2846461</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-10-22 14:08:29</td>\n",
       "<td> 2 min 17.987 sec</td>\n",
       "<td>16225 obs/sec</td>\n",
       "<td>9.1477333</td>\n",
       "<td>536</td>\n",
       "<td>548864.0</td>\n",
       "<td>0.7810443</td>\n",
       "<td>1.8049201</td>\n",
       "<td>0.6672981</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-10-22 14:08:32</td>\n",
       "<td> 2 min 21.509 sec</td>\n",
       "<td>16291 obs/sec</td>\n",
       "<td>10.0181333</td>\n",
       "<td>587</td>\n",
       "<td>601088.0</td>\n",
       "<td>0.7964069</td>\n",
       "<td>1.8205551</td>\n",
       "<td>0.6944167</td></tr></table></div>"
      ],
      "text/plain": [
       "    timestamp            duration          training_speed    epochs     iterations    samples    training_rmse    training_logloss    training_classification_error\n",
       "--  -------------------  ----------------  ----------------  ---------  ------------  ---------  ---------------  ------------------  -------------------------------\n",
       "    2016-10-22 14:07:51  0.000 sec                           0          0             0          nan              nan                 nan\n",
       "    2016-10-22 14:07:52  1 min 41.109 sec  8462 obs/sec      0.0170667  1             1024       0.476674         7.84784             0.227218\n",
       "    2016-10-22 14:07:58  1 min 47.674 sec  13516 obs/sec     1.41653    83            84992      0.28966          2.89129             0.0839482\n",
       "    2016-10-22 14:08:03  1 min 52.741 sec  14651 obs/sec     2.6624     156           159744     0.218533         1.64946             0.0477567\n",
       "    2016-10-22 14:08:08  1 min 57.794 sec  15398 obs/sec     3.97653    233           238592     0.220577         1.68045             0.048654\n",
       "    2016-10-22 14:08:14  2 min  2.876 sec  15849 obs/sec     5.30773    311           318464     0.213922         1.58                0.0457627\n",
       "    2016-10-22 14:08:19  2 min  7.920 sec  16145 obs/sec     6.63893    389           398336     0.21462          1.59086             0.0460618\n",
       "    2016-10-22 14:08:24  2 min 12.978 sec  16161 obs/sec     7.8848     462           473088     0.524848         2.10579             0.284646\n",
       "    2016-10-22 14:08:29  2 min 17.987 sec  16225 obs/sec     9.14773    536           548864     0.781044         1.80492             0.667298\n",
       "    2016-10-22 14:08:32  2 min 21.509 sec  16291 obs/sec     10.0181    587           601088     0.796407         1.82056             0.694417"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine the trained model\n",
    "model_crossvalidated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The validation error is based on the\n",
    "parameter `score validation samples`, which configures the same value\n",
    "on the validation set (by default, this is the entire validation set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04284669488946667"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Validation error of the original model (using a train/valid split)\n",
    "model.mean_per_class_error(valid=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6910313107498208"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Training error of the model trained on 100% of the data\n",
    "model_crossvalidated.mean_per_class_error(train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04964084533660609"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Estimated generalization error of the cross-validated model\n",
    "model_crossvalidated.mean_per_class_error(xval=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#ls ../../h2o-docs/src/booklets/v2_2015/source/images/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Predicting\n",
    "\n",
    "Once we have a satisfactory model (as determined by the validation or crossvalidation\n",
    "metrics), use the `h2o.predict()` command to compute and store\n",
    "predictions on new data for additional refinements in the interactive data science\n",
    "process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deepwater prediction progress: |██████████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "predictions = model_crossvalidated.predict(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th style=\"text-align: right;\">  predict</th><th style=\"text-align: right;\">       p0</th><th style=\"text-align: right;\">        p1</th><th style=\"text-align: right;\">         p2</th><th style=\"text-align: right;\">     p3</th><th style=\"text-align: right;\">       p4</th><th style=\"text-align: right;\">      p5</th><th style=\"text-align: right;\">      p6</th><th style=\"text-align: right;\">      p7</th><th style=\"text-align: right;\">       p8</th><th style=\"text-align: right;\">      p9</th></tr>\n",
       "<tr><td style=\"text-align: right;\">        2</td><td style=\"text-align: right;\">0.0951605</td><td style=\"text-align: right;\">0.0562663 </td><td style=\"text-align: right;\">0.121961   </td><td style=\"text-align: right;\">0.11441</td><td style=\"text-align: right;\">0.0899458</td><td style=\"text-align: right;\">0.092208</td><td style=\"text-align: right;\">0.101479</td><td style=\"text-align: right;\">0.114793</td><td style=\"text-align: right;\">0.0993742</td><td style=\"text-align: right;\">0.114402</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        3</td><td style=\"text-align: right;\">0        </td><td style=\"text-align: right;\">0.00159502</td><td style=\"text-align: right;\">5.02568e-06</td><td style=\"text-align: right;\">0.9984 </td><td style=\"text-align: right;\">0        </td><td style=\"text-align: right;\">0       </td><td style=\"text-align: right;\">0       </td><td style=\"text-align: right;\">0       </td><td style=\"text-align: right;\">0        </td><td style=\"text-align: right;\">0       </td></tr>\n",
       "<tr><td style=\"text-align: right;\">        2</td><td style=\"text-align: right;\">0.0951605</td><td style=\"text-align: right;\">0.0562663 </td><td style=\"text-align: right;\">0.121961   </td><td style=\"text-align: right;\">0.11441</td><td style=\"text-align: right;\">0.0899458</td><td style=\"text-align: right;\">0.092208</td><td style=\"text-align: right;\">0.101479</td><td style=\"text-align: right;\">0.114793</td><td style=\"text-align: right;\">0.0993742</td><td style=\"text-align: right;\">0.114402</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        2</td><td style=\"text-align: right;\">0.0951605</td><td style=\"text-align: right;\">0.0562663 </td><td style=\"text-align: right;\">0.121961   </td><td style=\"text-align: right;\">0.11441</td><td style=\"text-align: right;\">0.0899458</td><td style=\"text-align: right;\">0.092208</td><td style=\"text-align: right;\">0.101479</td><td style=\"text-align: right;\">0.114793</td><td style=\"text-align: right;\">0.0993742</td><td style=\"text-align: right;\">0.114402</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        2</td><td style=\"text-align: right;\">0.0951605</td><td style=\"text-align: right;\">0.0562663 </td><td style=\"text-align: right;\">0.121961   </td><td style=\"text-align: right;\">0.11441</td><td style=\"text-align: right;\">0.0899458</td><td style=\"text-align: right;\">0.092208</td><td style=\"text-align: right;\">0.101479</td><td style=\"text-align: right;\">0.114793</td><td style=\"text-align: right;\">0.0993742</td><td style=\"text-align: right;\">0.114402</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        2</td><td style=\"text-align: right;\">0.0951605</td><td style=\"text-align: right;\">0.0562663 </td><td style=\"text-align: right;\">0.121961   </td><td style=\"text-align: right;\">0.11441</td><td style=\"text-align: right;\">0.0899458</td><td style=\"text-align: right;\">0.092208</td><td style=\"text-align: right;\">0.101479</td><td style=\"text-align: right;\">0.114793</td><td style=\"text-align: right;\">0.0993742</td><td style=\"text-align: right;\">0.114402</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        2</td><td style=\"text-align: right;\">0.0951605</td><td style=\"text-align: right;\">0.0562663 </td><td style=\"text-align: right;\">0.121961   </td><td style=\"text-align: right;\">0.11441</td><td style=\"text-align: right;\">0.0899458</td><td style=\"text-align: right;\">0.092208</td><td style=\"text-align: right;\">0.101479</td><td style=\"text-align: right;\">0.114793</td><td style=\"text-align: right;\">0.0993742</td><td style=\"text-align: right;\">0.114402</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        2</td><td style=\"text-align: right;\">0.0951605</td><td style=\"text-align: right;\">0.0562663 </td><td style=\"text-align: right;\">0.121961   </td><td style=\"text-align: right;\">0.11441</td><td style=\"text-align: right;\">0.0899458</td><td style=\"text-align: right;\">0.092208</td><td style=\"text-align: right;\">0.101479</td><td style=\"text-align: right;\">0.114793</td><td style=\"text-align: right;\">0.0993742</td><td style=\"text-align: right;\">0.114402</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        2</td><td style=\"text-align: right;\">0.0951605</td><td style=\"text-align: right;\">0.0562663 </td><td style=\"text-align: right;\">0.121961   </td><td style=\"text-align: right;\">0.11441</td><td style=\"text-align: right;\">0.0899458</td><td style=\"text-align: right;\">0.092208</td><td style=\"text-align: right;\">0.101479</td><td style=\"text-align: right;\">0.114793</td><td style=\"text-align: right;\">0.0993742</td><td style=\"text-align: right;\">0.114402</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        2</td><td style=\"text-align: right;\">0.0951605</td><td style=\"text-align: right;\">0.0562663 </td><td style=\"text-align: right;\">0.121961   </td><td style=\"text-align: right;\">0.11441</td><td style=\"text-align: right;\">0.0899458</td><td style=\"text-align: right;\">0.092208</td><td style=\"text-align: right;\">0.101479</td><td style=\"text-align: right;\">0.114793</td><td style=\"text-align: right;\">0.0993742</td><td style=\"text-align: right;\">0.114402</td></tr>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable Importance\n",
    "\n",
    "Variable importance allows us to view the absolute and relative predictive strength of\n",
    "each feature in the prediction task.\n",
    "Each H2O algorithm class has its own methodology for computing variable importance.\n",
    "\n",
    "You can enable the variable importance, by setting the `variable_importances` parameter to `True`.\n",
    "\n",
    "H2O’s Deep Learning uses the Gedeon method [Gedeon, 1997](http://users.cecs.anu.edu.au/~Tom.Gedeon/pdfs/ContribDataMinv2.pdf), which is disabled\n",
    "by default since it can be slow for large networks. \n",
    "\n",
    "If variable importance is a top priority in your analysis, consider training a Distributed Random Forest (DRF) model and compare the generated variable importances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train Deep Learning model and validate on test set and save the variable importances\n",
    "from h2o.estimators.deeplearning import H2ODeepLearningEstimator\n",
    "\n",
    "model_variable_importances = H2ODeepLearningEstimator(\n",
    "     distribution=\"multinomial\",\n",
    "     activation=\"RectifierWithDropout\",\n",
    "     hidden=[32,32,32],         ## smaller number of neurons to be fast enough on the CPU\n",
    "     input_dropout_ratio=0.2,\n",
    "     sparse=True,\n",
    "     epochs=10,\n",
    "     variable_importances=True) ## this is not yet implemented for DeepWaterEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deeplearning Model Build progress: |██████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "model_variable_importances.train(\n",
    "         x=x,\n",
    "         y=y,\n",
    "         training_frame=train_df,\n",
    "         validation_frame=test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C379</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.003012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C351</td>\n",
       "      <td>0.981022</td>\n",
       "      <td>0.981022</td>\n",
       "      <td>0.002955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C488</td>\n",
       "      <td>0.947116</td>\n",
       "      <td>0.947116</td>\n",
       "      <td>0.002853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C491</td>\n",
       "      <td>0.917125</td>\n",
       "      <td>0.917125</td>\n",
       "      <td>0.002763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C323</td>\n",
       "      <td>0.887518</td>\n",
       "      <td>0.887518</td>\n",
       "      <td>0.002674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>C348</td>\n",
       "      <td>0.875348</td>\n",
       "      <td>0.875348</td>\n",
       "      <td>0.002637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>C486</td>\n",
       "      <td>0.868360</td>\n",
       "      <td>0.868360</td>\n",
       "      <td>0.002616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>C490</td>\n",
       "      <td>0.861337</td>\n",
       "      <td>0.861337</td>\n",
       "      <td>0.002595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>C489</td>\n",
       "      <td>0.858364</td>\n",
       "      <td>0.858364</td>\n",
       "      <td>0.002586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>C378</td>\n",
       "      <td>0.847305</td>\n",
       "      <td>0.847305</td>\n",
       "      <td>0.002552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>C487</td>\n",
       "      <td>0.826313</td>\n",
       "      <td>0.826313</td>\n",
       "      <td>0.002489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>C320</td>\n",
       "      <td>0.819662</td>\n",
       "      <td>0.819662</td>\n",
       "      <td>0.002469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>C377</td>\n",
       "      <td>0.817130</td>\n",
       "      <td>0.817130</td>\n",
       "      <td>0.002462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>C434</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.002442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>C380</td>\n",
       "      <td>0.805856</td>\n",
       "      <td>0.805856</td>\n",
       "      <td>0.002428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>C324</td>\n",
       "      <td>0.804754</td>\n",
       "      <td>0.804754</td>\n",
       "      <td>0.002424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>C515</td>\n",
       "      <td>0.799527</td>\n",
       "      <td>0.799527</td>\n",
       "      <td>0.002408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>C375</td>\n",
       "      <td>0.798024</td>\n",
       "      <td>0.798024</td>\n",
       "      <td>0.002404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>C403</td>\n",
       "      <td>0.794309</td>\n",
       "      <td>0.794309</td>\n",
       "      <td>0.002393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>C347</td>\n",
       "      <td>0.782969</td>\n",
       "      <td>0.782969</td>\n",
       "      <td>0.002359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>C376</td>\n",
       "      <td>0.780410</td>\n",
       "      <td>0.780410</td>\n",
       "      <td>0.002351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>C518</td>\n",
       "      <td>0.769808</td>\n",
       "      <td>0.769808</td>\n",
       "      <td>0.002319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>C516</td>\n",
       "      <td>0.768837</td>\n",
       "      <td>0.768837</td>\n",
       "      <td>0.002316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>C404</td>\n",
       "      <td>0.765285</td>\n",
       "      <td>0.765285</td>\n",
       "      <td>0.002305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>C344</td>\n",
       "      <td>0.760956</td>\n",
       "      <td>0.760956</td>\n",
       "      <td>0.002292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>C517</td>\n",
       "      <td>0.759907</td>\n",
       "      <td>0.759907</td>\n",
       "      <td>0.002289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>C350</td>\n",
       "      <td>0.758880</td>\n",
       "      <td>0.758880</td>\n",
       "      <td>0.002286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>C407</td>\n",
       "      <td>0.756711</td>\n",
       "      <td>0.756711</td>\n",
       "      <td>0.002280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>C373</td>\n",
       "      <td>0.755477</td>\n",
       "      <td>0.755477</td>\n",
       "      <td>0.002276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>C349</td>\n",
       "      <td>0.752905</td>\n",
       "      <td>0.752905</td>\n",
       "      <td>0.002268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>C43</td>\n",
       "      <td>0.316797</td>\n",
       "      <td>0.316797</td>\n",
       "      <td>0.000954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>C364</td>\n",
       "      <td>0.315059</td>\n",
       "      <td>0.315059</td>\n",
       "      <td>0.000949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>C563</td>\n",
       "      <td>0.313991</td>\n",
       "      <td>0.313991</td>\n",
       "      <td>0.000946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>C279</td>\n",
       "      <td>0.313365</td>\n",
       "      <td>0.313365</td>\n",
       "      <td>0.000944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>691</th>\n",
       "      <td>C111</td>\n",
       "      <td>0.313289</td>\n",
       "      <td>0.313289</td>\n",
       "      <td>0.000944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>692</th>\n",
       "      <td>C605</td>\n",
       "      <td>0.312975</td>\n",
       "      <td>0.312975</td>\n",
       "      <td>0.000943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693</th>\n",
       "      <td>C283</td>\n",
       "      <td>0.312389</td>\n",
       "      <td>0.312389</td>\n",
       "      <td>0.000941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>C120</td>\n",
       "      <td>0.311955</td>\n",
       "      <td>0.311955</td>\n",
       "      <td>0.000940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>C536</td>\n",
       "      <td>0.311880</td>\n",
       "      <td>0.311880</td>\n",
       "      <td>0.000940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>C396</td>\n",
       "      <td>0.311506</td>\n",
       "      <td>0.311506</td>\n",
       "      <td>0.000938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>C231</td>\n",
       "      <td>0.311004</td>\n",
       "      <td>0.311004</td>\n",
       "      <td>0.000937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>C132</td>\n",
       "      <td>0.307068</td>\n",
       "      <td>0.307068</td>\n",
       "      <td>0.000925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>C230</td>\n",
       "      <td>0.307001</td>\n",
       "      <td>0.307001</td>\n",
       "      <td>0.000925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>C769</td>\n",
       "      <td>0.306081</td>\n",
       "      <td>0.306081</td>\n",
       "      <td>0.000922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701</th>\n",
       "      <td>C425</td>\n",
       "      <td>0.302470</td>\n",
       "      <td>0.302470</td>\n",
       "      <td>0.000911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>702</th>\n",
       "      <td>C668</td>\n",
       "      <td>0.301573</td>\n",
       "      <td>0.301573</td>\n",
       "      <td>0.000908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>703</th>\n",
       "      <td>C201</td>\n",
       "      <td>0.301237</td>\n",
       "      <td>0.301237</td>\n",
       "      <td>0.000907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>C144</td>\n",
       "      <td>0.299976</td>\n",
       "      <td>0.299976</td>\n",
       "      <td>0.000904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>C419</td>\n",
       "      <td>0.292624</td>\n",
       "      <td>0.292624</td>\n",
       "      <td>0.000881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>C478</td>\n",
       "      <td>0.292519</td>\n",
       "      <td>0.292519</td>\n",
       "      <td>0.000881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707</th>\n",
       "      <td>C173</td>\n",
       "      <td>0.292039</td>\n",
       "      <td>0.292039</td>\n",
       "      <td>0.000880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>C422</td>\n",
       "      <td>0.290893</td>\n",
       "      <td>0.290893</td>\n",
       "      <td>0.000876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>C82</td>\n",
       "      <td>0.289686</td>\n",
       "      <td>0.289686</td>\n",
       "      <td>0.000873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>C224</td>\n",
       "      <td>0.288967</td>\n",
       "      <td>0.288967</td>\n",
       "      <td>0.000870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>C695</td>\n",
       "      <td>0.288762</td>\n",
       "      <td>0.288762</td>\n",
       "      <td>0.000870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>C653</td>\n",
       "      <td>0.287420</td>\n",
       "      <td>0.287420</td>\n",
       "      <td>0.000866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>713</th>\n",
       "      <td>C472</td>\n",
       "      <td>0.282404</td>\n",
       "      <td>0.282404</td>\n",
       "      <td>0.000851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714</th>\n",
       "      <td>C706</td>\n",
       "      <td>0.271169</td>\n",
       "      <td>0.271169</td>\n",
       "      <td>0.000817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>C64</td>\n",
       "      <td>0.265465</td>\n",
       "      <td>0.265465</td>\n",
       "      <td>0.000800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>C66</td>\n",
       "      <td>0.242973</td>\n",
       "      <td>0.242973</td>\n",
       "      <td>0.000732</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>717 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3\n",
       "0    C379  1.000000  1.000000  0.003012\n",
       "1    C351  0.981022  0.981022  0.002955\n",
       "2    C488  0.947116  0.947116  0.002853\n",
       "3    C491  0.917125  0.917125  0.002763\n",
       "4    C323  0.887518  0.887518  0.002674\n",
       "5    C348  0.875348  0.875348  0.002637\n",
       "6    C486  0.868360  0.868360  0.002616\n",
       "7    C490  0.861337  0.861337  0.002595\n",
       "8    C489  0.858364  0.858364  0.002586\n",
       "9    C378  0.847305  0.847305  0.002552\n",
       "10   C487  0.826313  0.826313  0.002489\n",
       "11   C320  0.819662  0.819662  0.002469\n",
       "12   C377  0.817130  0.817130  0.002462\n",
       "13   C434  0.810780  0.810780  0.002442\n",
       "14   C380  0.805856  0.805856  0.002428\n",
       "15   C324  0.804754  0.804754  0.002424\n",
       "16   C515  0.799527  0.799527  0.002408\n",
       "17   C375  0.798024  0.798024  0.002404\n",
       "18   C403  0.794309  0.794309  0.002393\n",
       "19   C347  0.782969  0.782969  0.002359\n",
       "20   C376  0.780410  0.780410  0.002351\n",
       "21   C518  0.769808  0.769808  0.002319\n",
       "22   C516  0.768837  0.768837  0.002316\n",
       "23   C404  0.765285  0.765285  0.002305\n",
       "24   C344  0.760956  0.760956  0.002292\n",
       "25   C517  0.759907  0.759907  0.002289\n",
       "26   C350  0.758880  0.758880  0.002286\n",
       "27   C407  0.756711  0.756711  0.002280\n",
       "28   C373  0.755477  0.755477  0.002276\n",
       "29   C349  0.752905  0.752905  0.002268\n",
       "..    ...       ...       ...       ...\n",
       "687   C43  0.316797  0.316797  0.000954\n",
       "688  C364  0.315059  0.315059  0.000949\n",
       "689  C563  0.313991  0.313991  0.000946\n",
       "690  C279  0.313365  0.313365  0.000944\n",
       "691  C111  0.313289  0.313289  0.000944\n",
       "692  C605  0.312975  0.312975  0.000943\n",
       "693  C283  0.312389  0.312389  0.000941\n",
       "694  C120  0.311955  0.311955  0.000940\n",
       "695  C536  0.311880  0.311880  0.000940\n",
       "696  C396  0.311506  0.311506  0.000938\n",
       "697  C231  0.311004  0.311004  0.000937\n",
       "698  C132  0.307068  0.307068  0.000925\n",
       "699  C230  0.307001  0.307001  0.000925\n",
       "700  C769  0.306081  0.306081  0.000922\n",
       "701  C425  0.302470  0.302470  0.000911\n",
       "702  C668  0.301573  0.301573  0.000908\n",
       "703  C201  0.301237  0.301237  0.000907\n",
       "704  C144  0.299976  0.299976  0.000904\n",
       "705  C419  0.292624  0.292624  0.000881\n",
       "706  C478  0.292519  0.292519  0.000881\n",
       "707  C173  0.292039  0.292039  0.000880\n",
       "708  C422  0.290893  0.290893  0.000876\n",
       "709   C82  0.289686  0.289686  0.000873\n",
       "710  C224  0.288967  0.288967  0.000870\n",
       "711  C695  0.288762  0.288762  0.000870\n",
       "712  C653  0.287420  0.287420  0.000866\n",
       "713  C472  0.282404  0.282404  0.000851\n",
       "714  C706  0.271169  0.271169  0.000817\n",
       "715   C64  0.265465  0.265465  0.000800\n",
       "716   C66  0.242973  0.242973  0.000732\n",
       "\n",
       "[717 rows x 4 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve the variable importance\n",
    "import pandas as pd\n",
    "pd.DataFrame(model_variable_importances.varimp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABIUAAANLCAYAAADfCS3nAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAPYQAAD2EBqD+naQAAIABJREFUeJzs3XmcdFdZJ/DfebPv+x4gAZJAWIISdgQJCBIEERRERRRw\nRFRk0AHHZcSRGRABN3QERVFEUJRNWYIIKBL2nbAHiNnIvr9Z3/fOH/cWXenUPVXVXfUufb/fz6c+\np7vPc2+dWrq666lzzlOapgkAAAAAw7Jpew8AAAAAgG1PUggAAABggCSFAAAAAAZIUggAAABggCSF\nAAAAAAZIUggAAABggCSFAAAAAAZIUggAAABggCSFAAAAAAZIUghgB1NK+XYpZWsp5U+XdP5Hdeff\nWkq57zrO8+LuHJsXOT4A2N6W/bcYYEchKQRsGKWUPxtLdnzvnMd+39ixv7+kIc6q6S7b4np2eqWU\nj0hOsTMrpfzs2OvPk2Y8pvq8L6XsVko5vZTyB6WUM0spl5RSbiqlXF5K+XiX1L3DGsb6mFLKn5dS\nvtid6/pSyjmllPeWUp5XSjl83nP2XM948nr8cnMp5bJSyjdKKR8opbyslPL4Usqui7jejWYtzy2+\nY1v9LQbYriSFgI3kb7q2SfITcx771LFj/3phI1of/4zOxv20TmZ97TDmeS73xpZSjk5yUZJ/SfKc\nJPdLcnCSXZIckOS7k7wgyZdKKc+a5cpKKaeUUj6a5J+TPCPJSd25dk9ybJKHJXlZkq+XUv7HHLdj\nmmbVZVOSA5PcIcn3JHlekjcnObeU8oJSiv9tJ/M6uXbuO2BD86kKsGE0TXNmKeXsJHdK8sRSys83\nTXPjtONKKXsn+aG0//id1TTNZ5Y81KqmaY7antcP7PT2Sps4aZJ8Msnbk3w0ySXdzx+T5OeT7Jnk\nT0op1zZN87d9JyulnJbkLUn268750SSvS/KFJNelTQo9OslPJtknye+WUk5O8vSmaRbxhvoPkrxm\n7Pt90ya5Tkny8O5yeJIXJ3lsKeUHmqa5cgHXy4D5WwwMhaQQsNG8LskLk+yf5AeT/MMMxzwh7RuZ\nJiuzjQB2Vk2Sdyb5zaZpPj2h/wOllLcmeW/amT6vKKW8aVISvZRyfNqZOPsm2ZrkOU3TrN5j5VNJ\n3l5KeVmStyU5OW2C6FtJfnsBt+eipmm+OOHn706bgLp7kr9Nco8kD0jyplLKo5qm2bqA6waADc0U\nW2CjeV1WpnrPuoRstHRsa5LXL3xEANtQ0zTfaJrmB3oSQqOYDyX5iyQlySFpl39N8pq0SfYk+ZUJ\nCaHxc56d5BFJLu7O++ullHuu4SbMpWmaLyR5YJIvdtd7WpKfWfb1AsBGICkEbChN03wzyYfSvjF4\nVCnl0Fp8KeWotEsPmiTva5rmwgkx9yyl/GYp5T2llPNKKTeWUq4ppXyllPKaUsq9p1zHrfZrKaUc\nWEp5YSnlM6WUK1ZvADqt4kkp5ehSyi+UUv6plPK1Usp13Wav55ZS3lxKecK0+2nV+TaVUn6ulPLh\nbuPYa0opnyql/EopZfd5ztVz/j1LKc8tpbyvu203llIuKqW8u5Tyk8veA2RsQ953dt/fpdso95ul\nlM3dhrV/Vko5ZtVxp5RSXtf1jzbT/eNSyiGV63pjd11f7L4/tpTyh93jtLm73W8vpTx8xrHfqxvr\n6HG+qpTy+W5z3WMqx520enPZUsqTuvv8glLKLaWUd402oU27v0yS7Fkmb+57+Ni5N5VSHlFKeXm5\n7QbGnyylvKQ2tu4cqx+T23X309e7+/qSUso75rifjiil/Hb3HL54bDwf7n7/Tq4cu12fn9vZ+8e+\nvtPqzlLKfZJ8b7plaE3T/MG0EzZN8+0kz+++3SXJIvcXql3v5rSzk0aeX0opffHd6+iLu+fs+IbZ\nbyilPGSW61zrOXp+P59SSnl/9/y9rpRyVinld0op+816HyzTeu6vUsrBpZRnlFJeX9oNyq/pfs8u\nLKW8s5Ty06WyUfiMr2fvHItf/Tp8cCnl/3TXfV03/veXKRtvl8rf4jKhimcp5cdKu/n5JaV9vf9i\nd70H1O/dpJRyXCnl1aX9u3R9af/X+MdSyoO7fvu+AcvTNI2Li4vLhrokeWbaWT9bkvzClNhfGYv9\nsQn9j+r6RzGrL6O+/1W5jhd3MZuT3CXJf00435PG4i/sfvanE86119j11sbzz0n27BnPo8aOf2iS\nf+s539Ykn05y8LTbVbnt905y7pTx/mffdcz4eH+4No6uf0va5TSPTnJtzzjOS3J8d8xPJbmxJ+4r\nSQ7tua43dDFfTHL/JJdWHqMXTbldL0xyS+WxuW78ebPq2JPGjvvRJH8/4TzvTPLfVp1z0mN0S5LD\nx879kkrs6DxXJzl9ymM2GsNDk1xeuZ9+fsr99NPdY1p7jn1xGc/Psft5a5J3ruM5/LNjY5j4mM77\nvJ/xHE8Zu95nTej/k7H+H5/jvLum3eh6a5Ibkuy1hrGNv049f47jPjB23L0qz5nrKr9bW7vbXqY8\n79Z0jtz69/PJaZe+9Z3nW0nuuC2fW4u+v5J8e8rv2NYkH0lyyJTfs+rr2Vj8+Ovw3dL+ze273pdW\nbnftb/H48/NBaZeq990/Z6XyNy4rf5cmHX9L2s3Up/69dXFxcVnrZSN/+gUM1z+kfSOSrCwN6zNa\nYnZt2o1UV9s1yTVJ/i7tG+iHpq3c8+i0n4afm/ZT9N+a9qlj2tmZb05yaJKXp52hdGo3hrOnHDt+\nji1Jzkib0HpU2je2D0ubDPtYN57Tk/z+DOd7adqZAP+Sdg+mU5P8cNoZBE2Se6bdI2RupZS7duc5\nOskVSX4nyeO76/j+JH+W9h/eByZ5c+1T/QU5Lu2bhYuS/FzaikwPSftmpklyVJJXlVIelHZZzZfS\nJofuk/axemN3njunvd9q9k/yprQb+b4obZWk+yf57931J8n/LKVMXOJSSnlekv+VdsbbhUl+qTv+\nId35NqdNEL6+lNK37GfkV9M+pv+W9g3VqUkemfaN1d+n3YflL7vYm5LcvfvZ6HLPtMmtkV3SPu//\nOMmPp338Tk27Wfsr0v4u7ZvkjaWUO04Z2x3S/k5sTvt8flCS+6b93bqqi3lZKeU2s1iSpLv/XpP2\nvrgu7XP+0Wl/Rx+atvLWe9P+zqw+dpHPz521OtFDx77+0oT+8Rkg/zLrSZumuSXJu7pvd0v73N1W\n3jv29fes7iylPDXtc2bPtAneX8rK6+iPpH1tbZI8K+1z4jYWcY4xz0vyY2mTj0/uzvEDaX8vmiS3\nS/LuUsqeU86zFAu6rSXt7fv1tJuc3yfJg9P+ff7X7vj7pF3+PU3t9Wy1/dJ+QLJv2iT7Q7v4ZyW5\noIv55VlnhlX8bpInpv3f4/FZeQzP6PrvkuT3Jh1YSjkpyT+mfQ27Ke1r2Glp749nJvlad+y013mA\ntdveWSkXFxeXZVzSvoEffep2Qk/MPcZi/rIn5tAk+1WuZ/e0byy3JvlST8zoE76taWefPHjK2Guf\nTu6S5A5Tjv+/3XXdlOTYCf3jn3BuSfKKnvO8bizupyq3q2+Gzie6Y89MckBPzOPGxjHzTIRV55hl\nptDo/v/cpLEk+aOx23pRug14J8S9bXRdSfaf0P+GsevanOS+E2Jul/YNyda0yYj9V/UfleT6bizf\nTHLEhHPcN20SZEuSr2fVJ/S59SfrW5L8vyn34cyfQqdN5Gyq9N9+7Dn8qhkeky8nOWxCzGljt+HF\nPffj5q7/3PT8nnexxyzj+ZnlzBR6XtrZDdMun5n1Mas8TqPZCecm2WVV/65jt/3sNZz/OWO36blr\nOH6tM4VOHzvuj1f1HZl2FtuWtEnNvpktL8vK6/Xtl3CO8d/PrUne1HOO3xmLe+ECnltzzRRaxG3t\n+u80xxgfMKF/3tez8dfhiyddf9pEzQ3d+d7Qc55ZZwpNfI6n/RBn9P9B39+Md3X9Nyd55IT+vdNu\n5P6dvytreR64uLi41C5mCgEb1XgVsb7ZQj859vXETyibprm0aZpr+q6kaZqbsrIfy4nd7IPe8LRv\nkv+zElPVNM2WpmnOmRL2W2lnWeyS5LFTYs/LyvhX+/m0SYskefbMg0xSSnlE2tkaTZKnNk1z1aS4\npmnenvaT3JJ2Vs4yNWmXIk0ay2jPiJK21PUzusd2tf/XtXukTczUruuPmqb52G06mubcrNzn++e2\nG6I/szt/kvxi0zQXrepPd96Xd+M9Pu0b4T6XpJ2htBBN05zTVKo6NU3zX2k/7S5pZ59VT5fk2U3T\nXDLhPO9Lm/gomTDjI+1tGs2e+Ommab5WGdP5498v+PnZjF0W4WVJPj/DZc0bOHeznl6d9g1nk+S3\nmqZZPZvq4LS3O2mX/8xr/Hnbuw/XElw29vVBq/p+Me2skW+mfRPf95j9z7S/N7vmtn8/FnGOkZI2\nufusnv4Xpp0pUpL8t20wm3K1hdzWpt2AvFfTNK/Kyky1x08Z0zyvZ02SX510/U3TfDnt8tW+15d5\nnNlM2G+re50czdi9zd+MUspxaWc5NUle3zTNeyacY3PapBnA0kgKARvVGWnflJS0S1xupfvn+ind\nt+c1TfP+WU5aStmjtJvi3rWUcrdSyt2y8sYpSU6Zcoq/m+V6ZlXaTX+P7jbiHI3npKxMjZ82njc0\nTXPzpI6maa5Ou4ShJPnuWTbLHPO4rv3ctDcESf6ja5e9xOSipmk+OKmje4NwY9p/zj9eSbx9duzr\naUujXlvp+4e0bwaTtlrTuNH3FzdNU1uy8+cTjpnkrU3T3FDpX5dSyv6llONLKSePPQdHt+2wUsqR\nlcMv7pI/fT7ZtZPu68d07ZeapnnvhP6ahTw/m6b5StM0u3SXx6zuX6Nmjsta/e+svBl9V9M0fzkh\nZnyD42vXcB3jx+zfG7V449e7epPmx6a9zW+fkAT7ju418aNpX/sesIRzfCcsyTuaprlsYmd7/tEH\nHEeknd26LS3ytn5HaTeGP3H0etG9ZpzfHT/tb9Y8r2dbMnlZ2cjo9eWosr6iCrWqpZ8c+3r169hp\nWfn/4W/7TtA0zcfTLt0DWIrenf4BdmZN02wppfxd2k8UjyulPKhpSzCPPDztXiJNKv+MJUkpZd8k\nz03ypCR3TTsDp0+12lna5Uvr0iW0npZ25sJ9szJbYrVmhvF8fEr/x5I8I+0/rndPW9ltFqd27b1K\nW91qFnuXUvZtmmYtb0Bn8dUp/Venvb9qcVeOfV2rCnRtl2iaqGmaG0spn0v7Bmr1G727p33sPlEb\nbNM055ZSvp32zeLdK6Hrfs6tVko5Pm1VqcekXcZVc2j6Z5pMe6Nzedfe6r4upeyd5IS099PERN8U\nO+Lzc+RHm6Z507SgUsqH0+6LNZdSytPT7u3SpL3/f7IndHyG5L7zXs+qY65ew/FrNf5c+c71dnvy\n3K379rmllOfOeL7vJDUXcY4JZnkNHrlHlvD7PMmib2sp5fFp9+V7cOrPp0X+Db2gaZrrKv2Xj329\nX249y2weva/1E65j3Pjr9idT94m0H/gALJykELCR/U1Wppk/NbdOaIxPce/d3LKUckLa/WVul5VP\n5id9Qj/6tG+vynhu6aaCr1kpZa+0y1lOmzKekdp4kna/hZrxJSAHT4kdd3jmn8nQpF3Osow33U3a\nPR1qRsmBWtx4AqGWHLy00jcyum+/c792Cb8Du2+nPTZJm2w5MvXH5opK39xKKT+Yds+OPVOfsTLt\nd2Kex2T1fT3+xvHCKeeYZEd7fo5b2hKhUsoTkrwq7W05N+0eJpf3hF+elfuoltToc8TY12t9s70W\n48+Ny1f9vGT+WVbjz99FnGO1Zb0Gr9dCbmspZVOSv87KjN1prxnT/mbN83o26+tLUn89X8/11K5j\ntLxxa9M0027XbZbYAiyKpBCwYTVN89lSyufTfrr6I6WUX2ya5uZulsET0v5j+snajI60y71ul/Yf\nu1enrSj15SSXjpZddYma0aeRtTd0vdPv5/C/s5IQem/aCkmfTvLt8Sn1pZSPpp0NMe0N5qL2QVlt\n9M/vx5M8fY7jZkmm7AwWcb8u6rFZxPMuSbvsI20SdY+0+1a9NO3z8OwkVzdt1amUUh6d5B2jwxZ1\n/Qs0uOdnKeWRaV/Pdkn7BvORTdOc1xffNM0tpZQvJTk57WzLA/r2Xurx3WNff7Y3avG+a+zr8Zlo\n42/I/zQr+4NNc+OCz7Hasl6D12tRt/Xn0iaEmrS/b3/UteePf0hSSvn7tNXMpr1eLOz1DICWpBCw\n0f1N2nKuB6bdH+HNaRNC+6T9J/Wv+w4spZyStrRsk+Q3m6Z5cU/oNvn0tvvE9ae78fxr0zTfXwmf\ndUxHzNHfN6NgksvSVqnau2maL85x3EZx2Awxo/v2O/dr0zRNKeXKtM/XaY9N0s7gaDLfY7MeP5p2\n6UeT5PSmaT7cE7fs34nx5MxRazh+UM/PUsqD07727Z52CeQjm6aZtpwyafdTOrn7+rGZstR27Pp2\nTTJ6fbo5yUfmGvD6fN/Y1+Ob+o/PVmrW+Lgv4hyrLes1eL0WdVufmfb14otpK2/e0hO3LWdB7ShG\ns4M2lVIOmjJbaJa/KQBrYqNpYKN7fVY+WRxVeRotHbs5ben6Pncb+/ofKnGnVvoWaXyZUO+eI6WU\ngzJ9E+SR+8zR/4UZz5m0s5eS5C6llAOrkRvTvqWUu/R1dpua3jPtm6XV9+sX0n5aXn1elVKOzcqy\nnnkem0lmna0w+p24oJIQSpb8O9HNMPhq2vvpIWs4xWCen6WUeyf5l6wsfTu9aZpZZ+68duzrX5jj\nap+SlSV6/9A0zfVzHLtm3W19cHe9ZzdN8539Z7q9oEabij9oLedfxDkmWNZr8Los8LaOkopv7UsI\ndR943Cs77qypZTlr7Ot7T4ndVv9nAAMkKQRsaE3TfDvt8paS5PSuyslo+dW7+6q+dMZnU+5Tifu5\ndQ90NrOO52cz+5KdHy2l7Dapo5SyX5Inpr2vPjXn0pG3d+0uacsaD9HTKn1PzspjuLpy1uj7w0sp\nP1A5x89MOGatRksPJz4Xxoyeg3v3BXQbs//YOsczi3/u2rt0S6PmMYjnZynl5CTvTlv964Ykj2ua\nZuZZO03TfCzJv6d9PblPKeU5M1znkWmXFSZtQv5l8457LbplweMzP393Qtjb096We3Wzp9ZiEecY\nGf1dmjhLppSyS1Y2Ar84yefXeX3zWtdt7fZIGy1Dq/3NelKSQ+Yf3k7vfVlJhD21L6iUct/YZBpY\nIkkhYAhGJX13SzszaJdVP+/ztbGvf2pSQCnlv6ct7bwtXJCVvYt+vHvDsHo8D0rym5n9E9fbJelb\nFvfKrGyE+adzjDNN0/xz2n1ESpJfL6U8rhZfSrlXKaW2HG5nU5I8p5Rym093uxk+o/v8mtx2Sc5f\npN2XoyT5w1LK4RPOcWqSX+6+/UaSd65zvKPNmjeVUo6rxI1+Jw6c9Jh2z8nXZtssdfijtImOkuQ1\npZQT+wJLKceMf7+o52cp5aRSytbust7HYKFKKXdM8p60b7ZvSvLDTdN8YA2nekba52lJ8vJSyrMq\n13mntAnKI9K+Br1ofLbOspRS7pl2idrJ3fW+J8lfTQh9RdpNgUuSv609Z7rzPm7CjL9FnGOkSZss\n+bMugbLabyU5sYt7ddM0s1bKW5R13damaZq0s41Kkh/qPmhYfcxJSf4g7W3cEfcfW5qmab6ZlQ+t\nfqyU8qjVMaWUfdLuHTi0WVTANmRPIWAI3pL2Tc2+WZnKfkVWZhr0+WjaJSonpi3Je1jaqksXpt2P\n5GlJfjDtvhXr/cR4qm7j1zemfZN2nyQfLKX8Qdp/ug9M8ri0JX8vT5s8uvMMp/1Ekud1/+y/Osn5\naW/bLyZ5WNp/RD/SNM2kN1jT/GiSDyc5IMlbSilvTbvs7etpN+4+Iu1mtD+Ydmr8i9LOatgILkh7\nGz9QSnl5kjPSLld8YJJfzcqb5hesnoHVNM2FpZRfS/LyJMcn+VQp5SVpn4+7JXlU2oTQ3mlnYvxM\n9+ZrPc4c+/qPu+u7KCtvRL7RXccbk7ywG8fflVJ+P8m/pV2WdM+0z5t7Zhv8TjRNc24p5RfTPm+P\nSXs/vSrtfX1R2vLP90jy+CTH5tbLQZPFPj93qDdsXSLxvWn3W2qSvCTJOd1MyT6XN01zm0puTdN8\no5TyxCT/lPY19E9LKU9Lm1T/fNqkwTFJHpN2tsNeWdmv7XcWdJOOWDX2fdIupT0lySOSPHw03LT7\nID15UgKlaZrzSynPTJuIvX3a58xfpX1cz0+759Ltktw/yQ+nfS18RMZKji/iHKt8oov7j1LKH6Z9\nPT8y7QboT+xivpH2MVyvh3aFEaZ5c9M01yzotv5N2ufBHZJ8pJTy0rT7C+2Vdv+n56T9kPozufUm\n4UPxS0k+lbaa49tLKa9MO0PrmrTP7xek/Vv+8ST3zQ72WgNsEE3TuLi4uGz4S5LXpH2jN7r8yYzH\nnZo2ybJl1fFbu599LO0botH3z59wjhd3/ZtnvM4Lu3P96YS+g5J8rmc8W7tj75f2ze7WJO+ccI5H\njY33oWnf1Pfdvk8nObRnnFNvV5K7pn0D0Dfe0fVsSfIra3xsP1wbR+2+mPV+H4vZY8pj/Yau/4tp\n3yhdWrm9/3fKeH4rbSKp77G5NsmP9Bx70ljck2a8H99aeZwOH4v72SS3VMb1l0kePfb9fdfxmMzy\nHHtG2iRo39i3JDlrGc/Psft56m2Zcjt/dg2PV+/zPiu/4/Ncep/33TlPSft6N7o/+u6rqybdV2u4\nT2a9DaPxnJ/kl2c89+PT/7o+ft4bk9xv0efIrX8/n5w26dL3+/StJHdawHNr1suWJCcu8LbunpW/\nMZOOvyrtJubfee1c7+tZ7VyV37vDJ/TX/haP/x29zWvcWFz1b0YXc3ra1/NJ988taRNDv9t9f9l6\nf7dcXFxcVl8sHwOG4q/TfsLWpP3H6nWzHNQ0zSfSfnr550nOSbsM49K0b8iem3YDzlElpNoneM2U\n/r5jVo/nirTJht9Ou+no9UmuTrth5UuS3Ktpmo/OcJ2jvuuz8mntR9NWJrou7ae2L0j7z26tDHf1\ndjVN86Ukd0+7L8abk/xXd503pn0T974k/7sb93r2Hpl2/85z/88SNzWmafdu+e60y/DOTrvU6dK0\npdq/r2maX5ty/G+nTUr+ZXf85rSfHn8h7Syik5qm6d1wPPM/534kyf9M+4n0VWl/T0a/L+PjelXa\nZOLb05Y2vyntzKh3JHlC0zRPHzt2EY/JtOfYa5KckPZN06fSzgK8OW31pA+lnaUwcXnYgp6fTdb2\n+913nkUd06zh0n9FTfPZpmnum3bm1F+lnQ1yZdrn9Xlp76v/keTO6/xdnnYbtqR9jM9Ju9/RK5L8\nUJLbN03z8plO2jRvTXJc2te496edWXZT2te+s5O8Le0MjjuMvZ4u/Bwrp2p+Iu1z8N/TvkZcn+RL\nSf5Pkns0TXN25fhZrOt5sJ7b2jTNTWmXWD8v7e/ndd3lq0n+OMl3Ne1yzvFx1m7DvLd5EXGLGFPt\nNeydaWc1/kXa5/WNaRNSb03yiKZpfjftvmBJ+9oMsFClacxCBIBFKKW8Ie0n/19umubkafHA8HT7\n6HwpbaLgKU3T1KpbQkopH0y7/Pi9TdPcZu8hgPUwUwgAAGAH1G3+/4Du25mrBwLMSlIIAABgO+iq\n9vX17Z22ouOmtDPLZlr6DjAP1ccAAAC2j9eVUpLkH7OyL9r+aauNPTttFcombYGMr2+vQQIbl6QQ\nAADA9lHSJoDuP6FvtJn1G5P8yrYcFDAcGyop9Bu/8Rt7J7lLki+/6EUv2ry9xwPAIC2iEhWwsXmd\nYOQXkjw+ycOSHJPksO7nFyc5M8lrm6Z573YaGzAAGyoplDYh9MlnP/vZ23scAAzQWEXPk+MNHzDB\nqsq/f99dGKhKJejju8uPb7vRADuJssiT2WgaAAAAYIAkhQAAAAAGSFIIAAAAYIAkhQAAAAAGSFII\nAAAAYIAkhQAAAAAGSFIIAAAAYIAkhQAAAAAGSFIIAAAAYIAkhQAAAAAGSFIIAAAAYIAkhQAAAAAG\nSFIIAAAAYIAkhQAAAAAGSFIIAAAAYIAkhQAAAAAGSFIIAAAAYIAkhQAAAAAGSFIIAAAAYIAkhQAA\nAAAGSFIIAAAAYIAkhQAAAAAGSFIIAAAAYIAkhQAAAAAGSFIIAAAAYIAkhQAAAAAGSFIIAAAAYIAk\nhQAAAAAGSFIIAAAAYIAkhQAAAAAGSFIIAAAAYIAkhQAAAAAGSFIIAAAAYIAkhQAAAAAGSFIIAAAA\nYIAkhQAAAAAGSFIIAAAAYIAkhQAAAAAGSFIIAAAAYIAkhQAAAAAGSFIIAAAAYIAkhQAAAAAGSFII\nAAAAYIAkhQAAAAAGSFIIAAAAYIAkhQAAAAAGSFIIAAAAYIAkhQAAAAAGSFIIAAAAYIAkhQAAAAAG\nSFIIAAAAYIAkhQAAAAAGSFIIAAAAYIAkhQAAAAAGSFIIAAAAYIAkhQAAAAAGSFIIAAAAYIAkhQAA\nAAAGSFIIAAAAYIAkhQAAAAAGSFIIAAAAYIAkhQAAAAAGSFIIAAAAYIAkhQAAAAAGSFIIAAAAYIAk\nhQAAAAAGSFIIAAAAYIAkhQAAAAAGSFIIAAAAYIAkhQAAAAAGSFIIAAAAYIAkhQAAAAAGSFIIAAAA\nYIAkhQAAAAAGSFIIAAAAYIAkhQAAAAAGSFIIAAAAYIAkhQAAAAAGSFIIAAAAYIAkhQAAAAAGSFII\nAAAAYIAkhQAAAAAGSFIIAAAAYIAkhQAAAAAGSFIIAAAAYIAkhQAAAAAGSFIIAAAAYIAkhQAAAAAG\nSFIIAAAAYIAkhQAAAAAGSFIIAAAAYIAkhQAAAAAGSFIIAAAAYIAkhQAAAAAGSFIIAAAAYIAkhQAA\nAAAGSFIIAAAAYIAkhQAAAAAGSFIIAAAAYIAkhQAAAAAGSFIIAAAAYIAkhQAAAAAGSFIIAAAAYIAk\nhQAAAAAGSFIIAAAAYIAkhQAAAAAGSFIIAAAAYIAkhQAAAAAGSFIIAAAAYIAkhQAAAAAGSFIIAAAA\nYIAkhQAZMPfOAAAgAElEQVQAAAAGSFIIAAAAYIAkhQAAAAAGSFIIAAAAYIAkhQAAAAAGSFIIAAAA\nYIAkhQAAAAAGSFIIAAAAYIAkhQAAAAAGSFIIAAAAYIAkhQAAAAAGSFIIAAAAYIAkhQAAAAAGSFII\nAAAAYIAkhQAAAAAGSFIIAAAAYIAkhQAAAAAGSFIIAAAAYIAkhQAAAAAGSFIIAAAAYIAkhQAAAAAG\nSFIIAAAAYIAkhQAAAAAGSFIIAAAAYIAkhQAAAAAGSFIIAAAAYIAkhQAAAAAGSFIIAAAAYIAkhQAA\nAAAGSFIIAAAAYIAkhQAAAAAGSFIIAAAAYIAkhQAAAAAGSFIIAAAAYIAkhQAAAAAGSFIIAAAAYIAk\nhQAAAAAGSFIIAAAAYIAkhQAAAAAGSFIIAAAAYIAkhQAAAAAGSFIIAAAAYIAkhQAAAAAGSFIIAAAA\nYIAkhQAAAAAGSFIIAAAAYIAkhQAAAAAGSFIIAAAAYIAkhQAAAAAGSFIIAAAAYIAkhQAAAAAGSFII\nAAAAYIAkhQAAAAAGSFIIAAAAYIAkhQAAAAAGSFIIAAAAYIAkhQAAAAAGSFIIAAAAYIAkhQAAAAAG\nSFIIAAAAYIAkhQAAAAAGSFIIAAAAYIAkhQAAAAAGSFIIAAAAYIAkhQAAAAAGSFIIAAAAYIAkhQAA\nAAAGSFIIAAAAYIAkhQAAAAAGSFIIAAAAYIAkhQAAAAAGSFIIAAAAYIAkhQAAAAAGSFIIAAAAYIAk\nhQAAAAAGSFIIAAAAYIAkhQAAAAAGaE1JoVLK3Uopny2l3FxKaUopt5RSvl1KeV7Xf1Yp5aaub2sp\n5cJSyvePHf/Qrm/1ZWsp5d5jcW8upVzb9d1USnlJKUUiCwAAAGCd5k6wlFIemORzSe6W5NokNye5\nPEmT5CVd2MeT/FKSByT5bJIjk7yjlFK6/g8luSDJV5Nc0Z3n4iQXNk3zye56TknyuCTXd9exS5Jf\nSPKaeccMAAAAwK2tZdbN27vjbk6yX5LdkhycZJ8kV3YxNyT55ST/keSUset6cPf1MUmOSnJCkoOS\n7J3k0CSHllIO72KekTYRdHB3HSXJ1UmeVkrZbw3jBgAAAKAzV1KolHJckkO6b/dIm6hJ1+6eNsGT\nJHfJSsJo3Me69pHdMU132dRddk9y9y5mlBwaJZpK2kRSSXL6POMGAAAA4NbmnSn06Bnj/j5tUihZ\nSRwlydETYsuq77d27T927cFjfU3X2lcIAAAAYB12nTP+pBnjfjHJnhN+vm/XjpaRTUruPCvJBzI5\nATVKIN2u74rPOuus3PWhj8vN2eVWP9/nrg/NPic/tDJkAAAAgB3Xt17ymIWeb96k0NS9fEopj0ub\nPFo9AyhJnpl2A+oDKqc4sWtPq8R8o6/jvPPOy+YLvp6tq65+1/0PlxQCAACADWrRCZMhmDcpVEvm\nJG0i6BnpX9715LRJoT0q5xgtFzuwEvP4rCwvu5Vjjz02X72yuc1MoT2OuWvldAAAALDzkhBhLeZN\nCo1vHF2S3JS2Qth1aRM9uyQ5onL8lq6tzTi6Yez8SXJL2kpne43F9C5jM1MIAACAHZkEDjuKeZNC\nq41m/IxmEG1Nsn8lfpRUulMl5piuHU312TW3HefhqThw792yyy63nin0Iw88Ln/sFw8AAAAgyeKr\neG1KfRbQqO/NlZjzu3b3SszV8wwKAAAAgFubd6bQzTPEfDbJsT19l3XtKZXjb+zam9KfGLqgNoAr\nN9+crbnlVj/76zO/lX/+1XfUDgMAAGAHY6kVLM+8SaGrZoh5d5K+39rRLKC3JXlQT8xnu7apXMd5\nM4wDAACAHZiED2xf691TaJLvqvTdpWtvX4m5Q9fuXYnp3VNI9TEAAIAdh8QP7LgWXZI+ST6Q5Ok9\nfR/r2jtXjh9tRn1lkkN6Yr7cd7DqYwAAANuWxA/snNZTkr5PrbLYaI+g+1Viruva89KfFHr9DOMA\nAABgCgkdGK5lLB87sdJ3j67dUokZbVJdKjH3SPKZvk4l6QEAAADqllF97KJK37e69htJDu2J+deu\nHW0C9O20y9b2Gov5+SSv67sS1ccAAIAhMdsHWItlVB87foa+rZWYA7t2tFTtyAkxfSXvAQAANhxJ\nH2AZlrF87N1JfrCn7/1d2zdLKEnu1rW3pH98V65hXAAAADsNiSBg2ZZRfeyelb7R7J+PpL8C2Xld\ne35WytOv9r6+K1CSHgAA2FlJBAHb0jKqj9WWdt27ax89w3V8O/1JoYv7DlaSHgAA2BlIAAHb26KX\nj21N8sYkpyerpuq0NnftgRP6RkaZm5MrMf81/9AAAACWR5IH2NksOim0Ke3G0CXJDUl27342cn3X\nXprkiJ5zjDaz3rdyPb+S5G/6OpWkBwAAAKhbRkn6J6dNBO05oe+Qrv29JC/rOf4/u3ZL+sd3WW0A\nStIDAACLYPYPsJEtoyT95krfdV1790rMF7v2xvSPr2+vIQAAgDWTBAKGZBkl6d+Q5Ht7+kYJnx+o\nHP+TSV6YNgG1T0/MtWsZGAAAwCSSQcAQLaMk/fdV+g7t2gvHvl7t413bVM7z8b4OJekBAIBJJH4A\nbm0ZJem/v9I3KknfNwMoSU7p2sMqMR/t61CSHgAASCSBAKZZRkn6K9NfOWxL197S058ke3VtbWxP\nTPLqvk7VxwAAAADqNk0Pmft8v5b+pV/v6drDK+c4sGsvqcR8a75hAQAAADBuGSXp352sWru1YpTw\nualy/DVdu8cMMRMpSQ8AADsXS70Atr1llKT/oa4dzRYaTxCN1nS9JcnP9hz/za7dr3IdF88wDgAA\nYAcnGQSw/SyjJP1JXTtpttAo0VOrYjbLbKT79HWoPgYAADsuSSCAHccyStIfV+kbLRs7rxIzWhp2\nRfrL1vfuSaT6GAAAbH+SPwA7vmWUpL97pe/Yrq1lZ0azib6Q5Ht7Ymp7EgEAANuAxA/Azm0Zy8eu\nmyGmtpbrqK49M/1JoStrJ1eSHgAAAKBuGdXHarOJRptPX5tk356Y0c8fWDnPX9QGoPoYAAAsl1lC\nADu/TXPGz1J97LBK38Fd+9FKzGhMH6zEfGaGcQAAAEsgIQSwMSxj+dhrk7ygp+/XuvabPf3JytKw\n76rEHJrkovmGBQAA1Ej2AAzLMqqP7VXpe1/Xbq7EfLhrH1KJeWqSX53UoSQ9AADMRzIIYJiWUX3s\n+yp9/5lk/yT3qcRs6dp9KjH37OtQkh4AAFZI+ADQZ9HLx7Ym+Vj6q4u9t2sPrJzjEWPn2qUnZs/5\nhwYAAMMhGQTANItOCm1KfYnZKFl0h0rMpV17Y/pnJjU9P0+iJD0AAADANMsoSX95pe9nuravHH2S\nHNO1e1Ribl8bgJL0AAAMgdlAAKzHvEmhWUrS36vS9+okJye5IsnePTGjPYVuSf9MoY/NMA4AANjp\nSfwAsCzLKElfO+doL6ErsjIjaLXdu/aG9Fcy++AaxgUAADsFiSAAtoVllKQ/uNI32uinVllstGzs\n+iQH9cRc0newkvQAAOyMJIIA2NaWUZL+7CTH9vRd27Wlpz9Z2UT6U0mO7onpm0GkJD0AADsNiSAA\ntqdllKR/RZIHZ3I5+TO6dlPlHKPE0T0qMU9J8rd9naqPAQAAANTVkjNrPd9xlfOOfn5Y5Rz7d+03\nKzGfmm9YAAAAAIxbRkn6H0z/8rAfSvKsJJ9Pct+emPO6tnffoCSX1QagJD0AADsCy8MA2JEtoyT9\n55Kc1tP38a7dr3L8xV27uRLzlRnGAQAA25xEEAA7i2WUpL+60ndE19aqjx3ftY+qxJyc5F2TOlQf\nAwBge5EQAmBnsoyS9LX9gkYzhS5IcvuemNHSsL0r5zm0r0P1MQAAtjXJIAB2RssoSX/vSt/pXXvn\nSsxoFlFtbKfMMA4AAFg4CSAANoplLB97Y/o3kf5Q174pyc/1xHy1a29I/2yhg2oDUJIeAAAAoG4Z\n1cdqy75u6tpvV2L27Nra2K6tDUD1MQAAFsGsIAA2smVUH7u80ndM1z6xEjNaWralEnP+DOMAAIA1\nkQwCYAg2LeGcfRtIJyszfK6sxIzWfdWqmJ0714gAAGBGEkIADMUyqo+dWOl7VdfWlqFd0LW1svUH\n9nUoSQ8AwFpJCAEwJMuoPlYrSf9HSU5KcrdKzGgzoFpS6Lv6OpSkBwBgGskfAFh89bGtST6b5Ht6\n+j/WtbUZR/fp2vOSnNATc8P8QwMAYKgkgQDgthadFNqU5OGV/gd17bnpX2Z2Y9fe0tOfTKk+piQ9\nAAAAQN0yStJfVunbt2tfneRlU66jqZznitoAlKQHACAxQwgAapZRkv6MJA/u6ftK136tcvxXu/aY\nSswlM4wDAICBkgwCgOmWUZL+y5W+b3Vt315BSfKiri2VmD3mGRAAAMMhIQQAs1lGSfq9Z7i+R1Vi\njuja2vKx/fs6lKQHABgeiSAAmN8yStL/a6VvVEr+lErMU5P8deqzmI7s61CSHgBg45L8AYDFWUZJ\n+ldU+kfTd2qziR7QtRcn2a8nprp8TPUxAAAAgLpF7ym0KfUlZgd17eYZzvWpSt8NM48IAAAAgNtY\nRkn6TyV5dE/fqPrYlUkO74m5rmsfVLmOS2sDUJIeAGBjsFwMAJZnGSXpt1b6runac5Kc2BPzra49\ntHKeA2cYBwAAOxEJIADYtha9p1CSPLbSd/sZjh/tF3RJkmN6Ym7p+bnqYwAAOzjJHwDYMSyjJP2e\nlb5ZNpouq9pJLurrUH0MAGDHJSEEADuOZZSkvyjJXXr6Rkml63r6k+TLXVtbItZXlQwAgB2QZBAA\n7HiWsXzsk0n6puSc0bW12URHdu1elZiTagNQkh4AAACgbhnVx+5V6fuhJE9LcsdKzGFd26R/CVl1\nppDqYwAA24cZQQCw81hG9bGzk5zW03dx19YqlB3dtVuSbMrk5NAs4wAAYBuQCAKAndMylo9dUekb\nTd+5sRIz6rsl7R5Gk2YL7TLhZwAAbEOSQQCwc1tG9bHafj/ndG1tptAocXRN+vcV2tR3sJL0AADL\nIxEEABvHMqqP3a/S95Cu3b0SM5ppdHmSw3timr6DlaQHAAAAmG7Ry8e2Jjk/KxXEVhvtBTRLcunS\nSt9n5hkUAABrY2YQAGxci04KbUrypiT37ul/b9e+J8nTe2Ju6NpjK9dzYW0QStIDAAAA1C2jJP2p\nlb6+qmTjDuzaIyoxN1T6lKQHAFgjM4MAYDiWUZJ+/0rff3RtLTk0SvjsUYl5apIXzTAWAABmIBkE\nAMOzjJL0J1T6Hta1e1ZiRkmlW9K/IfX1fQerPgYAMB8JIQAYpmWUpH9Xkmf39F3btb0l5ZNcMhZ7\ncE/MLT0/V30MAGAGEkEAwDJK0p9V6RvtF1SbKTQqQ39N+pNCn55hHAAAdCSBAIDVllGSvpYU+nbX\nbk7/3kPnjbV36Il5X20Qqo8BAAAA1C2jJP1llf7Pdm1tGdrRXXtNJeaC2iBUHwMAhs7MIABgmmWU\npP+9St+ZXXte+jekHiWMjqmc57FJ/n2GsQAADIZEEAAwj2WUpK/FPCnJK7Oyb9AkozEdW4m5/Qzj\nAAAYBMkgAGAtllGS/j1JntzTd8dSymlJ9qgcP+rbUon5ZF+HkvQAwJBICAEAa7XIkvRNkjLlnBen\nnSn00SR99eE/0rX7Vc5zdl+HkvQAwFBICAEA67HIkvSjLMzmSsw5SZ6Wlb2FJhntW7R7JealSf6x\n0g8AsCFJBAEAi7KMjaZr/6kc3TTN1aWUvSsxo3VfN6V/mdkuPT9PoiQ9AAAAwDTzJoUumSHmG5W+\nC7u2tqfQvbr2m0nu0hNzdW0AStIDABuFmUEAwLLMmxS6bIaYyyt9oyVhFyc5uifmmq79SvqTQufP\nMA4AgJ2OJBAAsK3MmxQ6ZIaYvkROspIw+qskf9gTc07Xnlw5z3/NMA4AgJ2GZBAAsK3NmxQ6bIaY\n/0jyzJ6+j5dSDkjykMrxH+raWgLqs30dStIDADsyyR8AYEexyOpjo5L0e1ViTkhbeaxW2n6UMLoi\nycE9MV/rO1hJegBgRyUhBADsSOZNCtU03aVWGexHkvxkkhcmOaYnZlTh7MjKeZ6Z5D19naqPAQAA\nANRtWvC5NiU5ohJzUdM0Z6SdBdTnpq79TCXmnEofAAAAAFPMO1Po5ukh+YlK33Fde2klpunaEyox\ntQpnStIDADsMS8YAgB3VvDOFrpoh5sZK32ijnztWYkbLymobTdscCAAAAGAdFrmn0MgNlb7RTKMt\nlZiDunZzkv16Yq7vO1j1MQBgR2GWEACwI5s3KVSrGjZSW9o1Sgr1bTKdrFQ4ayoxN/V1qD4GAGwv\nkkAAwM5k3uVjtZL0I++t9H1whuMv7tpLKjGXzXAeAAAAAHosevnY1iSnV/rv37X7VGJGyaDNlZhr\naoNQkh4AAACgbtFJoU3JqrJft3Zd19Y2oz64a4+sxOxdG4TqYwDAtmTZGACwM1pGSfpXJzmtp+/3\nuvYtSZ7bE/Plrr04yWE9MbX9hgAAtgnJIABgZzZvUmiWkvR3rvQ9JMlfTLneE7v22ErMcTOMAwBg\nKSSDAICNYBkl6c+u9J3QtQ+vxIxmAfWVo0+Su/V1KEkPACyLZBAAsJEsoyT9vSt9F3TttZWYUd/W\n9FdHe3vfwUrSAwDLICEEAGw0yyhJf1Olb6+u3b8Sc2HX1sZ21AzjAABYCAkhAGAjWsbysU9X+kaV\nxfo2kE6S75nwsya51dSfWkl7JekBAAAAplhv9bFRsqbpLptST/icVEo5LckNlZhJewmVVd9/V22Q\nStIDAItilhAAsFHNu3xsdfWxMtaOznWXKce/MsnVM1zXFZW+s2Y4HgAAAIAe8yaFZvG2St/mJM9P\nPeEz2pPoPysxb513UAAA8zJLCADYyOZdPrb3DDG/POX6XpqVsvOTjJaoHVOJeWNfh5L0AMAiSAgB\nABvdvEmhzTPE1PYU2i3JqUm+UIkZbSJdy+LcP8m7JnUoSQ8AAAAw3bxJoVq5+STZmuTPk9ynp/9z\nTdNcXUqpXe9oSVutwtgrk9ypr1P1MQAAAIC6Re8pNO18n+na2kbTF3ftlkrM5TOPCAAAAIDbmHem\n0Cxq1cfOK6UcMOV6R0vUbkqyV0/M0bUBKEkPAKyVvYQAgKFYRvWxGyp9P5fkzCSfr8S8v2tvrsRc\nOu+gAACmkRACAIZk3plCu88Qc3yl74gkv5B2NtHje2Ku69rS059U9htSfQwAmJdkEAAwRPMmhQ6o\n9DVpEzkHVWIOTfL7SWrruPbr2gvHvl7tDX0Hqz4GAMxDQggAGKp5l4/ttur7pmu3ZmVj6No5d0ub\nOKpN29mza4+pxJxQ6QMAmImEEAAwZOvdaHo0HWdTd9ma5OxK/LlJ7pHkq5WYh3TtjelfJnZdz8+T\nKEkPAAAAMM28SaHa5s9Jmxg6udJ/UNM0V5dS+qqKJSvLz76V5OCemE/UBqH6GAAwjVlCAMDQzbt8\n7JIZYq6t9F3VtW+sxFzZtYdVYvaYYRwAABNJCAEAzJ8UumyGmKMqfYd2ba2K2Ve6dpdKzLzjBgBI\nIiEEADAy7/KxQ2aI+Zck393Td1bXHlE5/ktdu++sgxqnJD0AMIlkEADArc2bFKot6Rp5W5L/1dN3\nXinlgCSvT/LonpjjZxjbmX0dStIDAKtJCAEA3Na8SaHVJelX25rk7pX+o9MmdD5UiRmVtq/tG/R/\nkjx8ylgAgIGTDAIA6LfekvRN2rL0W7vLrkk+OPbz1e6W5LeTPL9yzhO79ub07yt0x9qglKQHAAAA\nqFtvSfpR4mfT2Nc/nskJoSR5R5KfSluhrG9/oou7tqmMo1oFTUl6ACAxUwgAoGbeKl5XVfpGiaDT\nKzF3SnL/JBdWYg7q2q0zXBcAwEQSQgAAdfMmhW6aIeb3Kn27Jjk19aTOaAbRNZWY2p5EAAAAAEyx\n3j2FJjmv0ndtklemvjTs2127fyXm+L4OJekBYNjMEAIAmM28SaHdV32/Ne1soy1pZ/9sSlLLvpyQ\n5OlJfr0S84murc0mOrSvQ0l6AAAAgOnmTQrtPfZ1k5XlZ7t031+X5LDK8VcleWnq+wX9U9fWlrbV\nZhGpPgYAAAAwxbx7Cm0e+3r1TJ6SZJ8kT6gcf2OSRya5XSXmr7r2hkpMrQ8AAACAKeadKVTb/Hmk\nVlnsyCRnpC073zfb5/wZrqO2J5GS9AAwMPYRAgCY37wzhS6dIeaKSt+BSZ6X5AOVmGO7drdKzF4z\njAMAGAAJIQCAtZl3ptAe67y+G5N8JMlPz3AdtY2mz+zrUH0MAIZBMggAYH3mTQrdeYaY2vKxG9Im\ndGoxl3XtLZWYm/s6VB8DAAAAmG7e5WN7r/q+GWtHFcU+Vjn+6iS/keTgSswlPdc17vaVPgBggzNL\nCABg/eadKTSuycoSr1G7Oe2+QX02JXlR6nsC7TnDdZ9Q61SSHgAAAKBuPUmhknaPoF2SXJd2L6C9\ns7In0E1pN4seX8d1RJI/SfLDSY7vOe8sSaHDa52qjwHAxmSGEADA4sy7fGz1Xj57pE0sHZCVZM6+\nXbt7brtZ9OYkP5V6aftDuvbfKzEfnzZQAAAAAPrNO1Poqhli/rXS940kpyX5cCXmhq79dBc7ycUz\njAMA2ADMDgIAWI55k0I3zRDzgErfe5qmubqUUlv+dVDXHleJuaCvQ0l6ANg4JIQAAJZnPXsK9Tm1\n0jcqN//1JIf2xHyua+9bOc8X+jqUpAeAnZ9kEADA8s2bFNp9hpgbK32jWUTnVWJGexLVStLfYYZx\nAAA7EYkgAIBta96k0AGVvlGJ+i9VYk4rpZyW5O6VmNGG1VsrMedU+pSkBwAAAJhivcvHRomgrd1l\n1yQfqMRvSfLaZNWGP7d2+67dqxLz/CR/29epJD0A7DzMEAIA2D7mLUm/uvrYaOOeTWkTQluTHFk5\n/sokR6S+fGyUMLquElOdKQQA7BwkhAAAtp95k0LTqo9tSlt2vs/mJD+a5E6VmC1de1Alpm+TagBg\nJyEhBACwfc27fKy2ifTIb1b63t80zVtKKa+txIzG9OUk9+yJ+UDfwUrSA8COT0IIAGD7mzcpdO0M\nMbXE0eau/UiSR/bEjDYDurlynj37OpSkB4Adm4QQAMCOYd6k0CFT+rcmOarS/xNJfi3Jp9OfFBpN\n8aktEatO+1F9DAAAAKBu3j2FDpvhfF+u9O9eSjkgyamVmNEMoSMqMXeYMg4AAAAAKtZbkn7cqDz9\n8ZWYw5N8LslZlZiLu3a3Ssz5tYEoSQ8AOw7LxQAAdkzzJoVWl6Qf13SXv0/yY5W4o5K8rdI/Sgpt\nSVbtFr1ikcksAGAJJIMAAHZsi0yujJaiXV6J2ZzkqanvTbRf15ZKzIl9HaqPAQAAAEw3b1Jo7xli\nvqfS92ddSfq/qsR8uGuvS3JgT8x1fQerPgYA259ZQgAAO755N5rePD0k96/0nd61D6zE3KNrr6nE\nfGiGcQAAAADQY5HLx7Z27UeSPK4nZq9SymlJvpb+JWCjCmf7dO1oA+tx764NREl6AAAAgLp5k0IH\nVPpKdzm0EvOJJK9McmUlZlQ2bJQUmrS30NOTvLHvBKqPAcD2Y+kYAMDOYZEzhUbJm4dXYk5O8sgk\nH6vE7N61TSXm6jnGBQBsA5JBAAA7l3n3FLpkhpjrK323S3JGsmoaz62NElVbKjFnzDAOAGAbkRAC\nANj5zDtT6LIZYv4j/ZtNN0mel+RhSV7QE/ORrt2lpz9JnpDkzyd1KEkPANuWhBAAwM5p3qTQITPE\nfLnS942mac4opTy3ErNf156b5ISemN4ZS0rSA8C2IyEEALDzmnf52GHTQ3K7St/lXVtbPnZp1x5V\nibnfDOMAAJZIQggAYOc270yh3Sp9o9Lxd67E3KeU8tjUN5EeVR27Osm+PTFfqByvJD0AAADAFPMm\nhW6u9DXd5c1JntoTc0uSNyV5XeU8o3L1X0lydE/MWZXjlaQHgCUzSwgAYOc37/Kxq6aca1OSu1di\ndk3ylCRHVmIePBbbZ5YqaAAAAAD0mHem0E0zxHyr0ndB0zRvKaU8rBIzWqJ2UiXmgBnGAQAsmBlC\nAAAbx7xJoVnsU+nb2rVfrcR8sGtr+w711pdXkh4AFk8yCABg45k3KbT7DDEnV/rO6Nr7V2JGSaH9\nKzF793UoSQ8AAAAw3bxJoWnLtrYm+VCS5/T0j8rM37dyjgcn+YskWyoxh9UGofoYAAAAQN28G03X\nStKPzndspf9+pZQDkhxYiXlU126uxFw8ZRwAAAAAVCyyJP3IqZW+A5KcOeX4g7p230pMbb8hJekB\nYIHsJwQAsDEtsiT9SG1p2AFJnpfkikpMs6oFALYTCSEAgI1rGdXHqpqmOaOUcnUl5CNde076N62+\nsO9g1ccAAAAAplv0RtNJ8okkd+rpG80QunPl+NEMoUMqMf/V16H6GAAAAMB0i95oOqmXrR+Vkt+r\nEvOgrv1sJeYDM4wDAFgHS8cA4P+3d+/Rll11nei/s0IqSVUqlScJIYkhIiowDCBCAEGM3URs8e3A\n2LaP7it6oQfcRloZ3NioTfugu7Ft0bbtBqH7tjRwbRtf3bGRhxdiUFSIARKeMU/yTipJpZJKnXX/\nWGt17WzOmnuvU+dU1Tnr8xnjjHn2mb+19+SPPRK+mXP+YGtb7+NjK2mPfQ25qRv/W5JLB2r6559S\neZ/Ta4vQkh4AAACgbr1DoW0ZPjqWJI/txmcveI+kflTtq5P80dCk7mMAcGjsEgIA2PrGHh9bpiX9\nhytzd3TjOZWalW6sHTH75iXWAQCsgUAIAGAaNqIlfa2z2CeX+NzHdeODlZpPLbEOAGAkgRAAwHRs\nREv6Wytz53fjFUleMFBzXTd+MMnQv5n+8dAHaEkPAAAAsNhGtKS/uTJ3fzf+doZDodu68b9nOBTa\nOfQBWtIDwNrYJQQAMC0b0ZL+uMpcf/zsOUmagZrru/GUyvuctsQ6AAAAABiwnsfHmiQlyTMrNU8r\npV/Hj78AACAASURBVFyc5Bu72tVc1I0rA/PJwSNmq9KSHgAAAKBubCi0TPexEytztyR5c5K3Jfln\nAzUf7cbXVt7nT2oL0JIeAMZxdAwAYHrWs/tYv/PnkUrNrrQ7gU6u1FzVjbWaP6jMAQAAALDA2FDo\n4SVqPlmZO6Npmj2pXBSd5B3dOHS8LAueBwBGsEsIAGCaNqIl/RmVuY90Y+0Y2j9K8rOph0JfNjSh\nJT0ALEcYBAAwbWNDoe1L1NR28fQt7b+1UvPytKHQ/gx3Mrt66GEt6QFgMYEQAABjQ6HdC+ZXUt8F\ntK8bH1yiphZAHV9bhO5jAAAAAHVj7xQ6don3q10QvauUsjvJNZWaK7vxoUrNMZU5AAAAABbYiJb0\n31WZOzPJFUk+U6l5ZzfeleTsgZrrawvQkh4A6hwfAwDgUFvSNzPjSvd7LTg6O8nbk1xYqfnZbtxV\nqanNAQAVAiEAAJJD7z5WZsb+9xuTPGugfn+SH05ybZLzB2pO6sZPJnn2QM21QwvSfQwAhgmEAADo\nrfdF00m7E2joCNmtSS5K8sHK8/tmaocMHh/TfQwAVicQAgBg1tjjY8u4rjbXNM2eJKdUavqW9l9X\nqRnaQQQArEIgBADAvLE7hebvFJq3kuR7K/N9m/laF7O7uvH2JI8bqHlPbRFa0gMAAADUHeqdQvO2\npX6J9FndeFWGO4v1wdMTK+/zfUneNTSp+xgAHGSXEAAAqxkbCu1YouaTSV4yMPfebjxQef6vuvHh\nyufVOpwBABEGAQBQN/ZOob1L1NSCo79XSnlJkqdWavpLqrdXar6wxDoAAAAAGLDex8dWktxdmS9J\n3p3kA0m+bKDms91YC4VOHZrQkh4A7BICAGCxQ21J36QNepruZ9uC9zw2yaVJvjrJJQM1H1piHYOh\nkJb0AAAAAIsd6k6hMjP2v9fu+7m9aZrfLaW8qlJzSZKfXvC5K0uuDwAmxQ4hAACWtd4t6ZPkxCXm\nPphkaNvOtUt8xgm1SS3pAQAAAOrGhkIPL1GzZ4maWjpz/MxnDa3vr2tvriU9AFNklxAAAGOM7T62\njFoo9J5uPKtS87xurK3tZaNWBABbnEAIAICxxoZCtY5gvdptzs8tpexOsrNS04dKV1dqPr3EOgAA\nAAAYcKjdx1bzucrcviRXJHOtwVb350meOTA3eA5MS3oApsYuIQAA1mJsKHTs3Ot9aXcbPZjkuLT3\nAX1V5flnJLksyT/JcMB02ty4mg8PTWhJDwAAALDYobSkb3LwUujt3esH0nYPG/pPlh9N8sNJ7srw\nvUL9Fp/bK5/93CQfGprUfQwAAACg7lAump4/AlbS3hW00r1uup9ZtyW5KMlHKu97QzeeU6k5ack1\nAgAAALCKsTuF9i5R04c5q90b9K1p7wm6qvL8B7uxdgnQNbUFaEkPwBS4SwgAgEMxdqfQ5ytzzRI1\njyR5a5J7KjVf2Y3nV2q+qzIHAFueQAgAgEM1dqfQSmWu3xn0iUrNFUnOTvKjlZraRdW9JwxN6D4G\nAAAAsNjYUOi8JWpOr8y9LO29Qtcv8fwjaTuareaUoYd1HwNgq7NLCACA9TD2+NgydwrV/k31dWl3\nFN2/xPvcW5lb7b4iAAAAAJY0dqfQnZW5/mjZ7krNDyW5uHufxw/UPNiNteCodkRNS3oAAACABcaG\nQifOvX4gyfYk93XvtSvJryZ59sDzK0mOT7J/ic/650n+88Dcz9Qe1H0MgK3K0TEAANbL2ONj83f8\n7ExybJJT0wZCpfvbkDvTBkL3VWr6HUfPrdQ8rb5MANh6BEIAAKynsaFQTUkb6JxVqbkjyWOTPLzE\nmr6zUvNj45YGAAAAwKyxx8ceqsw1aQOd8ys1T0pyS9qdRUP6o2WDHcaSubNhM7SkB2ArsksIAID1\nNjYUumPudZN2h1Az8/tpc3OztqVtS/+fKp/RpznXJ/mKgZqPDT2sJT0AW41ACACAjXCox8fKzLgt\n7fGxPXNzs77YNM3lSU6qvOeubvxCpeamMYsEAAAA4NHG7hQaaiPf25bkmsr8taWU3WmPoR2/YE1D\n8wtpSQ8AAABQNzYUOnmJms9U5p6U5Mq09wrtHqhpurG2m+i62gK0pAdgq3B0DACAjTL2+Njeylwf\n5nxzpebkJDuS3Fip6TuTPaFS8/2VOQAAAAAWWM+W9L2LKnMnpA2Ptldq+susa53O7hu7KAAAAAAO\nGnt8bOjIV3LwYukPJxnq/76S5MeS/J+V93lXNx6o1OwamtCSHoCtwtExAAA20thQ6Nglaq6rzK00\nTXN5KeUXKjX9LqBaKPRHQxNa0gOw2QmDAAA4HMaGQousLJjv7x06pVLzLUn+eVZvad+7oPYhuo8B\nAAAA1B3qnULNzLjSvd8HavWllIuTnFWpeWo3PrZSc/GyCwQAAADgS43dKbR/7nWZG5N60PRwkrem\nvUT6+IGa47rxwQwfV7u58hla0gOwqTk+BgDA4TA2FLq3MtcHQy+q1FyVdgfQ25O8cqDmtm6s3Sl0\nT2UOADYlYRAAAIfT2FDo4SVqLqzMXZDkyUm+q1LzYDceV6kZPFqm+xgAAADAYmNDoYeWqLkmyUsG\n5v60aZo9pZQfqTx/RTfenWTHQM1fDD2s+xgAAADAYmMvmr5/7nXfbexA8r8v8bktw767lPLqJHsr\nNed244mVmqdU5gBg03F0DACAw23sTqHTZn5vcjBUOqZ7/UDqu4k+lOQXklyW5JsHav6gG2vHx1Yq\nc1rSAwAAACwwNhQ6eeb3MjdXkuxMcm3l+Zd3dT9TqfmnSd6Ueoeyc2qL1H0MgM3ELiEAAI6EsaHQ\nrUvU3FeZ+5kkT0tyZqWmD56G7hNKDl5GDQCbmkAIAIAjZeydQp+Ye91040oO3in0pMrz357klCQf\nrNT0R8Nqnc72V+YAAAAAWGDsTqH5HT79EbJtM78/ofL8XWkvpb63UnN3N26v1AxeVK0lPQAAAMBi\nY0OhWtev2YBoNU2Slyb5mxxsO7+avuvY/J1Fs84emtCSHoDNwtExAACOpLHHx46tzK10P08cmC9J\nLk/y4iTnV96n7zp2VaXmpypzAHDUEwgBAHCkjd0pNHvs60DyqDNaK2mPdZ1feX5HknckeV+Sbxqo\nub4bH1t5nyenDZhWpSU9AAAAQN3YUGj28udj0h4JK924LclJSfZVni9Jfq6rGwqF+vuC7shw6/lv\nSPLLQx+iJT0ARzO7hAAAOBqMPT720NzrMjP273V9hq00TfP61FvK90fUancK3VqZA4CjlkAIAICj\nxdhQ6P4lamp3Ae0tpexO/YhZf0TtrGUXBQAAAMA4Y4+PnbZEzdWVubvSdh6r7SZ6fTceV6k5aWhC\nS3oAjlZ2CQEAcDQZGwqdMfd69k6h/l6hlVXmeyXJq5O8rfIZL0zy3rSXUg85b2hCS3oAjkYCIQAA\njjZjQ6H5lvSzdwqVtIFQs8p877NJrkxlp0+SVya5LMltGb5o+q21Reo+BgAAAFA39k6hmn6n0A9W\nai5Ie3ysZns3vq5Ss8wxNgAAAAAGjN0ptL8y1+8KqgU2j0vybUneWanpt/j8s0rNNyR549CklvQA\nHE0cHQMA4Gg0dqfQvYtLqj7XNM3lefQRs3l7uvH8Ss167nACgA0jEAIA4Gg1dqfQMgYvgU5ybjeu\nVGqO78Y1BT+6jwFwtBAIAQBwNBsbCu1eomZvZa6/qPpv0h4BW80Xu/HeJKcM1Nw39AG6jwEAAAAs\nNnY3znz3sdX8t8rcjd345EpNf9H0eyo1v7HEOgDgiLFLCACAo91GHB+7oTK3rxtPrNSc3I3vS/LD\nAzXX1hagJT0AAABA3Xp2H+tdv0TNI5W5/r6hPhx6JF+6zjOT3DT0BrqPAXCk2SkEAMDRbiO6j+2r\nzN24RE0fPH13N64WXNWeBwAAAGCBjWjt/sLKXN+K/hOVmv5o2PmVmgtHrAcADiu7hAAA2Aw2ovvY\nSZW5Z5RSLk5yW6XmTUt81lcMTWhJDwAAALDYenYf63cBvatScyDJm5PsqNR8RzfWWtv/naGJviX9\nQzd/+tE/N32q8nYAsD7sEgIAYLNYz+NjTdpLop9dqTkuyU8muatS85RuPKVSU7uoGgAAAIAFDrX7\nWJOkpA2DVrr3e3rl+b1pdwo9WKk5oRu3V2rOri1SS3oAAACAurGh0O1zr0s3bsvBXUfPqTx/XNpd\nQidUavo13Z3k9IGa6yrPa0kPwBHj+BgAAJvF2FDopiVqPp7kawfmjk/ymiRvqzx/Xzd+NsOh0ANL\nrAMADhthEAAAm83YO4Vqx776i6bLgpo3p340rO8sdmKl5vjKHAAAAAALjN0pVDv21XtCZW5nkj1J\nbkmya6BmXzcOzSfJNUMTWtIDcLjZJQQAwGY0NhQaOs6VtLuAmiSfTvLCgZqr0nYXu7PyPv3RsNpO\noWcOTfQt6VfmNiw95qTHZueTv6HylgAwnkAIAIDNamwotIw/TPKygbn9SX4kya9Unn9cNx5Tqake\nH9N9DAAAAKBu7J1Cd1TmSvd+T63UfCDJTye5oVLTHx/bWan58socAAAAAAuM3SlUu2i69/WVuR9I\nu1uodtF0f2/RXUnOHKj5fG0BWtIDcLg4PgYAwGY1dqdQ7aLp/hKf91dqPpnknyTZXalZ6cba8bH9\nlTkAOCwEQgAAbGZjdwo9foma0ypzxyT5+dQDn761/cmVmh1DE7qPAQAAACw2NhQ6Y+51k3aH0Er3\n85gk70nyUwPPf13aY2EPVz6jn9uX4Q5kHx56WPcxAA4Hu4QAANjsxh4fO3bm974Ffe9A97On8vwJ\nSY5L8oVKzYFurN07dFJlDgAAAIAFNqIl/dOXqPlIkmcPzN3VjbW1Pb/25lrSAwAAANSNDYVmL3gu\nc3PHdD/fVHn+obTHwz5eqbm2Gx/J8G6h2m4k3ccA2FCOjgEAsBWMPT52+9zrPhjaloMB09dUnj82\nyd4kL6nU3N2ND1ZqPlqZAwAAAGCBsaHQTUvU3FeZezDJs5JcWKl56hKf8cASNQCw7uwSAgBgqxh7\nfKy2e6f3uSRDbb62N02zp5Qy1FUsSc7txuMqNV8/NKElPQAbRSAEAMBWMjYUOmGJmtmOZCt59G6k\n67ux1pL+2MpcbzBU0pIeAAAAYLGxodDjK3Mr3XjVzN/mj6edVUp5Sb70kupZfUv6Yyo1tZ1GALDu\n7BICAGCrGRsKnTHze9P9bEsbCO3v3q92Tqsk+Z0cbDu/mh3deGuScwZqPlZbpJb0AAAAAHVjQ6FZ\nJY/uPtYf+6qd0Tox7U6gplKzrxt3VGq+WFuYlvQArBc7hAAA2KoOtSX9rNK9369Uar6Y5ObUj4b1\nQVPtiNgzK3MAAAAALLCeLen7MOf0Ss29SV6W5K8rNXu6cX+lZqUyBwAAAMACh3J8bEh1n33TNJeX\nUp6f5EUDJfd24/1JdqY9ajZ/MfXgnURa0gOwXhwdAwBgK1vP7mO9fZW5D3Tj8ys1e+Zer9apbLCl\nvZb0AKwHgRAAAFvdoXQfW81KDraUX823lFJ2Jzm7UvNV3XhvkjMHah6sLUL3MQAAAIC6sXcKHVuZ\n69vTf65Ssy/JlUmuqdTc3Y3zO4ZmPVKZAwAAAGCBsTuFapc/9y6ozD0xyQ2pHx/r29WfV6m5ubYA\nLekBWCvHxgAAmIqxO4Xurcz1l/h8plKzP8mPLfiM7d14WqWmqcwBAAAAsMBGdB97RmXumK772B1J\ndi9Y0zED80ny0iT/12oTuo8BAAAALDY2FJoPclbS7jY6kHan0LYkH0py0cDz+0opFyf5X0m+fKDm\nzm58ZA3r030MgDVzdAwAgCk51Ium++f7bTkrSU6uPH9ckrcmub1Ss6MbazW1DmcAAAAALLARx8fu\nX/B521LvYvZH3bivUnN9bQFa0gMAAADUjQ2F9lbmSvfzUKXmke49fjHJawdq/qYbd1be56zKnO5j\nAKyJ42MAAEzJ2FDok3Ov5+8UKjl4J9DQ5/2nJJdWap7ejR9O8p0DNR9euFIAWJIwCACAKRobCn12\n7vVqdwo9vvL8nUlen3qo0+80ekqlptaZDACWJhACAGCqxoZCZy+Y35bk/Mr8VUl+MMlfVmouTfKq\nJKdVas4YmtCSHoBlCYQAAJiysaHQY5eoubUyty/tRdQ3JjlzoOa+bqztBhp6Vkt6AJYiEAIAYOrG\nhkL3zfzeJI9KXpq0l0g3leefl+TK1FvK7+/GlUrNeZU5AAAAABYYGwodN/N7ycFgaKX72ZHk7srz\n27uaazJ8Z1D/GTclOXWg5tO1RWpJDwAAAFA3NhRatEOnpHK0K20odFyS/yfJiwZq+surjxuYT5IP\n1RahJT0ANY6OAQDA+FDokbnX/fGxbTO/f03l+dK9x0srNTu78f5KzVWVOQAYJBACAIDWtsUlS+uP\nkf2bSs3eJKcnOadS0wdPtXZh+8YtDQAAAIBZY3cK7Zh7/VDaLmEPpD3udXzqu3h2JPmtJF9Zqbmr\nG2vHx74jyX9dbUJLegCG2CUEAAAHjQ2F9s697oOb3TnYdew1leevS/Lc1Hf69O9TKjVDl1RrSQ8A\nAACwhLGhUE1/fOyGSs0NSb4tyRUL3idp7xTataBmVbqPAQAAANSNvVNo/vjYau9Xuy9oZ9M0e9Lu\nLBpyejfeVam5b8E6AAAAAKgYu1PoniVqaqHQ2aWU3Uk+Van7nW48ofI+f1tbgJb0AMxylxAAAHyp\nsTuF7lyipnY07Opu/rOVmlu6cX+l5suWWAcACIQAAGDA2J1Cpy1R864klw3MPTnJ/5HklyrPvyLJ\nzyXZWal5cGhC9zEAEmEQAAAsMjYUOmOJmu2VuZ9NcmWStyT5twM1/64b70xy8kDNx4Y+QPcxAAAA\ngMXGHh87tjK30v38eKXmtUk+nuRbKjVnduONlZorK3MATJxdQgAAsNihtKRvup9tacOg/d37Pany\nzAVJbkvynErNi7vxaZWal6c9prYqLekBAAAA6saGQrOXP5fuJ2mDoe3d699K8oKB5x9I28HsvMpn\nPDL3upn5nKGaR9F9DGC67BICAIDljD0+dntlrg9ubqnUPCbJs1LvLNZfIr137n1n3VV5HoCJEggB\nAMDyxoZCNy1Rc1Fl7m+bptmTdrfQkP7c10ql5lNLrAOACREIAQDAOIdyp9CQx1fmPtmNx1RqzurG\nEys1Zw9NaEkPMD0CIQAAGG9sKFQLfHonVObunxtXc6Abj6/UPH1oQkt6AAAAgMXGhkJnVOb6416n\nV2ouLaW8e8H77OzGP0/y/IGan6w8D8AE2B0EAACHZmwodOwSNbV7hx5M8v8mebhS0889s1Lz40ne\nNzSpJT0AAABA3aG0pJ/Xt6hvKjUnJLk5ye8necVAzZtn3m/IzsqclvQAW5xdQgAAcOg2oiV9rbPY\nXyR5WZJ7KzWf6cZaYLWvMgcAAADAAmNDoTuXqKn959sLmqa5PMnzKjXP7cZah7Ja23sAtjC7hAAA\nYH2MPT522hI1/znJzw/M/WY3nld5/gXduC/tcbMmX3qU7Oahh7WkBwAAAFhsPbuP9Wrt5p+0xPt8\n2cz7nJDV7xa6dehhLekBti67hAAAYP2sd/exlQXv+YxSyu7Uj6319w2dWKnZVVuE7mMAAAAAdWND\noXn90a6VHAyEHqjUn5/k46mHS6d04560O4VW8/naonQfA9h67BICAID1Nfai6fmW9P0ZrW05eDH0\n4NGumWcerMz3cydValYWfAYAAAAAFWNDoVor+T4gOrlSc2eSV6S+U+hAN9Z2MZ1fmQNgi7FLCAAA\n1t/Y42MPL1FzdmVuJckbu/cZOhrWHz87kOHwaPCiat3HAAAAABY71DuFVvPUBZ93UZKrk+weqNnb\njY8MzCfJ3UMTuo8BbC12CQEAwMYYe3xsGX9Tmft00zR70l4iPeS+bqzdG/Tno1cFwKYjEAIAgI2z\nETuFHleZ64+D7ajUPLEbS6Wmdm+RlvQAAAAAC2xEKPTxytz/KKXsTvI7SV4zUPO+bqzdX/TltQVo\nSQ+w+dklBAAAG2sjjo/VbnQ+N8kVSW6r1PSBz9BF1EnyhLGLAgAAAOCgsaHQ9rnXzczY3wH0+crz\nlyZ5Z5KXVGqOmxtXc09lDoBNzi4hAADYeGOPj813DCszY0kbDF1bef6hJK9Lsq9S89i5917NnUMT\nWtIDbG4CIQAAODzGhkLHzr1u0oY3TfezLcn5ledL2t1C/7FS86FuPJDhnUynDT2sJT0AAADAYmND\nof1zr1fbKXR+7fmmaX63lPKOSs3zllhb7TN0HwMAAABYYOydQvfOvZ6/U2hbkgsqz+8qpVyc5IFK\nTa1dfe+OJWoAAAAAGDB2p9B8m/gyNybJg5Xntyd5a5Lrkpw6UHNglfccqlmVlvQAm4+7hAAA4PBa\nz5b0fYizUqm5Ne0l05+p1ByYG1ezc8S6ADjKCYQAAODwG7tTaBnPrcydluRZSb4tyUsHav57N96S\n5JyBmvuGPkD3MQAAAIDFxoZCD1Xm+k5kf5rkqQM1+9N2F3tL5X1u7sbPZTgUunzoYd3HADYPO4QA\nAODIGRsK3T/3ug+CVrqfxyT5VDfXXzw9656u/uTKZ3x9Nz6+UvP7yywWgKOTMAgAAI68saHQaXOv\n++04ffizkoMdybblYGjUuz/Ja5L8RuUz+uNntXuDLkzyvqFJLekBAAAA6saGQrUdPqX72TX3t1m7\nkvyrJFdneCdQ326+1sXsRUl+eWhS9zGAo5ddQgAAcHQYGwrds0TNkypzp6TdTXRBpeaKbhy8TDpf\numMJgE1AIAQAAEePsS3pb6rMNWkDnxsX1JyZehjVB0a1lvQb0TUNgA0kEAIAgKPLeoYrfcC0vVLz\niSS/kOTFSX50oGZvN16b5BkDNXcM/F1LeoCjkEAIAACOPmNDodOXqHl+Ze7UtBdEX1ip+Xw3nlip\n0ZIeYJMQCAEAwNFpbCh03IL5lSQnVOYfm/bOoJVKze91Y21rz/wF1gAchQRCAABw9BobCtWOhjVp\nj5DVLqNeSXJZkrdVan4uybtT35X0wrRdzFalJT0AAABA3dhQaMcSNf8lyTcOzN2R5A2pXyJ9Sjfu\nTXLyQE31gmwt6QGOHLuDAABgcxjbfWzv3OtmZux/f6Dy/PlJ3pnkukrN7m6stZ0/uzIHwBEiEAIA\ngM1jbCg0r8yM29IeD3tipX5vktclc63BHq3f4nNbpebaZRcIwOEhEAIAgM1l7PGx3QvmtyW5vTL/\ncJIfSvKrlZpburG2tsFdRFrSAxw+giAAANi8xoZCyzizMvfFpml+t5RyWZLHD9Q8uMRn3D80oSU9\nwMYSBAEAwNYwNhS6d8H8SpJdlfn+EulbKjUndWPtMuq/rC1C9zEAAACAukO9U2i19zu3Mn9XNz6t\nUtO3ve9DoWaVmj0j1wUAAADAjI1oSf9nSV664PnabqL++Nmp3VhWqTmvtgAt6QHWj+NiAACwNY0N\nheZb0q9me2XuzFLK7iT7KzX9bqLa2r5xiXUAcAiEQQAAsLVtxEXTN1bm9ia5Isl1Ge4g1t9b9ECS\nEwZq3jv0AbqPAQAAACy23i3pk/pOoUeSvDrJpUm+dqDmmm48aWA+Sa4fmtB9DODQ2CEEAADTMPai\n6WOXqKl1DfujpmkuTyXUSbKzG1e7S6j3D5ZYBwAAAAAD1vv42ErqncGe1I3fXql5Qjfuy3AIderA\n35NoSQ8AAACwyKGGQk3aHT1N97MtyX2V+nNKKRcnc63BHu3hmfceckNtUbqPASzHUTEAAJiusaHQ\nfNewMjP2v/9E5fmVJG9Ocnql5oxurIVCn6rMAbAKARAAADBr7J1C9y4u+d93Aq1mV5KLUr+MuvdQ\nZa4WGAEwRyAEAADMG7tT6OHFJflCkhcOzO1I8swFz9/fjbsqNc8ZmtCSHpgSYQ8AALBWY3cKzVvp\nxgM5eE/Q11XqH5PkrUneW6n57W78xUrNG4cm+pb0D9386Uf/3OTEGQAAAEBv7E6h2WNf80e4DqS9\nV6j2nnel7SpWa0nfdxZ7XKXm5MocwJZmdxAAALAexoZCO2Z+fyiPbhn/cNrOYysZtivJV+fgZdR9\n97JZ39CNz6+8zxmVOS3pAQAAABYYGwrdOvP7sWlDoB1pL6B+JG1XsQ8meXLacOjmJOd09Svd8yXJ\n13R/mw+EkoMXVZ9XWccptUVqSQ9sRXYIAQAA62lsKPT+JK/qft+fdufPMWmPfO1NGw71u3i25WAg\n1L8+P8kVSa6b+XvTPXdfknO790naC6d3zdX1IdLnR64b4IgR5gAAAEejsaHQn878PrRT6DeTvCBt\niPP5JF8+88wtSV6d5HUzfytp7wjq7wk6vhtPzaPN7ip6TZJfG7l2YOKEMwAAAAeNCoWaprm7lHJl\nkovS7vw5qRtPTRsKbUtyT1de8uhAKEkuTXJ1kr+tfEzfkv7KtPcLHUh7f9G+HAyK/mro4UsuuSTv\nec97cvbZZy/5vwoAAABgetbSkv77k9yWNqiZ7UD2cJI7m6b5wyQfmJl7uBv/ZZKvTRv2/PLM/EqS\nG3Lw2NifdOMN3XhM2t1IszuH/uca1g0AAABAZ3Qo1DTNF9JeFP0f0raW35f2Quk/TfKDXdk/TBvy\nrCS5O22A9ANJXpbkhKZp/jrtEbK+jf25aUOifUne1H3OP0h7ROyBtMfU+h1IdyV519h1AwAAAHDQ\nWnYKpWmaW5umeWXTNBc0TXNC0zTnNU3zrU3TXN7NfyHt0bFfSxsONWmPl12X5Me6ml9MGwzdkPbI\n2MeSXNw923tVkl9PGwyVJH+c5Oubprl3LesGAAAAoDX2oumlNU1za5JXdj9DNW9M8sbK/IEkP9n9\nAAAAALBO1rRTCAAAAIDNTSgEAAAAMEFCIQAAAIAJEgoBAAAATJBQCAAAAGCChEIAAAAAEyQUAgAA\nAJggoRAAAADABAmFAAAAACZIKAQAAAAwQUIhAAAAgAkSCgEAAABMkFAIAAAAYIKEQgAAAAATppnR\nowAAC8RJREFUJBQCAAAAmCChEAAAAMAECYUAAAAAJkgoBAAAADBBQiEAAACACRIKAQAAAEyQUAgA\nAABggoRCAAAAABMkFAIAAACYIKEQAAAAwAQJhQAAAAAmSCgEAAAAMEFCIQAAAIAJEgoBAAAATJBQ\nCAAAAGCChEIAAAAAEyQUAgAAAJggoRAAAADABAmFAAAAACZIKAQAAAAwQUIhAAAAgAkSCgEAAABM\nkFAIAAAAYIKEQgAAAAATJBQCAAAAmCChEAAAAMAECYUAAAAAJkgoBAAAADBBQiEAAACACRIKAQAA\nAEyQUAgAAABggoRCAAAAABMkFAIAAACYIKEQAAAAwAQJhQAAAAAmSCgEAAAAMEFCIQAAAIAJEgoB\nAAAATJBQCAAAAGCChEIAAAAAEyQUAgAAAJggoRAAAADABAmFAAAAACZIKAQAAAAwQUIhAAAAgAkS\nCgEAAABMkFAIAAAAYIKEQgAAAAATJBQCAAAAmCChEAAAAMAECYUAAAAAJkgoBAAAADBBQiEAAACA\nCRIKAQAAAEyQUAgAAABggoRCAAAAABMkFAIAAACYIKEQAAAAwAQJhQAAAAAmSCgEAAAAMEFCIQAA\nAIAJEgoBAAAATJBQCAAAAGCChEIAAAAAEyQUAgAAAJggoRAAAADABAmFAAAAACZIKAQAAAAwQUIh\nAAAAgAkSCgEAAABMkFAIAAAAYIKEQgAAAAATJBQCAAAAmCChEAAAAMAECYUAAAAAJkgoBAAAADBB\nQiEAAACACRIKAQAAAEyQUAgAAABggoRCAAAAABMkFAIAAACYIKEQAAAAwAQJhQAAAAAmSCgEAAAA\nMEFCIQAAAIAJEgoBAAAATJBQCAAAAGCChEIAAAAAEyQUAgAAAJggoRAAAADABAmFAAAAACZIKAQA\nAAAwQUIhAAAAgAkSCgEAAABMkFAIAAAAYIKEQgAAAAATJBQCAAAAmCChEAAAAMAECYUAAAAAJkgo\nBAAAADBBQiEAAACACRIKAQAAAEyQUAgAAABggoRCAAAAABMkFAIAAACYIKEQAAAAwAQJhQAAAAAm\nSCgEAAAAMEFCIQAAAIAJEgoBAAAATJBQCAAAAGCChEIAAAAAEyQUAgAAAJggoRAAAADABAmFAAAA\nACZIKAQAAAAwQUIhAAAAgAkSCgEAAABMkFAIAAAAYIKEQgAAAAATJBQCAAAAmCChEAAAAMAECYUA\nAAAAJkgoBAAAADBBQiEAAACACRIKAQAAAEyQUAgAAABggoRCAAAAABMkFAIAAACYIKEQAAAAwAQJ\nhQAAAAAmSCgEAAAAMEFCIQAAAIAJEgoBAAAATJBQCAAAAGCChEIAAAAAEyQUAgAAAJggoRAAAADA\nBAmFAAAAACZIKAQAAAAwQUIhAAAAgAkSCgEAAABMkFAIAAAAYIKEQgAAAAATJBQCAAAAmCChEAAA\nAMAECYUAAAAAJkgoBAAAADBBQiEAAACACRIKAQAAAEyQUAgAAABggoRCAAAAABMkFAIAAACYIKEQ\nAAAAwAQJhQAAAAAmSCgEAAAAMEFCIQAAAIAJEgoBAAAATJBQCAAAAGCChEIAAAAAEyQUAgAAAJgg\noRAAAADABAmFAAAAACZIKAQAAAAwQUIhAAAAgAkSCgEAAABMkFAIAAAAYIKEQgAAAAATtOVCoU98\n4hNHegmwpb3jHe840kuALc13DDaW7xhsLN8x2FillEvX8/2EQsAo/kEPG8t3DDaW7xhsLN8x2HBC\nIQAAAAAOjVAIAAAAYIKEQgAAAAAT9JgjvYB1dnyS3H777Ud6HbBl7du3LzfffPORXgZsWb5jsLF8\nx2Bj+Y7BxjrhhBN2X3bZZTve8IY37F2P99tqodD5T3nKU/Lud7/7SK8DtqydO3fm13/914/0MmDL\n8h2DjeU7BhvLdww21iWXXPKCJF+V5K/W4/1K0zTr8T5Hhcsuu+y0JJckuS7JviO7GgAAAIB1d816\n7RTaUqEQAAAAAMtx0TQAAADABAmFAAAAACZIKAQAAAAwQUIhAAAAgAkSCgEAAABM0KYLhUopryil\nfKGU8mAp5cpSytctqH9hKeUvSyn7SimfLqX80OFaK2xGY75jpZTvLKX8cSnltlLKvaWUK0opLzqc\n64XNZuw/x2aee14pZX8p5a82eo2wma3h3xW3l1L+RSnluu7fFz9fSvnhw7Rc2HTW8B37+6WUj5VS\nHiil3FxKeUsp5dTDtV7YLEopzy+l/F4p5aZSykop5duWeOaQ845NFQqVUl6a5F8neX2Spyf5eJLL\nSymnD9Sfn+QPkvxJkguT/EqS/1hK+buHY72w2Yz9jiV5QZI/TvLiJM9I8v4kv19KufAwLBc2nTV8\nx/rndid5e5L3bvgiYRNb43fs3Um+McmPJHlSkkuTXLvBS4VNaQ3/f+x5af/59R+SPDnJ9yR5VpLf\nPCwLhs1lZ5KPJXl5kmZR8XrlHaVpFn7WUaOUcmWSjzRN86rudUlyQ5J/2zTNG1ep/6UkL26a5mtm\n/vaOJLubpvmWw7Rs2DTGfscG3uPqJP+1aZo3bNxKYXNa63es+2fXp5OsJPn2pmmecTjWC5vNGv5d\n8ZuT/HaSC5qmueewLhY2oTV8x34iyY83TfMVM3/7x0l+smma8w7TsmHTKaWsJPmOpml+r1KzLnnH\nptkpVEo5NsnXpk3BkiRNm2i9N8lzBh67KF/6X1Uvr9TDZK3xOzb/HiXJriR3bcQaYTNb63eslPIj\nSZ6Q5Gc3eo2wma3xO/aSJB9N8lOllBtLKdeWUv5lKeX4DV8wbDJr/I79WZJzSykv7t7jzCTfm+QP\nN3a1MAnrkndsmlAoyelJjkly69zfb01y1sAzZw3Un1RKOW59lweb3lq+Y/P+adptj+9ax3XBVjH6\nO1ZK+YokP5/k7zdNs7Kxy4NNby3/HLsgyfOTPCXJdyR5VdrjLb+2QWuEzWz0d6xpmiuS/ECSd5ZS\nHk5yS5K7k/zjDVwnTMW65B2bKRQCjmKllO9P8tNJvrdpmjuO9HpgsyulbEvyX5K8vmmaz/V/PoJL\ngq1oW9pjmd/fNM1Hm6b5n0leneSH/AdEOHSllCenvefkZ9LeP3lJ2t2v//4ILguY8ZgjvYAR7khy\nIMmZc38/M8kXB5754kD9nqZpHlrf5cGmt5bvWJKklPJ9aS8M/J6mad6/McuDTW/sd2xXkmcmeVop\npd+1sC3tSc2Hk7yoaZoPbNBaYTNayz/HbklyU9M098/87VNpA9hzknxu1adgmtbyHXttkg83TfOm\n7vXVpZSXJ/n/Sin/d9M087scgOWtS96xaXYKNU2zP8lfJvmm/m/d/SXflOSKgcf+bLa+86Lu78CM\nNX7HUkq5NMlbknxf919YgVWs4Tu2J8lTkzwtbUeJC5P8RpJrut8/ssFLhk1ljf8c+3CSs0spO2b+\n9pVpdw/duEFLhU1pjd+xHUkemfvbStrOSna/wqFZl7xj04RCnTcl+dFSyg+WUr4q7b8c70jytiQp\npfxCKeXtM/W/keSCUsovlVK+skulv6d7H+BLjfqOdUfG3p7kJ5L8RSnlzO7npMO/dNgUlv6ONa1P\nzv4kuS3JvqZpPtU0zYNH6H8DHM3G/rvibye5M8lvlVK+upTygiRvTPIWu8phVWO/Y7+f5LtLKT9e\nSnlC16L+V9J2MKvuRIepKaXsLKVcWEp5WvenC7rX53bzG5J3bKbjY2ma5l2llNOT/FzabVEfS3JJ\n0zS3dyVnJTl3pv66UsrfS/LLSV6Z9r/4/KOmaeZv6AYy/juW5EfTXjj4a3n0pZxvT/IPN37FsLms\n4TsGjLCGf1d8oJTyd5P8apK/SBsQvTPtHXnAnDV8x95eSjkxySuS/Ksk96TtXvbaw7pw2ByemeT9\naXfSNUn+dff3/v9bbUjeUdouggAAAABMyWY7PgYAAADAOhAKAQAAAEyQUAgAAABggoRCAAAAABMk\nFAIAAACYIKEQAAAAwAQJhQAAAAAmSCgEAAAAMEFCIQAAAIAJEgoBAAAATJBQCAAAAGCC/n9hSLEy\nOfDqLQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5112fc9210>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_variable_importances.varimp_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Comparison with Grid Search\n",
    "\n",
    "Grid search provides more subtle insights into the model tuning and selection\n",
    "process by inspecting and comparing our trained models after the grid search process is complete. \n",
    "\n",
    "To learn when and how to select different parameter\n",
    "configurations in a grid search, refer to Parameters for parameter descriptions\n",
    "and configurable values.\n",
    "\n",
    "There are different strategies to explore the hyperparameter combinatorial space:\n",
    "\n",
    "- Cartesian Search: test *every* single combination\n",
    "- Random Search: sample combinations\n",
    "\n",
    "## Cartesian Search\n",
    "In this example, three different network topologies and two different $l_1$ norm\n",
    "weights are specified. This grid search model trains six different models using all\n",
    "possible combinations of these parameters; other parameter combinations can\n",
    "be specified for a larger space of models. Note that the models will most likely\n",
    "converge before the default value of epochs, since early stopping is enabled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from h2o.grid.grid_search import H2OGridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hyper_parameters = {\n",
    "    \"hidden\":[[200,200,200],[300,300],[500]], \n",
    "    \"learning_rate\":[1e-3,5e-3],\n",
    "}\n",
    "\n",
    "model_grid = H2OGridSearch(H2ODeepWaterEstimator, hyper_params=hyper_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deepwater Grid Build progress: |██████████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "model_grid.train(\n",
    "    x=x, \n",
    "    y=y,\n",
    "    distribution=\"multinomial\", \n",
    "    epochs=1000,\n",
    "    training_frame=train_df, \n",
    "    validation_frame=test_df,\n",
    "    score_interval=2, \n",
    "    stopping_rounds=3,\n",
    "    stopping_tolerance=0.05,\n",
    "    stopping_metric=\"misclassification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              hidden learning_rate  \\\n",
      "0         [300, 300]         0.005   \n",
      "1              [500]         0.005   \n",
      "2         [300, 300]         0.001   \n",
      "3    [200, 200, 200]         0.001   \n",
      "4              [500]         0.001   \n",
      "5    [200, 200, 200]         0.005   \n",
      "\n",
      "                                                           model_ids  \\\n",
      "0  Grid_DeepWater_py_1_sid_97dd_model_python_1477169483588_6_model_4   \n",
      "1  Grid_DeepWater_py_1_sid_97dd_model_python_1477169483588_6_model_5   \n",
      "2  Grid_DeepWater_py_1_sid_97dd_model_python_1477169483588_6_model_1   \n",
      "3  Grid_DeepWater_py_1_sid_97dd_model_python_1477169483588_6_model_0   \n",
      "4  Grid_DeepWater_py_1_sid_97dd_model_python_1477169483588_6_model_2   \n",
      "5  Grid_DeepWater_py_1_sid_97dd_model_python_1477169483588_6_model_3   \n",
      "\n",
      "              logloss  \n",
      "0  1.1154530555508715  \n",
      "1  1.3041829310332147  \n",
      "2  1.8262448334340582  \n",
      "3  1.8825314106317805  \n",
      "4  1.9376039117616448  \n",
      "5   9.994712853586279  \n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print model grid search results\n",
    "model_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid_DeepWater_py_1_sid_97dd_model_python_1477169483588_6_model_4 mean per class error: 0.0\n",
      "Grid_DeepWater_py_1_sid_97dd_model_python_1477169483588_6_model_5 mean per class error: 0.000608778192448\n",
      "Grid_DeepWater_py_1_sid_97dd_model_python_1477169483588_6_model_1 mean per class error: 0.000302786811541\n",
      "Grid_DeepWater_py_1_sid_97dd_model_python_1477169483588_6_model_0 mean per class error: 0.00139071571568\n",
      "Grid_DeepWater_py_1_sid_97dd_model_python_1477169483588_6_model_2 mean per class error: 0.0199871335982\n",
      "Grid_DeepWater_py_1_sid_97dd_model_python_1477169483588_6_model_3 mean per class error: 0.309396426468\n"
     ]
    }
   ],
   "source": [
    "for model in model_grid:\n",
    "    print model.model_id + \" mean per class error: \" + str(model.mean_per_class_error())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Grid_DeepWater_py_1_sid_97dd_model_python_1477169483588_6_model_4</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Grid_DeepWater_py_1_sid_97dd_model_python_1477169483588_6_model_5</td>\n",
       "      <td>0.000609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Grid_DeepWater_py_1_sid_97dd_model_python_1477169483588_6_model_1</td>\n",
       "      <td>0.000303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Grid_DeepWater_py_1_sid_97dd_model_python_1477169483588_6_model_0</td>\n",
       "      <td>0.001391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Grid_DeepWater_py_1_sid_97dd_model_python_1477169483588_6_model_2</td>\n",
       "      <td>0.019987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Grid_DeepWater_py_1_sid_97dd_model_python_1477169483588_6_model_3</td>\n",
       "      <td>0.309396</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                   0         1\n",
       "0  Grid_DeepWater_py_1_sid_97dd_model_python_1477169483588_6_model_4  0.000000\n",
       "1  Grid_DeepWater_py_1_sid_97dd_model_python_1477169483588_6_model_5  0.000609\n",
       "2  Grid_DeepWater_py_1_sid_97dd_model_python_1477169483588_6_model_1  0.000303\n",
       "3  Grid_DeepWater_py_1_sid_97dd_model_python_1477169483588_6_model_0  0.001391\n",
       "4  Grid_DeepWater_py_1_sid_97dd_model_python_1477169483588_6_model_2  0.019987\n",
       "5  Grid_DeepWater_py_1_sid_97dd_model_python_1477169483588_6_model_3  0.309396"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_results = pd.DataFrame([[m.model_id, m.mean_per_class_error()] for m in model_grid])\n",
    "grid_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Grid Search\n",
    "\n",
    "If the search space is too large you can let the GridSearch algorithm select the parameter, by sampling from the parameter space. \n",
    "\n",
    "Just specify how many models (and/or how much training time) you want, and provide a seed to make the random selection deterministic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hyper_parameters = {\n",
    "    \"hidden\":[[1000,1000],[2000]],\n",
    "    \"learning_rate\":[s*0.001 for s in range(30,100)]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "search_criteria = {\"strategy\":\"RandomDiscrete\", \"max_models\":10, \"max_runtime_secs\":100, \"seed\":123456}\n",
    "\n",
    "model_grid_random_search = H2OGridSearch(H2ODeepWaterEstimator,\n",
    "    hyper_params=hyper_parameters,\n",
    "    search_criteria=search_criteria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deepwater Grid Build progress: |██████████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "model_grid_random_search.train(x=x, y=y,\n",
    "                distribution=\"multinomial\", \n",
    "                epochs=1000,\n",
    "                training_frame=train_df, \n",
    "                validation_frame=test_df,\n",
    "                score_interval=2, \n",
    "                stopping_rounds=3,\n",
    "                stopping_tolerance=0.05,\n",
    "                stopping_metric=\"misclassification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid_results = pd.DataFrame([[m.model_id, m.mean_per_class_error()] for m in model_grid_random_search])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Grid_DeepWater_py_1_sid_97dd_model_python_1477169483588_8_model_1</td>\n",
       "      <td>0.283926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Grid_DeepWater_py_1_sid_97dd_model_python_1477169483588_8_model_2</td>\n",
       "      <td>0.281501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Grid_DeepWater_py_1_sid_97dd_model_python_1477169483588_8_model_0</td>\n",
       "      <td>0.292263</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                   0         1\n",
       "0  Grid_DeepWater_py_1_sid_97dd_model_python_1477169483588_8_model_1  0.283926\n",
       "1  Grid_DeepWater_py_1_sid_97dd_model_python_1477169483588_8_model_2  0.281501\n",
       "2  Grid_DeepWater_py_1_sid_97dd_model_python_1477169483588_8_model_0  0.292263"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Checkpoints \n",
    "\n",
    "\n",
    "\n",
    "H2O supporst model checkpoints. You can store the `state` of training and resume it later.\n",
    "Checkpointing can be used to reload existing models that were saved to\n",
    "disk in a previous session. \n",
    "\n",
    "To resume model training, use checkpoint model keys (model id) to incrementally\n",
    "train a specific model using more iterations, more data, different data, and\n",
    "so forth. To further train the initial model, use it (or its key) as a checkpoint\n",
    "argument for a new model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To improve this initial model, start from the previous model and add iterations by\n",
    "building another model, specifying checkpoint=previous model id, and\n",
    "changing train samples per iteration, target ratio comm to comp,\n",
    "or other parameters. Many parameters can be changed between checkpoints,\n",
    "especially those that affect regularization or performance tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use GridSearch with checkpoint restarts to scan a broader range of hyperparameter combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Re-start the training process on a saved DL model using the ‘checkpoint‘ argument\n",
    "model_checkpoint = H2ODeepWaterEstimator(\n",
    "     checkpoint=model,\n",
    "     distribution=\"multinomial\",\n",
    "     activation=\"Rectifier\",\n",
    "     hidden=[32,32,32],\n",
    "     input_dropout_ratio=0.2,\n",
    "     #sparse=True,\n",
    "     epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details\n",
      "=============\n",
      "H2ODeepWaterEstimator :  Deep Water\n",
      "Model Key:  Grid_DeepWater_py_1_sid_97dd_model_python_1477169483588_6_model_3\n",
      "Status of Deep Learning Model: MLP: [200, 200, 200], 886.2 KB, predicting C785, 10-class classification, 831,488 training samples, mini-batch size 32\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>input_neurons</b></td>\n",
       "<td><b>rate</b></td>\n",
       "<td><b>momentum</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>717</td>\n",
       "<td>0.0027300</td>\n",
       "<td>0.99</td></tr></table></div>"
      ],
      "text/plain": [
       "    input_neurons    rate        momentum\n",
       "--  ---------------  ----------  ----------\n",
       "    717              0.00273002  0.99"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsMultinomial: deepwater\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.306451090878\n",
      "RMSE: 0.553580247911\n",
      "LogLoss: 10.5712170993\n",
      "Mean Per-Class Error: 0.309396426468\n",
      "Confusion Matrix: vertical: actual; across: predicted\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>0</b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>2</b></td>\n",
       "<td><b>3</b></td>\n",
       "<td><b>4</b></td>\n",
       "<td><b>5</b></td>\n",
       "<td><b>6</b></td>\n",
       "<td><b>7</b></td>\n",
       "<td><b>8</b></td>\n",
       "<td><b>9</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>816.0</td>\n",
       "<td>0.0</td>\n",
       "<td>5.0</td>\n",
       "<td>24.0</td>\n",
       "<td>2.0</td>\n",
       "<td>78.0</td>\n",
       "<td>29.0</td>\n",
       "<td>36.0</td>\n",
       "<td>27.0</td>\n",
       "<td>5.0</td>\n",
       "<td>0.2015656</td>\n",
       "<td>206 / 1,022</td></tr>\n",
       "<tr><td>1.0</td>\n",
       "<td>986.0</td>\n",
       "<td>6.0</td>\n",
       "<td>3.0</td>\n",
       "<td>7.0</td>\n",
       "<td>15.0</td>\n",
       "<td>12.0</td>\n",
       "<td>3.0</td>\n",
       "<td>91.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.1227758</td>\n",
       "<td>138 / 1,124</td></tr>\n",
       "<tr><td>30.0</td>\n",
       "<td>13.0</td>\n",
       "<td>569.0</td>\n",
       "<td>90.0</td>\n",
       "<td>28.0</td>\n",
       "<td>113.0</td>\n",
       "<td>56.0</td>\n",
       "<td>50.0</td>\n",
       "<td>63.0</td>\n",
       "<td>8.0</td>\n",
       "<td>0.4421569</td>\n",
       "<td>451 / 1,020</td></tr>\n",
       "<tr><td>19.0</td>\n",
       "<td>13.0</td>\n",
       "<td>25.0</td>\n",
       "<td>608.0</td>\n",
       "<td>9.0</td>\n",
       "<td>161.0</td>\n",
       "<td>5.0</td>\n",
       "<td>23.0</td>\n",
       "<td>113.0</td>\n",
       "<td>13.0</td>\n",
       "<td>0.3852376</td>\n",
       "<td>381 / 989</td></tr>\n",
       "<tr><td>21.0</td>\n",
       "<td>8.0</td>\n",
       "<td>7.0</td>\n",
       "<td>16.0</td>\n",
       "<td>600.0</td>\n",
       "<td>51.0</td>\n",
       "<td>55.0</td>\n",
       "<td>31.0</td>\n",
       "<td>75.0</td>\n",
       "<td>91.0</td>\n",
       "<td>0.3717277</td>\n",
       "<td>355 / 955</td></tr>\n",
       "<tr><td>34.0</td>\n",
       "<td>4.0</td>\n",
       "<td>7.0</td>\n",
       "<td>112.0</td>\n",
       "<td>27.0</td>\n",
       "<td>620.0</td>\n",
       "<td>19.0</td>\n",
       "<td>24.0</td>\n",
       "<td>79.0</td>\n",
       "<td>14.0</td>\n",
       "<td>0.3404255</td>\n",
       "<td>320 / 940</td></tr>\n",
       "<tr><td>43.0</td>\n",
       "<td>5.0</td>\n",
       "<td>15.0</td>\n",
       "<td>29.0</td>\n",
       "<td>21.0</td>\n",
       "<td>43.0</td>\n",
       "<td>777.0</td>\n",
       "<td>26.0</td>\n",
       "<td>38.0</td>\n",
       "<td>5.0</td>\n",
       "<td>0.2245509</td>\n",
       "<td>225 / 1,002</td></tr>\n",
       "<tr><td>10.0</td>\n",
       "<td>27.0</td>\n",
       "<td>5.0</td>\n",
       "<td>22.0</td>\n",
       "<td>35.0</td>\n",
       "<td>18.0</td>\n",
       "<td>2.0</td>\n",
       "<td>830.0</td>\n",
       "<td>32.0</td>\n",
       "<td>58.0</td>\n",
       "<td>0.2011550</td>\n",
       "<td>209 / 1,039</td></tr>\n",
       "<tr><td>9.0</td>\n",
       "<td>22.0</td>\n",
       "<td>16.0</td>\n",
       "<td>73.0</td>\n",
       "<td>10.0</td>\n",
       "<td>158.0</td>\n",
       "<td>16.0</td>\n",
       "<td>19.0</td>\n",
       "<td>638.0</td>\n",
       "<td>18.0</td>\n",
       "<td>0.3483146</td>\n",
       "<td>341 / 979</td></tr>\n",
       "<tr><td>10.0</td>\n",
       "<td>6.0</td>\n",
       "<td>3.0</td>\n",
       "<td>17.0</td>\n",
       "<td>143.0</td>\n",
       "<td>51.0</td>\n",
       "<td>16.0</td>\n",
       "<td>151.0</td>\n",
       "<td>70.0</td>\n",
       "<td>557.0</td>\n",
       "<td>0.4560547</td>\n",
       "<td>467 / 1,024</td></tr>\n",
       "<tr><td>993.0</td>\n",
       "<td>1084.0</td>\n",
       "<td>658.0</td>\n",
       "<td>994.0</td>\n",
       "<td>882.0</td>\n",
       "<td>1308.0</td>\n",
       "<td>987.0</td>\n",
       "<td>1193.0</td>\n",
       "<td>1226.0</td>\n",
       "<td>769.0</td>\n",
       "<td>0.3064197</td>\n",
       "<td>3,093 / 10,094</td></tr></table></div>"
      ],
      "text/plain": [
       "0    1     2    3    4    5     6    7     8     9    Error     Rate\n",
       "---  ----  ---  ---  ---  ----  ---  ----  ----  ---  --------  --------------\n",
       "816  0     5    24   2    78    29   36    27    5    0.201566  206 / 1,022\n",
       "1    986   6    3    7    15    12   3     91    0    0.122776  138 / 1,124\n",
       "30   13    569  90   28   113   56   50    63    8    0.442157  451 / 1,020\n",
       "19   13    25   608  9    161   5    23    113   13   0.385238  381 / 989\n",
       "21   8     7    16   600  51    55   31    75    91   0.371728  355 / 955\n",
       "34   4     7    112  27   620   19   24    79    14   0.340426  320 / 940\n",
       "43   5     15   29   21   43    777  26    38    5    0.224551  225 / 1,002\n",
       "10   27    5    22   35   18    2    830   32    58   0.201155  209 / 1,039\n",
       "9    22    16   73   10   158   16   19    638   18   0.348315  341 / 979\n",
       "10   6     3    17   143  51    16   151   70    557  0.456055  467 / 1,024\n",
       "993  1084  658  994  882  1308  987  1193  1226  769  0.30642   3,093 / 10,094"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-10 Hit Ratios: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>k</b></td>\n",
       "<td><b>hit_ratio</b></td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>0.6935803</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.7236972</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.7238954</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.7238954</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.7238954</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.7238954</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.7238954</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.7238954</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.7238954</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>1.0</td></tr></table></div>"
      ],
      "text/plain": [
       "k    hit_ratio\n",
       "---  -----------\n",
       "1    0.69358\n",
       "2    0.723697\n",
       "3    0.723895\n",
       "4    0.723895\n",
       "5    0.723895\n",
       "6    0.723895\n",
       "7    0.723895\n",
       "8    0.723895\n",
       "9    0.723895\n",
       "10   1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ModelMetricsMultinomial: deepwater\n",
      "** Reported on validation data. **\n",
      "\n",
      "MSE: 0.289670879949\n",
      "RMSE: 0.538210813668\n",
      "LogLoss: 9.99471285359\n",
      "Mean Per-Class Error: 0.291548942095\n",
      "Confusion Matrix: vertical: actual; across: predicted\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>0</b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>2</b></td>\n",
       "<td><b>3</b></td>\n",
       "<td><b>4</b></td>\n",
       "<td><b>5</b></td>\n",
       "<td><b>6</b></td>\n",
       "<td><b>7</b></td>\n",
       "<td><b>8</b></td>\n",
       "<td><b>9</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>810.0</td>\n",
       "<td>0.0</td>\n",
       "<td>2.0</td>\n",
       "<td>22.0</td>\n",
       "<td>1.0</td>\n",
       "<td>64.0</td>\n",
       "<td>32.0</td>\n",
       "<td>24.0</td>\n",
       "<td>19.0</td>\n",
       "<td>6.0</td>\n",
       "<td>0.1734694</td>\n",
       "<td>170 / 980</td></tr>\n",
       "<tr><td>0.0</td>\n",
       "<td>1009.0</td>\n",
       "<td>6.0</td>\n",
       "<td>4.0</td>\n",
       "<td>2.0</td>\n",
       "<td>12.0</td>\n",
       "<td>12.0</td>\n",
       "<td>2.0</td>\n",
       "<td>88.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.1110132</td>\n",
       "<td>126 / 1,135</td></tr>\n",
       "<tr><td>35.0</td>\n",
       "<td>14.0</td>\n",
       "<td>580.0</td>\n",
       "<td>85.0</td>\n",
       "<td>30.0</td>\n",
       "<td>105.0</td>\n",
       "<td>58.0</td>\n",
       "<td>42.0</td>\n",
       "<td>71.0</td>\n",
       "<td>12.0</td>\n",
       "<td>0.4379845</td>\n",
       "<td>452 / 1,032</td></tr>\n",
       "<tr><td>16.0</td>\n",
       "<td>7.0</td>\n",
       "<td>20.0</td>\n",
       "<td>683.0</td>\n",
       "<td>3.0</td>\n",
       "<td>138.0</td>\n",
       "<td>4.0</td>\n",
       "<td>27.0</td>\n",
       "<td>107.0</td>\n",
       "<td>5.0</td>\n",
       "<td>0.3237624</td>\n",
       "<td>327 / 1,010</td></tr>\n",
       "<tr><td>19.0</td>\n",
       "<td>6.0</td>\n",
       "<td>2.0</td>\n",
       "<td>16.0</td>\n",
       "<td>681.0</td>\n",
       "<td>48.0</td>\n",
       "<td>42.0</td>\n",
       "<td>32.0</td>\n",
       "<td>53.0</td>\n",
       "<td>83.0</td>\n",
       "<td>0.3065173</td>\n",
       "<td>301 / 982</td></tr>\n",
       "<tr><td>30.0</td>\n",
       "<td>5.0</td>\n",
       "<td>3.0</td>\n",
       "<td>88.0</td>\n",
       "<td>27.0</td>\n",
       "<td>626.0</td>\n",
       "<td>22.0</td>\n",
       "<td>21.0</td>\n",
       "<td>60.0</td>\n",
       "<td>10.0</td>\n",
       "<td>0.2982063</td>\n",
       "<td>266 / 892</td></tr>\n",
       "<tr><td>54.0</td>\n",
       "<td>5.0</td>\n",
       "<td>7.0</td>\n",
       "<td>29.0</td>\n",
       "<td>27.0</td>\n",
       "<td>58.0</td>\n",
       "<td>727.0</td>\n",
       "<td>23.0</td>\n",
       "<td>27.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.2411273</td>\n",
       "<td>231 / 958</td></tr>\n",
       "<tr><td>5.0</td>\n",
       "<td>37.0</td>\n",
       "<td>9.0</td>\n",
       "<td>16.0</td>\n",
       "<td>21.0</td>\n",
       "<td>39.0</td>\n",
       "<td>3.0</td>\n",
       "<td>810.0</td>\n",
       "<td>42.0</td>\n",
       "<td>46.0</td>\n",
       "<td>0.2120623</td>\n",
       "<td>218 / 1,028</td></tr>\n",
       "<tr><td>16.0</td>\n",
       "<td>9.0</td>\n",
       "<td>7.0</td>\n",
       "<td>82.0</td>\n",
       "<td>16.0</td>\n",
       "<td>175.0</td>\n",
       "<td>11.0</td>\n",
       "<td>21.0</td>\n",
       "<td>622.0</td>\n",
       "<td>15.0</td>\n",
       "<td>0.3613963</td>\n",
       "<td>352 / 974</td></tr>\n",
       "<tr><td>11.0</td>\n",
       "<td>7.0</td>\n",
       "<td>2.0</td>\n",
       "<td>22.0</td>\n",
       "<td>122.0</td>\n",
       "<td>37.0</td>\n",
       "<td>12.0</td>\n",
       "<td>155.0</td>\n",
       "<td>86.0</td>\n",
       "<td>555.0</td>\n",
       "<td>0.4499504</td>\n",
       "<td>454 / 1,009</td></tr>\n",
       "<tr><td>996.0</td>\n",
       "<td>1099.0</td>\n",
       "<td>638.0</td>\n",
       "<td>1047.0</td>\n",
       "<td>930.0</td>\n",
       "<td>1302.0</td>\n",
       "<td>923.0</td>\n",
       "<td>1157.0</td>\n",
       "<td>1175.0</td>\n",
       "<td>733.0</td>\n",
       "<td>0.2897</td>\n",
       "<td>2,897 / 10,000</td></tr></table></div>"
      ],
      "text/plain": [
       "0    1     2    3     4    5     6    7     8     9    Error     Rate\n",
       "---  ----  ---  ----  ---  ----  ---  ----  ----  ---  --------  --------------\n",
       "810  0     2    22    1    64    32   24    19    6    0.173469  170 / 980\n",
       "0    1009  6    4     2    12    12   2     88    0    0.111013  126 / 1,135\n",
       "35   14    580  85    30   105   58   42    71    12   0.437984  452 / 1,032\n",
       "16   7     20   683   3    138   4    27    107   5    0.323762  327 / 1,010\n",
       "19   6     2    16    681  48    42   32    53    83   0.306517  301 / 982\n",
       "30   5     3    88    27   626   22   21    60    10   0.298206  266 / 892\n",
       "54   5     7    29    27   58    727  23    27    1    0.241127  231 / 958\n",
       "5    37    9    16    21   39    3    810   42    46   0.212062  218 / 1,028\n",
       "16   9     7    82    16   175   11   21    622   15   0.361396  352 / 974\n",
       "11   7     2    22    122  37    12   155   86    555  0.44995   454 / 1,009\n",
       "996  1099  638  1047  930  1302  923  1157  1175  733  0.2897    2,897 / 10,000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-10 Hit Ratios: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>k</b></td>\n",
       "<td><b>hit_ratio</b></td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>0.7103</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.74</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.7402</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.7402</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.7402</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.7402</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.7402</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.7402</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.7402</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>1.0</td></tr></table></div>"
      ],
      "text/plain": [
       "k    hit_ratio\n",
       "---  -----------\n",
       "1    0.7103\n",
       "2    0.74\n",
       "3    0.7402\n",
       "4    0.7402\n",
       "5    0.7402\n",
       "6    0.7402\n",
       "7    0.7402\n",
       "8    0.7402\n",
       "9    0.7402\n",
       "10   1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring History: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>timestamp</b></td>\n",
       "<td><b>duration</b></td>\n",
       "<td><b>training_speed</b></td>\n",
       "<td><b>epochs</b></td>\n",
       "<td><b>iterations</b></td>\n",
       "<td><b>samples</b></td>\n",
       "<td><b>training_rmse</b></td>\n",
       "<td><b>training_logloss</b></td>\n",
       "<td><b>training_classification_error</b></td>\n",
       "<td><b>validation_rmse</b></td>\n",
       "<td><b>validation_logloss</b></td>\n",
       "<td><b>validation_classification_error</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-10-22 14:17:34</td>\n",
       "<td> 0.000 sec</td>\n",
       "<td>None</td>\n",
       "<td>0.0</td>\n",
       "<td>0</td>\n",
       "<td>0.0</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-10-22 14:17:34</td>\n",
       "<td> 3 min 23.937 sec</td>\n",
       "<td>12800 obs/sec</td>\n",
       "<td>0.0170667</td>\n",
       "<td>1</td>\n",
       "<td>1024.0</td>\n",
       "<td>0.5535802</td>\n",
       "<td>10.5712171</td>\n",
       "<td>0.3064197</td>\n",
       "<td>0.5382108</td>\n",
       "<td>9.9947129</td>\n",
       "<td>0.2897</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-10-22 14:17:45</td>\n",
       "<td> 3 min 34.773 sec</td>\n",
       "<td>20329 obs/sec</td>\n",
       "<td>3.4474667</td>\n",
       "<td>202</td>\n",
       "<td>206848.0</td>\n",
       "<td>0.7372107</td>\n",
       "<td>1.6381753</td>\n",
       "<td>0.5714286</td>\n",
       "<td>0.7305526</td>\n",
       "<td>1.6401491</td>\n",
       "<td>0.558</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-10-22 14:17:53</td>\n",
       "<td> 3 min 42.254 sec</td>\n",
       "<td>21160 obs/sec</td>\n",
       "<td>5.9562667</td>\n",
       "<td>349</td>\n",
       "<td>357376.0</td>\n",
       "<td>0.6851881</td>\n",
       "<td>1.5026314</td>\n",
       "<td>0.4868239</td>\n",
       "<td>0.6796391</td>\n",
       "<td>1.5961850</td>\n",
       "<td>0.4757</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-10-22 14:18:00</td>\n",
       "<td> 3 min 49.944 sec</td>\n",
       "<td>21532 obs/sec</td>\n",
       "<td>8.5504</td>\n",
       "<td>501</td>\n",
       "<td>513024.0</td>\n",
       "<td>0.6997539</td>\n",
       "<td>1.5634526</td>\n",
       "<td>0.5266495</td>\n",
       "<td>0.6910466</td>\n",
       "<td>1.6082121</td>\n",
       "<td>0.5121</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-10-22 14:18:08</td>\n",
       "<td> 3 min 57.521 sec</td>\n",
       "<td>21626 obs/sec</td>\n",
       "<td>11.0421333</td>\n",
       "<td>647</td>\n",
       "<td>662528.0</td>\n",
       "<td>0.6513551</td>\n",
       "<td>1.7837146</td>\n",
       "<td>0.4342183</td>\n",
       "<td>0.6449443</td>\n",
       "<td>1.8584088</td>\n",
       "<td>0.4247</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-10-22 14:18:16</td>\n",
       "<td> 4 min  5.146 sec</td>\n",
       "<td>22136 obs/sec</td>\n",
       "<td>13.8581333</td>\n",
       "<td>812</td>\n",
       "<td>831488.0</td>\n",
       "<td>0.6371026</td>\n",
       "<td>1.4911832</td>\n",
       "<td>0.4160888</td>\n",
       "<td>0.6294410</td>\n",
       "<td>1.5705711</td>\n",
       "<td>0.406</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-10-22 14:18:16</td>\n",
       "<td> 4 min  5.961 sec</td>\n",
       "<td>22126 obs/sec</td>\n",
       "<td>13.8581333</td>\n",
       "<td>812</td>\n",
       "<td>831488.0</td>\n",
       "<td>0.5535802</td>\n",
       "<td>10.5712171</td>\n",
       "<td>0.3064197</td>\n",
       "<td>0.5382108</td>\n",
       "<td>9.9947129</td>\n",
       "<td>0.2897</td></tr></table></div>"
      ],
      "text/plain": [
       "    timestamp            duration          training_speed    epochs     iterations    samples    training_rmse    training_logloss    training_classification_error    validation_rmse    validation_logloss    validation_classification_error\n",
       "--  -------------------  ----------------  ----------------  ---------  ------------  ---------  ---------------  ------------------  -------------------------------  -----------------  --------------------  ---------------------------------\n",
       "    2016-10-22 14:17:34  0.000 sec                           0          0             0          nan              nan                 nan                              nan                nan                   nan\n",
       "    2016-10-22 14:17:34  3 min 23.937 sec  12800 obs/sec     0.0170667  1             1024       0.55358          10.5712             0.30642                          0.538211           9.99471               0.2897\n",
       "    2016-10-22 14:17:45  3 min 34.773 sec  20329 obs/sec     3.44747    202           206848     0.737211         1.63818             0.571429                         0.730553           1.64015               0.558\n",
       "    2016-10-22 14:17:53  3 min 42.254 sec  21160 obs/sec     5.95627    349           357376     0.685188         1.50263             0.486824                         0.679639           1.59618               0.4757\n",
       "    2016-10-22 14:18:00  3 min 49.944 sec  21532 obs/sec     8.5504     501           513024     0.699754         1.56345             0.526649                         0.691047           1.60821               0.5121\n",
       "    2016-10-22 14:18:08  3 min 57.521 sec  21626 obs/sec     11.0421    647           662528     0.651355         1.78371             0.434218                         0.644944           1.85841               0.4247\n",
       "    2016-10-22 14:18:16  4 min  5.146 sec  22136 obs/sec     13.8581    812           831488     0.637103         1.49118             0.416089                         0.629441           1.57057               0.406\n",
       "    2016-10-22 14:18:16  4 min  5.961 sec  22126 obs/sec     13.8581    812           831488     0.55358          10.5712             0.30642                          0.538211           9.99471               0.2897"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deepwater Model Build progress: |█████████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "model_checkpoint.train(\n",
    " x=x,\n",
    " y=y,\n",
    " training_frame=train_df,\n",
    " validation_frame=test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify a model and a file path. The default path is the current working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/arno/h2o-3/examples/deeplearning/notebooks/Grid_DeepWater_py_1_sid_97dd_model_python_1477169483588_6_model_3\n"
     ]
    }
   ],
   "source": [
    "model_path = h2o.save_model(\n",
    "     model = model,\n",
    "     #path = \"/tmp/mymodel\",\n",
    "     force = True)\n",
    "\n",
    "print model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-rw-r-- 1 arno arno 992K Oct 22 14:32 /home/arno/h2o-3/examples/deeplearning/notebooks/Grid_DeepWater_py_1_sid_97dd_model_python_1477169483588_6_model_3\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lah $model_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After restarting H2O, you can load the saved model by specifying the host and model file path. \n",
    "\n",
    "Note: The saved model must be the same version used to save the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load model from disk\n",
    "saved_model = h2o.load_model(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use the following commands to retrieve a model from its H2O key.\n",
    "This is useful if you have created an H2O model using the web interface and\n",
    "want to continue the modeling process in another language, for example **R**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details\n",
      "=============\n",
      "H2ODeepWaterEstimator :  Deep Water\n",
      "Model Key:  DeepWater_model_python_1477169483588_9\n",
      "Status of Deep Learning Model: MLP: [32, 32, 32], 102.7 KB, predicting C785, 10-class classification, 1,200,128 training samples, mini-batch size 32\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>input_neurons</b></td>\n",
       "<td><b>rate</b></td>\n",
       "<td><b>momentum</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>717</td>\n",
       "<td>0.0022726</td>\n",
       "<td>0.99</td></tr></table></div>"
      ],
      "text/plain": [
       "    input_neurons    rate       momentum\n",
       "--  ---------------  ---------  ----------\n",
       "    717              0.0022726  0.99"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsMultinomial: deepwater\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.269314533705\n",
      "RMSE: 0.518955232853\n",
      "LogLoss: 0.951109441306\n",
      "Mean Per-Class Error: 0.330786411718\n",
      "Confusion Matrix: vertical: actual; across: predicted\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>0</b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>2</b></td>\n",
       "<td><b>3</b></td>\n",
       "<td><b>4</b></td>\n",
       "<td><b>5</b></td>\n",
       "<td><b>6</b></td>\n",
       "<td><b>7</b></td>\n",
       "<td><b>8</b></td>\n",
       "<td><b>9</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>922.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>42.0</td>\n",
       "<td>16.0</td>\n",
       "<td>11.0</td>\n",
       "<td>2.0</td>\n",
       "<td>3.0</td>\n",
       "<td>0.0752257</td>\n",
       "<td>75 / 997</td></tr>\n",
       "<tr><td>1.0</td>\n",
       "<td>1010.0</td>\n",
       "<td>20.0</td>\n",
       "<td>6.0</td>\n",
       "<td>1.0</td>\n",
       "<td>20.0</td>\n",
       "<td>8.0</td>\n",
       "<td>24.0</td>\n",
       "<td>5.0</td>\n",
       "<td>6.0</td>\n",
       "<td>0.0826521</td>\n",
       "<td>91 / 1,101</td></tr>\n",
       "<tr><td>23.0</td>\n",
       "<td>2.0</td>\n",
       "<td>812.0</td>\n",
       "<td>33.0</td>\n",
       "<td>4.0</td>\n",
       "<td>32.0</td>\n",
       "<td>41.0</td>\n",
       "<td>78.0</td>\n",
       "<td>4.0</td>\n",
       "<td>6.0</td>\n",
       "<td>0.2154589</td>\n",
       "<td>223 / 1,035</td></tr>\n",
       "<tr><td>3.0</td>\n",
       "<td>2.0</td>\n",
       "<td>26.0</td>\n",
       "<td>834.0</td>\n",
       "<td>0.0</td>\n",
       "<td>103.0</td>\n",
       "<td>2.0</td>\n",
       "<td>63.0</td>\n",
       "<td>12.0</td>\n",
       "<td>3.0</td>\n",
       "<td>0.2041985</td>\n",
       "<td>214 / 1,048</td></tr>\n",
       "<tr><td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>2.0</td>\n",
       "<td>1.0</td>\n",
       "<td>9.0</td>\n",
       "<td>29.0</td>\n",
       "<td>18.0</td>\n",
       "<td>802.0</td>\n",
       "<td>4.0</td>\n",
       "<td>40.0</td>\n",
       "<td>0.9900552</td>\n",
       "<td>896 / 905</td></tr>\n",
       "<tr><td>89.0</td>\n",
       "<td>0.0</td>\n",
       "<td>7.0</td>\n",
       "<td>60.0</td>\n",
       "<td>1.0</td>\n",
       "<td>657.0</td>\n",
       "<td>22.0</td>\n",
       "<td>52.0</td>\n",
       "<td>2.0</td>\n",
       "<td>12.0</td>\n",
       "<td>0.2716186</td>\n",
       "<td>245 / 902</td></tr>\n",
       "<tr><td>7.0</td>\n",
       "<td>0.0</td>\n",
       "<td>3.0</td>\n",
       "<td>4.0</td>\n",
       "<td>5.0</td>\n",
       "<td>10.0</td>\n",
       "<td>932.0</td>\n",
       "<td>13.0</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0450820</td>\n",
       "<td>44 / 976</td></tr>\n",
       "<tr><td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>15.0</td>\n",
       "<td>34.0</td>\n",
       "<td>2.0</td>\n",
       "<td>31.0</td>\n",
       "<td>3.0</td>\n",
       "<td>901.0</td>\n",
       "<td>0.0</td>\n",
       "<td>18.0</td>\n",
       "<td>0.1043738</td>\n",
       "<td>105 / 1,006</td></tr>\n",
       "<tr><td>12.0</td>\n",
       "<td>4.0</td>\n",
       "<td>28.0</td>\n",
       "<td>23.0</td>\n",
       "<td>2.0</td>\n",
       "<td>149.0</td>\n",
       "<td>22.0</td>\n",
       "<td>99.0</td>\n",
       "<td>660.0</td>\n",
       "<td>24.0</td>\n",
       "<td>0.3548387</td>\n",
       "<td>363 / 1,023</td></tr>\n",
       "<tr><td>2.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>9.0</td>\n",
       "<td>1.0</td>\n",
       "<td>49.0</td>\n",
       "<td>3.0</td>\n",
       "<td>854.0</td>\n",
       "<td>1.0</td>\n",
       "<td>34.0</td>\n",
       "<td>0.9643606</td>\n",
       "<td>920 / 954</td></tr>\n",
       "<tr><td>1060.0</td>\n",
       "<td>1019.0</td>\n",
       "<td>914.0</td>\n",
       "<td>1004.0</td>\n",
       "<td>26.0</td>\n",
       "<td>1122.0</td>\n",
       "<td>1067.0</td>\n",
       "<td>2897.0</td>\n",
       "<td>692.0</td>\n",
       "<td>146.0</td>\n",
       "<td>0.3192922</td>\n",
       "<td>3,176 / 9,947</td></tr></table></div>"
      ],
      "text/plain": [
       "0     1     2    3     4    5     6     7     8    9    Error      Rate\n",
       "----  ----  ---  ----  ---  ----  ----  ----  ---  ---  ---------  -------------\n",
       "922   0     0    0     1    42    16    11    2    3    0.0752257  75 / 997\n",
       "1     1010  20   6     1    20    8     24    5    6    0.0826521  91 / 1,101\n",
       "23    2     812  33    4    32    41    78    4    6    0.215459   223 / 1,035\n",
       "3     2     26   834   0    103   2     63    12   3    0.204198   214 / 1,048\n",
       "0     0     2    1     9    29    18    802   4    40   0.990055   896 / 905\n",
       "89    0     7    60    1    657   22    52    2    12   0.271619   245 / 902\n",
       "7     0     3    4     5    10    932   13    2    0    0.045082   44 / 976\n",
       "1     1     15   34    2    31    3     901   0    18   0.104374   105 / 1,006\n",
       "12    4     28   23    2    149   22    99    660  24   0.354839   363 / 1,023\n",
       "2     0     1    9     1    49    3     854   1    34   0.964361   920 / 954\n",
       "1060  1019  914  1004  26   1122  1067  2897  692  146  0.319292   3,176 / 9,947"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-10 Hit Ratios: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>k</b></td>\n",
       "<td><b>hit_ratio</b></td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>0.6807077</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.8199457</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.9269126</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.9489293</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.9653162</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.9779833</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.9839147</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.9906504</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.9962802</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>0.9999999</td></tr></table></div>"
      ],
      "text/plain": [
       "k    hit_ratio\n",
       "---  -----------\n",
       "1    0.680708\n",
       "2    0.819946\n",
       "3    0.926913\n",
       "4    0.948929\n",
       "5    0.965316\n",
       "6    0.977983\n",
       "7    0.983915\n",
       "8    0.99065\n",
       "9    0.99628\n",
       "10   1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ModelMetricsMultinomial: deepwater\n",
      "** Reported on validation data. **\n",
      "\n",
      "MSE: 0.268227184536\n",
      "RMSE: 0.517906540349\n",
      "LogLoss: 0.985670191123\n",
      "Mean Per-Class Error: 0.326379692338\n",
      "Confusion Matrix: vertical: actual; across: predicted\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>0</b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>2</b></td>\n",
       "<td><b>3</b></td>\n",
       "<td><b>4</b></td>\n",
       "<td><b>5</b></td>\n",
       "<td><b>6</b></td>\n",
       "<td><b>7</b></td>\n",
       "<td><b>8</b></td>\n",
       "<td><b>9</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>913.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>35.0</td>\n",
       "<td>20.0</td>\n",
       "<td>12.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0683673</td>\n",
       "<td>67 / 980</td></tr>\n",
       "<tr><td>1.0</td>\n",
       "<td>1062.0</td>\n",
       "<td>9.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>26.0</td>\n",
       "<td>11.0</td>\n",
       "<td>12.0</td>\n",
       "<td>9.0</td>\n",
       "<td>3.0</td>\n",
       "<td>0.0643172</td>\n",
       "<td>73 / 1,135</td></tr>\n",
       "<tr><td>22.0</td>\n",
       "<td>0.0</td>\n",
       "<td>833.0</td>\n",
       "<td>33.0</td>\n",
       "<td>4.0</td>\n",
       "<td>31.0</td>\n",
       "<td>19.0</td>\n",
       "<td>71.0</td>\n",
       "<td>15.0</td>\n",
       "<td>4.0</td>\n",
       "<td>0.1928295</td>\n",
       "<td>199 / 1,032</td></tr>\n",
       "<tr><td>8.0</td>\n",
       "<td>0.0</td>\n",
       "<td>25.0</td>\n",
       "<td>817.0</td>\n",
       "<td>0.0</td>\n",
       "<td>110.0</td>\n",
       "<td>0.0</td>\n",
       "<td>43.0</td>\n",
       "<td>5.0</td>\n",
       "<td>2.0</td>\n",
       "<td>0.1910891</td>\n",
       "<td>193 / 1,010</td></tr>\n",
       "<tr><td>2.0</td>\n",
       "<td>0.0</td>\n",
       "<td>4.0</td>\n",
       "<td>4.0</td>\n",
       "<td>12.0</td>\n",
       "<td>24.0</td>\n",
       "<td>18.0</td>\n",
       "<td>880.0</td>\n",
       "<td>1.0</td>\n",
       "<td>37.0</td>\n",
       "<td>0.9877800</td>\n",
       "<td>970 / 982</td></tr>\n",
       "<tr><td>112.0</td>\n",
       "<td>0.0</td>\n",
       "<td>3.0</td>\n",
       "<td>55.0</td>\n",
       "<td>1.0</td>\n",
       "<td>644.0</td>\n",
       "<td>19.0</td>\n",
       "<td>41.0</td>\n",
       "<td>5.0</td>\n",
       "<td>12.0</td>\n",
       "<td>0.2780269</td>\n",
       "<td>248 / 892</td></tr>\n",
       "<tr><td>10.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>6.0</td>\n",
       "<td>15.0</td>\n",
       "<td>910.0</td>\n",
       "<td>13.0</td>\n",
       "<td>0.0</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0501044</td>\n",
       "<td>48 / 958</td></tr>\n",
       "<tr><td>0.0</td>\n",
       "<td>6.0</td>\n",
       "<td>25.0</td>\n",
       "<td>40.0</td>\n",
       "<td>3.0</td>\n",
       "<td>27.0</td>\n",
       "<td>0.0</td>\n",
       "<td>913.0</td>\n",
       "<td>0.0</td>\n",
       "<td>14.0</td>\n",
       "<td>0.1118677</td>\n",
       "<td>115 / 1,028</td></tr>\n",
       "<tr><td>14.0</td>\n",
       "<td>3.0</td>\n",
       "<td>26.0</td>\n",
       "<td>16.0</td>\n",
       "<td>7.0</td>\n",
       "<td>136.0</td>\n",
       "<td>17.0</td>\n",
       "<td>96.0</td>\n",
       "<td>632.0</td>\n",
       "<td>27.0</td>\n",
       "<td>0.3511294</td>\n",
       "<td>342 / 974</td></tr>\n",
       "<tr><td>5.0</td>\n",
       "<td>3.0</td>\n",
       "<td>1.0</td>\n",
       "<td>17.0</td>\n",
       "<td>5.0</td>\n",
       "<td>34.0</td>\n",
       "<td>3.0</td>\n",
       "<td>904.0</td>\n",
       "<td>5.0</td>\n",
       "<td>32.0</td>\n",
       "<td>0.9682854</td>\n",
       "<td>977 / 1,009</td></tr>\n",
       "<tr><td>1087.0</td>\n",
       "<td>1075.0</td>\n",
       "<td>926.0</td>\n",
       "<td>984.0</td>\n",
       "<td>39.0</td>\n",
       "<td>1082.0</td>\n",
       "<td>1017.0</td>\n",
       "<td>2985.0</td>\n",
       "<td>672.0</td>\n",
       "<td>133.0</td>\n",
       "<td>0.3232</td>\n",
       "<td>3,232 / 10,000</td></tr></table></div>"
      ],
      "text/plain": [
       "0     1     2    3    4    5     6     7     8    9    Error      Rate\n",
       "----  ----  ---  ---  ---  ----  ----  ----  ---  ---  ---------  --------------\n",
       "913   0     0    0    0    35    20    12    0    0    0.0683673  67 / 980\n",
       "1     1062  9    1    1    26    11    12    9    3    0.0643172  73 / 1,135\n",
       "22    0     833  33   4    31    19    71    15   4    0.192829   199 / 1,032\n",
       "8     0     25   817  0    110   0     43    5    2    0.191089   193 / 1,010\n",
       "2     0     4    4    12   24    18    880   1    37   0.98778    970 / 982\n",
       "112   0     3    55   1    644   19    41    5    12   0.278027   248 / 892\n",
       "10    1     0    1    6    15    910   13    0    2    0.0501044  48 / 958\n",
       "0     6     25   40   3    27    0     913   0    14   0.111868   115 / 1,028\n",
       "14    3     26   16   7    136   17    96    632  27   0.351129   342 / 974\n",
       "5     3     1    17   5    34    3     904   5    32   0.968285   977 / 1,009\n",
       "1087  1075  926  984  39   1082  1017  2985  672  133  0.3232     3,232 / 10,000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-10 Hit Ratios: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>k</b></td>\n",
       "<td><b>hit_ratio</b></td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>0.6768</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.8203</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.9297000</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.9519000</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.9678000</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.9791</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.9862</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.993</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.997</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>1.0</td></tr></table></div>"
      ],
      "text/plain": [
       "k    hit_ratio\n",
       "---  -----------\n",
       "1    0.6768\n",
       "2    0.8203\n",
       "3    0.9297\n",
       "4    0.9519\n",
       "5    0.9678\n",
       "6    0.9791\n",
       "7    0.9862\n",
       "8    0.993\n",
       "9    0.997\n",
       "10   1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring History: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>timestamp</b></td>\n",
       "<td><b>duration</b></td>\n",
       "<td><b>training_speed</b></td>\n",
       "<td><b>epochs</b></td>\n",
       "<td><b>iterations</b></td>\n",
       "<td><b>samples</b></td>\n",
       "<td><b>training_rmse</b></td>\n",
       "<td><b>training_logloss</b></td>\n",
       "<td><b>training_classification_error</b></td>\n",
       "<td><b>validation_rmse</b></td>\n",
       "<td><b>validation_logloss</b></td>\n",
       "<td><b>validation_classification_error</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-10-22 14:31:22</td>\n",
       "<td> 0.000 sec</td>\n",
       "<td>None</td>\n",
       "<td>0.0</td>\n",
       "<td>0</td>\n",
       "<td>0.0</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-10-22 14:31:22</td>\n",
       "<td> 1.793 sec</td>\n",
       "<td>13128 obs/sec</td>\n",
       "<td>0.0170667</td>\n",
       "<td>1</td>\n",
       "<td>1024.0</td>\n",
       "<td>0.8539392</td>\n",
       "<td>24.3542422</td>\n",
       "<td>0.7310747</td>\n",
       "<td>0.8509188</td>\n",
       "<td>24.0927802</td>\n",
       "<td>0.7257</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-10-22 14:31:34</td>\n",
       "<td>12.511 sec</td>\n",
       "<td>20632 obs/sec</td>\n",
       "<td>3.4986667</td>\n",
       "<td>205</td>\n",
       "<td>209920.0</td>\n",
       "<td>0.7188709</td>\n",
       "<td>1.5158395</td>\n",
       "<td>0.5762541</td>\n",
       "<td>0.7221390</td>\n",
       "<td>1.5556631</td>\n",
       "<td>0.5805</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-10-22 14:31:40</td>\n",
       "<td>18.896 sec</td>\n",
       "<td>22086 obs/sec</td>\n",
       "<td>5.8197333</td>\n",
       "<td>341</td>\n",
       "<td>349184.0</td>\n",
       "<td>0.6995402</td>\n",
       "<td>1.4658763</td>\n",
       "<td>0.5408666</td>\n",
       "<td>0.7056942</td>\n",
       "<td>1.4987537</td>\n",
       "<td>0.5506</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-10-22 14:31:47</td>\n",
       "<td>26.410 sec</td>\n",
       "<td>22615 obs/sec</td>\n",
       "<td>8.5162667</td>\n",
       "<td>499</td>\n",
       "<td>510976.0</td>\n",
       "<td>0.6669614</td>\n",
       "<td>1.3446123</td>\n",
       "<td>0.4924098</td>\n",
       "<td>0.6678846</td>\n",
       "<td>1.3668519</td>\n",
       "<td>0.4956</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-10-22 14:31:55</td>\n",
       "<td>33.710 sec</td>\n",
       "<td>22972 obs/sec</td>\n",
       "<td>11.1786667</td>\n",
       "<td>655</td>\n",
       "<td>670720.0</td>\n",
       "<td>0.6167714</td>\n",
       "<td>1.2473903</td>\n",
       "<td>0.4266613</td>\n",
       "<td>0.6148602</td>\n",
       "<td>1.2259792</td>\n",
       "<td>0.4224</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-10-22 14:32:02</td>\n",
       "<td>40.715 sec</td>\n",
       "<td>23225 obs/sec</td>\n",
       "<td>13.7386667</td>\n",
       "<td>805</td>\n",
       "<td>824320.0</td>\n",
       "<td>0.5511370</td>\n",
       "<td>1.0822004</td>\n",
       "<td>0.3526691</td>\n",
       "<td>0.5519751</td>\n",
       "<td>1.1224738</td>\n",
       "<td>0.3567</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-10-22 14:32:09</td>\n",
       "<td>47.855 sec</td>\n",
       "<td>23423 obs/sec</td>\n",
       "<td>16.3669333</td>\n",
       "<td>959</td>\n",
       "<td>982016.0</td>\n",
       "<td>0.5319236</td>\n",
       "<td>1.0301335</td>\n",
       "<td>0.3287423</td>\n",
       "<td>0.5288792</td>\n",
       "<td>1.0411657</td>\n",
       "<td>0.3314</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-10-22 14:32:16</td>\n",
       "<td>54.952 sec</td>\n",
       "<td>23545 obs/sec</td>\n",
       "<td>18.9610667</td>\n",
       "<td>1111</td>\n",
       "<td>1137664.0</td>\n",
       "<td>0.5189552</td>\n",
       "<td>0.9511094</td>\n",
       "<td>0.3192922</td>\n",
       "<td>0.5179065</td>\n",
       "<td>0.9856702</td>\n",
       "<td>0.3232</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-10-22 14:32:19</td>\n",
       "<td>58.257 sec</td>\n",
       "<td>23567 obs/sec</td>\n",
       "<td>20.0021333</td>\n",
       "<td>1172</td>\n",
       "<td>1200128.0</td>\n",
       "<td>0.5000624</td>\n",
       "<td>0.9701306</td>\n",
       "<td>0.2927516</td>\n",
       "<td>0.4991592</td>\n",
       "<td>0.9976713</td>\n",
       "<td>0.2931</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-10-22 14:32:20</td>\n",
       "<td>58.987 sec</td>\n",
       "<td>23561 obs/sec</td>\n",
       "<td>20.0021333</td>\n",
       "<td>1172</td>\n",
       "<td>1200128.0</td>\n",
       "<td>0.5189552</td>\n",
       "<td>0.9511094</td>\n",
       "<td>0.3192922</td>\n",
       "<td>0.5179065</td>\n",
       "<td>0.9856702</td>\n",
       "<td>0.3232</td></tr></table></div>"
      ],
      "text/plain": [
       "    timestamp            duration    training_speed    epochs     iterations    samples      training_rmse    training_logloss    training_classification_error    validation_rmse    validation_logloss    validation_classification_error\n",
       "--  -------------------  ----------  ----------------  ---------  ------------  -----------  ---------------  ------------------  -------------------------------  -----------------  --------------------  ---------------------------------\n",
       "    2016-10-22 14:31:22  0.000 sec                     0          0             0            nan              nan                 nan                              nan                nan                   nan\n",
       "    2016-10-22 14:31:22  1.793 sec   13128 obs/sec     0.0170667  1             1024         0.853939         24.3542             0.731075                         0.850919           24.0928               0.7257\n",
       "    2016-10-22 14:31:34  12.511 sec  20632 obs/sec     3.49867    205           209920       0.718871         1.51584             0.576254                         0.722139           1.55566               0.5805\n",
       "    2016-10-22 14:31:40  18.896 sec  22086 obs/sec     5.81973    341           349184       0.69954          1.46588             0.540867                         0.705694           1.49875               0.5506\n",
       "    2016-10-22 14:31:47  26.410 sec  22615 obs/sec     8.51627    499           510976       0.666961         1.34461             0.49241                          0.667885           1.36685               0.4956\n",
       "    2016-10-22 14:31:55  33.710 sec  22972 obs/sec     11.1787    655           670720       0.616771         1.24739             0.426661                         0.61486            1.22598               0.4224\n",
       "    2016-10-22 14:32:02  40.715 sec  23225 obs/sec     13.7387    805           824320       0.551137         1.0822              0.352669                         0.551975           1.12247               0.3567\n",
       "    2016-10-22 14:32:09  47.855 sec  23423 obs/sec     16.3669    959           982016       0.531924         1.03013             0.328742                         0.528879           1.04117               0.3314\n",
       "    2016-10-22 14:32:16  54.952 sec  23545 obs/sec     18.9611    1111          1.13766e+06  0.518955         0.951109            0.319292                         0.517907           0.98567               0.3232\n",
       "    2016-10-22 14:32:19  58.257 sec  23567 obs/sec     20.0021    1172          1.20013e+06  0.500062         0.970131            0.292752                         0.499159           0.997671              0.2931\n",
       "    2016-10-22 14:32:20  58.987 sec  23561 obs/sec     20.0021    1172          1.20013e+06  0.518955         0.951109            0.319292                         0.517907           0.98567               0.3232"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve model by H2O key\n",
    "model = h2o.get_model(model_id=model_checkpoint._id)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "In this jupyter you learned to:\n",
    "- use a deeplearning model\n",
    "- use GridSearch\n",
    "- use Checkpointing\n",
    "- use Early Stopping"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
